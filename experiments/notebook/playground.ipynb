{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"client0_attacker_14_normal_step\": 0.5175706596299099,\n",
    "  \"client0_attacker_19_normal_step\": 0.5429864203393666,\n",
    "  \"client0_attacker_32_normal_step\": 0.3857142807290817,\n",
    "  \"_step\": 4249,\n",
    "  \"client0_loss\": 2.031713839054108,\n",
    "  \"client0_attacker_29_tr2t_avg\": 0.5275647235774503,\n",
    "  \"client0_attacker_8_normal_avg\": 0.6366766778182428,\n",
    "  \"client0_attacker_16_normal_step\": 0.5285769033264401,\n",
    "  \"client0_attacker_24_normal_step\": 0.544871789879511,\n",
    "  \"client0_attacker_28_normal_step\": 0.4467532417557092,\n",
    "  \"client0_test-ppl\": 14.366519927978516,\n",
    "  \"client0_attacker_0_normal_avg\": 0.5362440276624566,\n",
    "  \"client0_attacker_32_normal_avg\": 0.4366247128481753,\n",
    "  \"client0_attacker_9_normal_step\": 0.5223380441441088,\n",
    "  \"client0_attacker_34_normal_avg\": 0.31704178424232093,\n",
    "  \"client0_attacker_35_normal_avg\": 0.27924916250140014,\n",
    "  \"client0_attacker_30_normal_step\": 0.4590469049036024,\n",
    "  \"global_step\": 4249,\n",
    "  \"client0_global_round\": 0,\n",
    "  \"client0_attacker_5_b2tr_avg\": 0.6304907277186129,\n",
    "  \"client0_attacker_3_normal_avg\": 0.6183885509769569,\n",
    "  \"client0_attacker_23_normal_step\": 0.5818181768206444,\n",
    "  \"client0_attacker_31_normal_step\": 0.41103848447329144,\n",
    "  \"client0_self_pt\": 0,\n",
    "  \"client0_attacker_11_normal_avg\": 0.6377722236693276,\n",
    "  \"client0_attacker_33_normal_avg\": 0.39310278683275807,\n",
    "  \"client0_attacker_6_normal_step\": 0.5439360879591302,\n",
    "  \"client0_attacker_2_normal_avg\": 0.6089481650353057,\n",
    "  \"client0_attacker_4_normal_avg\": 0.6238578184133798,\n",
    "  \"client0_attacker_22_normal_step\": 0.5893812020286877,\n",
    "  \"client0_attacker_25_normal_step\": 0.5504761854822313,\n",
    "  \"client0_attacker_13_normal_step\": 0.5263951684539971,\n",
    "  \"client0_attacker_9_normal_avg\": 0.6384095213150243,\n",
    "  \"client0_attacker_16_normal_avg\": 0.6330719245495596,\n",
    "  \"client0_attacker_24_normal_avg\": 0.5943958147410345,\n",
    "  \"client0_attacker_26_normal_avg\": 0.5723204183075637,\n",
    "  \"client0_attacker_15_normal_step\": 0.5175706596299099,\n",
    "  \"client0_attacker_5_b2tr_step\": 0.5145243232532479,\n",
    "  \"client0_attacker_7_normal_avg\": 0.6351210251036679,\n",
    "  \"client0_attacker_12_normal_avg\": 0.6366890118070682,\n",
    "  \"client0_attacker_13_normal_avg\": 0.6347554874791649,\n",
    "  \"client0_attacker_21_normal_avg\": 0.620009580633759,\n",
    "  \"client0_attacker_25_normal_avg\": 0.5867858649221694,\n",
    "  \"client0_attacker_27_normal_avg\": 0.5616850112415854,\n",
    "  \"client0_attacker_3_normal_step\": 0.5351071642617553,\n",
    "  \"_wandb.runtime\": 1649,\n",
    "  \"client0_local_epoch\": 0,\n",
    "  \"client0_attacker_10_normal_avg\": 0.6380667878549796,\n",
    "  \"client0_attacker_20_normal_avg\": 0.624557655192967,\n",
    "  \"client0_attacker_20_normal_step\": 0.5729323258308399,\n",
    "  \"client0_attacker_21_normal_step\": 0.5688311638336314,\n",
    "  \"client0_attacker_33_normal_step\": 0.33369407870222145,\n",
    "  \"client0_attacker_34_normal_step\": 0.30359476626650117,\n",
    "  \"client0_attacker_31_normal_avg\": 0.4747830768028701,\n",
    "  \"client0_attacker_10_normal_step\": 0.5096798162960074,\n",
    "  \"client0_attacker_12_normal_step\": 0.5175706596299099,\n",
    "  \"client0_attacker_26_normal_step\": 0.5203007468834715,\n",
    "  \"_runtime\": 1651.2562370300293,\n",
    "  \"_timestamp\": 1707696679.616939,\n",
    "  \"client0_attacker_1_normal_step\": 0.5177280500885659,\n",
    "  \"client0_attacker_28_normal_avg\": 0.5459204030441271,\n",
    "  \"client0_attacker_6_normal_avg\": 0.6324742085562801,\n",
    "  \"client0_attacker_17_normal_avg\": 0.6309008512450668,\n",
    "  \"client0_attacker_18_normal_avg\": 0.6301045366130664,\n",
    "  \"client0_attacker_4_normal_step\": 0.5473022862129748,\n",
    "  \"client0_attacker_17_normal_step\": 0.5469824243357921,\n",
    "  \"client0_attacker_15_normal_avg\": 0.6324732529184328,\n",
    "  \"client0_attacker_22_normal_avg\": 0.611303527540108,\n",
    "  \"client0_attacker_23_normal_avg\": 0.6043506538926331,\n",
    "  \"client0_attacker_7_normal_step\": 0.5562817669714759,\n",
    "  \"client0_self\": 0.0005098648707545071,\n",
    "  \"client0_local_step\": 4249,\n",
    "  \"client0_attacker_8_normal_step\": 0.5549242374281007,\n",
    "  \"client0_attacker_29_tr2t_step\": 0.454184699192842,\n",
    "  \"client0_attacker_2_normal_step\": 0.5012778336386043,\n",
    "  \"client0_attacker_11_normal_step\": 0.5135746556334841,\n",
    "  \"client0_attacker_0_normal_step\": 0.5027100221139359,\n",
    "  \"client0_attacker_14_normal_avg\": 0.6337987627417009,\n",
    "  \"client0_attacker_35_normal_step\": 0.2107142807178891,\n",
    "  \"client0_attacker_27_normal_step\": 0.5097402547483976,\n",
    "  \"client0_attacker_1_normal_avg\": 0.5966522677713505,\n",
    "  \"client0_attacker_19_normal_avg\": 0.627233252992626,\n",
    "  \"client0_attacker_30_normal_avg\": 0.5104403879249436,\n",
    "  \"client0_attacker_18_normal_step\": 0.5510835863330007\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b18475090dd43a9a7d018e928b16429"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from sfl.utils.exp import get_model_and_tokenizer\n",
    "\n",
    "model, tokenizer = get_model_and_tokenizer('llama2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "LlamaConfig {\n  \"_name_or_path\": \"/root/autodl-tmp/sfl/models/daryl149/llama-2-7b-chat-hf\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 2048,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"pad_token_id\": 0,\n  \"pretraining_tp\": 1,\n  \"quantization_config\": {\n    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n    \"bnb_4bit_quant_type\": \"nf4\",\n    \"bnb_4bit_use_double_quant\": true,\n    \"llm_int8_enable_fp32_cpu_offload\": false,\n    \"llm_int8_has_fp16_weight\": false,\n    \"llm_int8_skip_modules\": null,\n    \"llm_int8_threshold\": 6.0,\n    \"load_in_4bit\": false,\n    \"load_in_8bit\": true\n  },\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.31.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "LLAMA2SplitLMHeadModel(\n  (model): LLAMA2SplitModel(\n    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear8bitLt(\n            in_features=4096, out_features=4096, bias=False\n            (lora_dropout): ModuleDict(\n              (default): Identity()\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=4096, out_features=8, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=8, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n          )\n          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n          (v_proj): Linear8bitLt(\n            in_features=4096, out_features=4096, bias=False\n            (lora_dropout): ModuleDict(\n              (default): Identity()\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=4096, out_features=8, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=8, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n          )\n          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n    (perturber): DxPrivacy(\n      (embedder): Embedding(32000, 4096, padding_idx=0)\n    )\n  )\n  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sfl.config import FLConfig\n",
    "config = FLConfig(collect_intermediates=True,\n",
    "                  global_round=4,\n",
    "                  client_evaluate_freq=500,\n",
    "                  client_epoch=1,  # 每轮联邦每个Client训2轮\n",
    "                  split_point_1=4,\n",
    "                  split_point_2=30,  # [0,1 | 2,3,.... 29| 30, 31]\n",
    "                  use_lora_at_trunk=True,  # 在trunk部分使用LoRA\n",
    "                  use_lora_at_top=True,\n",
    "                  use_lora_at_bottom=True,\n",
    "                  top_and_bottom_from_scratch='False',  # top和bottom都不采用预训练参数.\n",
    "                  noise_mode=\"none\",\n",
    "                  noise_scale=0.0,  # 噪声大小,\n",
    "                  batch_size=2,\n",
    "                  dataset_type='train'\n",
    "                  )\n",
    "\n",
    "model.config_sfl(config)\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nobody\n"
     ]
    }
   ],
   "source": [
    "from sfl.utils.model import get_output\n",
    "from sfl.utils.exp import get_dlg_attacker\n",
    "\n",
    "\n",
    "ts = get_output(\"test\", tokenizer, model)\n",
    "print(ts)\n",
    "dlg = get_dlg_attacker(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sfl.config import DRAConfig\n",
    "from sfl.utils.exp import get_dra_attacker\n",
    "\n",
    "atk_cfg = DRAConfig(target_model_name='llama2', target_dataset='wikitext', target_sps='4-30')\n",
    "atk, _ = get_dra_attacker(atk_cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm_notebook\n",
    "from sfl.utils.model import calculate_rouge\n",
    "from sfl.utils.exp import get_dataset_class\n",
    "\n",
    "client_ids = ['0']\n",
    "# model = model.convert_to_lora_model()\n",
    "dlg.to(model.device)\n",
    "atk.to(model.device)\n",
    "dataset_cls = get_dataset_class('wikitext')\n",
    "dataset = dataset_cls(tokenizer=tokenizer, client_ids=client_ids)\n",
    "test_loader = dataset.get_dataloader_unsliced(1, 'train', shrink_frac=0.2)\n",
    "\n",
    "# avg_rouge = 0\n",
    "# avg_rouge_dlg = 0\n",
    "# step = 0\n",
    "# opt = AdamW(model.parameters(), lr=1e-5)\n",
    "# with tqdm_notebook(total=len(test_loader)) as pbar:\n",
    "#   for batch in test_loader:\n",
    "#     opt.zero_grad()\n",
    "#     input_ids = batch['input_ids'].to(model.device)\n",
    "#     o1 = model(input_ids, batch['input_att_mask'].to(model.device), labels=input_ids)\n",
    "#     # o2 = dlg(tr2t.fx.to(model.device))\n",
    "#     # print(o1)\n",
    "#     o1.loss.backward()\n",
    "#     b2tr, tr2t, all = model.get_all_inter()\n",
    "#     opt.step()\n",
    "#     pred = atk(b2tr.fx.to(model.device))\n",
    "#     # res = tokenizer.decode(pred.argmax(dim=-1)[0])\n",
    "#       # print(res)\n",
    "#     # print(batch['input_text'][0])\n",
    "#     gt = dlg.fit(tr2t.fx.to(model.device), tr2t.grad.to(model.device), epochs=30, gt_init=pred)\n",
    "#     avg_rouge += calculate_rouge(tokenizer, pred, batch['input_text'])['rouge-l']['f']\n",
    "#     avg_rouge_dlg += calculate_rouge(tokenizer, gt, batch['input_text'])['rouge-l']['f']\n",
    "#     step += 1\n",
    "#     pbar.set_postfix({'dra_rouge': avg_rouge / step, 'dlg_rouge':avg_rouge_dlg/step})\n",
    "#     pbar.update()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sfl.utils.exp import add_sfl_params\n",
    "import argparse\n",
    "import torch\n",
    "from typing import Any\n",
    "from sfl.utils.model import Intermediate\n",
    "from sfl.simulator.strategy import BaseSFLStrategy\n",
    "from sfl.simulator.simulator import SFLSimulator\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "add_sfl_params(parser)\n",
    "args = parser.parse_args({})\n",
    "\n",
    "args.log_to_wandb = False\n",
    "args.dlg_epochs = 30\n",
    "args.dlg_init_with_dra = True\n",
    "\n",
    "# 定义Client本地学习策略\n",
    "class QAFLStrategy(BaseSFLStrategy):\n",
    "\n",
    "\n",
    "    def sample_attacker_triggered(self, global_round, client_id, local_epoch, local_step,\n",
    "                                  b2tr_inter: Intermediate, tr2t_inter: Intermediate,\n",
    "                                  all_inter: dict[Any, Intermediate],\n",
    "                                  batch, logs):\n",
    "        encoder_inter = all_inter.get('encoder', None)\n",
    "        with torch.no_grad():\n",
    "            for type, atk in zip(['b2tr', 'tr2t'], [self.dra1, self.dra2]):\n",
    "                if atk is None:\n",
    "                    continue\n",
    "                atk.to(self.simulator.device)\n",
    "                inter = b2tr_inter if type == 'b2tr' else tr2t_inter\n",
    "                if self.llm.type == 'encoder-decoder':\n",
    "                    attacked = atk(torch.concat([encoder_inter.fx.to(\n",
    "                        self.simulator.device), inter.fx.to(atk.device)], dim=1))\n",
    "                else:\n",
    "                    attacked = atk(inter.fx.to(atk.device))\n",
    "                rouge_res = calculate_rouge(self.tokenizer, attacked, batch['input_text'])\n",
    "                self.log_to_sample_result(client_id, f'attacker_{type}', rouge_res['rouge-l']['f'])\n",
    "                self.log_to_all_result(client_id, f'attacker_{type}', rouge_res['rouge-l']['f'])\n",
    "                logs[f'attacker_{type}_step'] = rouge_res['rouge-l']['f']\n",
    "        gt_init = None\n",
    "        if self.args.dlg_init_with_dra:\n",
    "            gt_init = attacked\n",
    "        self.dlg.to(self.simulator.device)\n",
    "        gt = self.dlg.fit(tr2t_inter.fx.to(self.simulator.device), tr2t_inter.grad.to(self.simulator.device),\n",
    "                          epochs=self.args.dlg_epochs,\n",
    "                          adjust=False,\n",
    "                          beta=self.args.dlg_beta,\n",
    "                          gt_init=gt_init,\n",
    "                          gt_reg=self.args.dlg_dra_reg,\n",
    "                          temp_range=self.args.dlg_temp_range,\n",
    "                          further_ft=self.args.dlg_further_ft,\n",
    "                          encoder_inter=None if encoder_inter is None else encoder_inter.fx.to(\n",
    "                              self.simulator.device)\n",
    "                          )\n",
    "        if self.llm.type == 'encoder-decoder':\n",
    "            # replace the latter half of attacked to gt\n",
    "            attacked[:, -gt.shape[1]:, :] = gt\n",
    "            rouge = calculate_rouge(self.tokenizer, attacked, batch['input_text'])\n",
    "        else:\n",
    "            rouge = calculate_rouge(self.tokenizer, gt, batch['input_text'])\n",
    "        self.log_to_sample_result(client_id, 'tag_rouge_lf', rouge['rouge-l']['f'])\n",
    "        self.log_to_all_result(client_id, 'tag_rouge_lf', rouge['rouge-l']['f'])\n",
    "        print(self.attack_all_performs)\n",
    "\n",
    "\n",
    "\n",
    "simulator = SFLSimulator(client_ids=client_ids,\n",
    "                             strategy=QAFLStrategy(args, model, tokenizer, test_loader, atk, None,dlg),\n",
    "                             llm=model,\n",
    "                             tokenizer=tokenizer,\n",
    "                             dataset=dataset, config=config, args=args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================Global Round 0=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sfl/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Client 0 Epoch 0 Step (25, 25) Loss 4.160:  50%|██████████████████████████████████████████████                                              | 25/50 [00:10<00:19,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'attacker_b2tr': [0.8272024232734682], 'tag_rouge_lf': [0.8850751691844674]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Client 0 Epoch 0 Step (25, 25) Loss 4.160:  52%|███████████████████████████████████████████████▊                                            | 26/50 [00:12<00:26,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'attacker_b2tr': [0.8272024232734682, 0.8380681768187558], 'tag_rouge_lf': [0.8850751691844674, 0.8305422597568983]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Client 0 Epoch 0 Step (26, 26) Loss 3.428:  54%|█████████████████████████████████████████████████▋                                          | 27/50 [00:14<00:32,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'attacker_b2tr': [0.8272024232734682, 0.8380681768187558, 0.8364117597065831], 'tag_rouge_lf': [0.8850751691844674, 0.8305422597568983, 0.8763371794261045]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Client 0 Epoch 0 Step (27, 27) Loss 2.915:  56%|███████████████████████████████████████████████████▌                                        | 28/50 [00:16<00:36,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'attacker_b2tr': [0.8272024232734682, 0.8380681768187558, 0.8364117597065831, 0.9007445768382571], 'tag_rouge_lf': [0.8850751691844674, 0.8305422597568983, 0.8763371794261045, 0.9359576918279902]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Client 0 Epoch 0 Step (28, 28) Loss 3.835:  58%|█████████████████████████████████████████████████████▎                                      | 29/50 [00:18<00:37,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'attacker_b2tr': [0.8272024232734682, 0.8380681768187558, 0.8364117597065831, 0.9007445768382571, 0.8967741885559293], 'tag_rouge_lf': [0.8850751691844674, 0.8305422597568983, 0.8763371794261045, 0.9359576918279902, 0.8982404642157533]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Client 0 Epoch 0 Step (29, 29) Loss 2.846:  60%|███████████████████████████████████████████████████████▏                                    | 30/50 [00:20<00:37,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'attacker_b2tr': [0.8272024232734682, 0.8380681768187558, 0.8364117597065831, 0.9007445768382571, 0.8967741885559293, 0.8679947818195736], 'tag_rouge_lf': [0.8850751691844674, 0.8305422597568983, 0.8763371794261045, 0.9359576918279902, 0.8982404642157533, 0.9082718007828153]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Client 0 Epoch 0 Step (30, 30) Loss 2.826:  60%|███████████████████████████████████████████████████████▏                                    | 30/50 [00:21<00:14,  1.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m simulator\u001B[38;5;241m.\u001B[39msimulate()\n",
      "File \u001B[0;32m/home/project/SFL-LLM/sfl/simulator/simulator.py:149\u001B[0m, in \u001B[0;36mSFLSimulator.simulate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    147\u001B[0m iters\u001B[38;5;241m.\u001B[39msetdefault(client_id, [\u001B[38;5;28miter\u001B[39m(loaders[client_id])])\n\u001B[1;32m    148\u001B[0m itt \u001B[38;5;241m=\u001B[39m CircularDataLoaderIterator(iters[client_id], loaders[client_id], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mclient_steps)\n\u001B[0;32m--> 149\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client_step(client_id, i, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_epochs[client_id], itt)\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_steps[client_id] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m itt\u001B[38;5;241m.\u001B[39miterated_num\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_steps[client_id] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m itt\u001B[38;5;241m.\u001B[39miterated_num\n",
      "File \u001B[0;32m/home/project/SFL-LLM/sfl/simulator/simulator.py:231\u001B[0m, in \u001B[0;36mSFLSimulator._client_step\u001B[0;34m(self, client_id, global_round, local_epoch, iterator)\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;66;03m# client step\u001B[39;00m\n\u001B[1;32m    230\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m--> 231\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mclient_step(client_id, global_round, local_epoch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm, iterator, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig)\n\u001B[1;32m    232\u001B[0m \u001B[38;5;66;03m# store updated client parameters\u001B[39;00m\n\u001B[1;32m    233\u001B[0m cm \u001B[38;5;241m=\u001B[39m ([p\u001B[38;5;241m.\u001B[39mcpu() \u001B[38;5;28;01mfor\u001B[39;00m nm, p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mget_top_params()],\n\u001B[1;32m    234\u001B[0m       [p\u001B[38;5;241m.\u001B[39mcpu() \u001B[38;5;28;01mfor\u001B[39;00m nm, p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mget_bottom_params()])\n",
      "File \u001B[0;32m/home/project/SFL-LLM/sfl/simulator/strategy.py:114\u001B[0m, in \u001B[0;36mBaseSFLStrategy.client_step\u001B[0;34m(self, client_id, global_round, client_epoch, llm, iterator, config)\u001B[0m\n\u001B[1;32m    105\u001B[0m avg_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m    106\u001B[0m \u001B[38;5;66;03m# avg_self_rouge += \\\u001B[39;00m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;66;03m#     calculate_rouge(self.tokenizer, outputs.logits.argmax(dim=-1), batch['input_text'])['rouge-l'][\u001B[39;00m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;66;03m#         'f']\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;66;03m#     avg_self_rouge_pt += \\\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m#         calculate_rouge(self.tokenizer, outputs_pt.logits, batch['input_text'])['rouge-l']['f']\u001B[39;00m\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_done(client_id, step, batch,\n\u001B[1;32m    115\u001B[0m                {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mfloat\u001B[39m(avg_loss \u001B[38;5;241m/\u001B[39m batch_num)})\n\u001B[1;32m    116\u001B[0m \u001B[38;5;66;03m# , \"self\": float(avg_self_rouge / batch_num),\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;66;03m#  \"self_pt\": float(avg_self_rouge_pt / batch_num)})  # Collect gradients\u001B[39;00m\n\u001B[1;32m    118\u001B[0m pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/home/project/SFL-LLM/sfl/simulator/strategy.py:55\u001B[0m, in \u001B[0;36mFLStrategy.step_done\u001B[0;34m(self, client_id, mini_step, batch, logs)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep_done\u001B[39m(\u001B[38;5;28mself\u001B[39m, client_id, mini_step, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 55\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimulator\u001B[38;5;241m.\u001B[39m_client_one_step_done(client_id, mini_step, batch, logs)\n",
      "File \u001B[0;32m/home/project/SFL-LLM/sfl/simulator/simulator.py:274\u001B[0m, in \u001B[0;36mSFLSimulator._client_one_step_done\u001B[0;34m(self, client_id, mini_step, batch, logs)\u001B[0m\n\u001B[1;32m    270\u001B[0m     logs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    271\u001B[0m report \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mglobal_step\u001B[39m\u001B[38;5;124m'\u001B[39m: global_step, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclient\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclient_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_global_round\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_global_round,\n\u001B[1;32m    272\u001B[0m           \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclient\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclient_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_local_epoch\u001B[39m\u001B[38;5;124m'\u001B[39m: local_epoch,\n\u001B[1;32m    273\u001B[0m           \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclient\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclient_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_local_step\u001B[39m\u001B[38;5;124m'\u001B[39m: local_step}\n\u001B[0;32m--> 274\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mcallback_intermediate_result(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_global_round,\n\u001B[1;32m    275\u001B[0m                                            client_id,\n\u001B[1;32m    276\u001B[0m                                            local_epoch,\n\u001B[1;32m    277\u001B[0m                                            local_step,\n\u001B[1;32m    278\u001B[0m                                            b2tr_inter, tr2t_inter, all_inters,\n\u001B[1;32m    279\u001B[0m                                            batch, logs)\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (local_step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mclient_evaluate_freq \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mclient_evaluate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_global_round, client_id, logs)\n",
      "File \u001B[0;32m/home/project/SFL-LLM/sfl/simulator/strategy.py:136\u001B[0m, in \u001B[0;36mBaseSFLStrategy.callback_intermediate_result\u001B[0;34m(self, global_round, client_id, local_epoch, local_step, b2tr_inter, tr2t_inter, all_inter, batch, logs)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m client_id \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattack_sample_counter:\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattack_sample_counter[client_id] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 136\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msample_attacker_triggered(global_round, client_id, local_epoch, local_step, b2tr_inter, tr2t_inter,\n\u001B[1;32m    137\u001B[0m                                    all_inter,\n\u001B[1;32m    138\u001B[0m                                    batch, logs)\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key, \u001B[38;5;28mlist\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattack_all_performs[client_id]\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    140\u001B[0m         logs[key \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_avg\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m average(\u001B[38;5;28mlist\u001B[39m)\n",
      "Cell \u001B[0;32mIn[22], line 45\u001B[0m, in \u001B[0;36mQAFLStrategy.sample_attacker_triggered\u001B[0;34m(self, global_round, client_id, local_epoch, local_step, b2tr_inter, tr2t_inter, all_inter, batch, logs)\u001B[0m\n\u001B[1;32m     43\u001B[0m     gt_init \u001B[38;5;241m=\u001B[39m attacked\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdlg\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimulator\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 45\u001B[0m gt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdlg\u001B[38;5;241m.\u001B[39mfit(tr2t_inter\u001B[38;5;241m.\u001B[39mfx\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimulator\u001B[38;5;241m.\u001B[39mdevice), tr2t_inter\u001B[38;5;241m.\u001B[39mgrad\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimulator\u001B[38;5;241m.\u001B[39mdevice),\n\u001B[1;32m     46\u001B[0m                   epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdlg_epochs,\n\u001B[1;32m     47\u001B[0m                   adjust\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     48\u001B[0m                   beta\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdlg_beta,\n\u001B[1;32m     49\u001B[0m                   gt_init\u001B[38;5;241m=\u001B[39mgt_init,\n\u001B[1;32m     50\u001B[0m                   gt_reg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdlg_dra_reg,\n\u001B[1;32m     51\u001B[0m                   temp_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdlg_temp_range,\n\u001B[1;32m     52\u001B[0m                   further_ft\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdlg_further_ft,\n\u001B[1;32m     53\u001B[0m                   encoder_inter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m encoder_inter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m encoder_inter\u001B[38;5;241m.\u001B[39mfx\u001B[38;5;241m.\u001B[39mto(\n\u001B[1;32m     54\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimulator\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     55\u001B[0m                   )\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoder-decoder\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;66;03m# replace the latter half of attacked to gt\u001B[39;00m\n\u001B[1;32m     58\u001B[0m     attacked[:, \u001B[38;5;241m-\u001B[39mgt\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:, :] \u001B[38;5;241m=\u001B[39m gt\n",
      "File \u001B[0;32m/home/project/SFL-LLM/sfl/model/attacker/dlg_attacker.py:59\u001B[0m, in \u001B[0;36mDLGAttacker.fit\u001B[0;34m(self, inter, gradient, epochs, adjust, beta, lr, gt_init, gt_reg, temp_range, further_ft, **kwargs)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     58\u001B[0m     loss \u001B[38;5;241m=\u001B[39m calc_shifted_loss_logits(x, torch\u001B[38;5;241m.\u001B[39msoftmax(gt, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m---> 59\u001B[0m grad \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mgrad(loss, inter, create_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     60\u001B[0m grad_diff \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m gx, gy \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(grad, gradient\u001B[38;5;241m.\u001B[39mto(loss\u001B[38;5;241m.\u001B[39mdevice)):\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/torch/autograd/__init__.py:303\u001B[0m, in \u001B[0;36mgrad\u001B[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001B[0m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(grad_outputs_)\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 303\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    304\u001B[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001B[1;32m    305\u001B[0m         allow_unused, accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "simulator.simulate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}