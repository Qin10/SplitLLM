{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = {\n",
    "  \"client0_attacker_14_normal_step\": 0.5175706596299099,\n",
    "  \"client0_attacker_19_normal_step\": 0.5429864203393666,\n",
    "  \"client0_attacker_32_normal_step\": 0.3857142807290817,\n",
    "  \"_step\": 4249,\n",
    "  \"client0_loss\": 2.031713839054108,\n",
    "  \"client0_attacker_29_tr2t_avg\": 0.5275647235774503,\n",
    "  \"client0_attacker_8_normal_avg\": 0.6366766778182428,\n",
    "  \"client0_attacker_16_normal_step\": 0.5285769033264401,\n",
    "  \"client0_attacker_24_normal_step\": 0.544871789879511,\n",
    "  \"client0_attacker_28_normal_step\": 0.4467532417557092,\n",
    "  \"client0_test-ppl\": 14.366519927978516,\n",
    "  \"client0_attacker_0_normal_avg\": 0.5362440276624566,\n",
    "  \"client0_attacker_32_normal_avg\": 0.4366247128481753,\n",
    "  \"client0_attacker_9_normal_step\": 0.5223380441441088,\n",
    "  \"client0_attacker_34_normal_avg\": 0.31704178424232093,\n",
    "  \"client0_attacker_35_normal_avg\": 0.27924916250140014,\n",
    "  \"client0_attacker_30_normal_step\": 0.4590469049036024,\n",
    "  \"global_step\": 4249,\n",
    "  \"client0_global_round\": 0,\n",
    "  \"client0_attacker_5_b2tr_avg\": 0.6304907277186129,\n",
    "  \"client0_attacker_3_normal_avg\": 0.6183885509769569,\n",
    "  \"client0_attacker_23_normal_step\": 0.5818181768206444,\n",
    "  \"client0_attacker_31_normal_step\": 0.41103848447329144,\n",
    "  \"client0_self_pt\": 0,\n",
    "  \"client0_attacker_11_normal_avg\": 0.6377722236693276,\n",
    "  \"client0_attacker_33_normal_avg\": 0.39310278683275807,\n",
    "  \"client0_attacker_6_normal_step\": 0.5439360879591302,\n",
    "  \"client0_attacker_2_normal_avg\": 0.6089481650353057,\n",
    "  \"client0_attacker_4_normal_avg\": 0.6238578184133798,\n",
    "  \"client0_attacker_22_normal_step\": 0.5893812020286877,\n",
    "  \"client0_attacker_25_normal_step\": 0.5504761854822313,\n",
    "  \"client0_attacker_13_normal_step\": 0.5263951684539971,\n",
    "  \"client0_attacker_9_normal_avg\": 0.6384095213150243,\n",
    "  \"client0_attacker_16_normal_avg\": 0.6330719245495596,\n",
    "  \"client0_attacker_24_normal_avg\": 0.5943958147410345,\n",
    "  \"client0_attacker_26_normal_avg\": 0.5723204183075637,\n",
    "  \"client0_attacker_15_normal_step\": 0.5175706596299099,\n",
    "  \"client0_attacker_5_b2tr_step\": 0.5145243232532479,\n",
    "  \"client0_attacker_7_normal_avg\": 0.6351210251036679,\n",
    "  \"client0_attacker_12_normal_avg\": 0.6366890118070682,\n",
    "  \"client0_attacker_13_normal_avg\": 0.6347554874791649,\n",
    "  \"client0_attacker_21_normal_avg\": 0.620009580633759,\n",
    "  \"client0_attacker_25_normal_avg\": 0.5867858649221694,\n",
    "  \"client0_attacker_27_normal_avg\": 0.5616850112415854,\n",
    "  \"client0_attacker_3_normal_step\": 0.5351071642617553,\n",
    "  \"_wandb.runtime\": 1649,\n",
    "  \"client0_local_epoch\": 0,\n",
    "  \"client0_attacker_10_normal_avg\": 0.6380667878549796,\n",
    "  \"client0_attacker_20_normal_avg\": 0.624557655192967,\n",
    "  \"client0_attacker_20_normal_step\": 0.5729323258308399,\n",
    "  \"client0_attacker_21_normal_step\": 0.5688311638336314,\n",
    "  \"client0_attacker_33_normal_step\": 0.33369407870222145,\n",
    "  \"client0_attacker_34_normal_step\": 0.30359476626650117,\n",
    "  \"client0_attacker_31_normal_avg\": 0.4747830768028701,\n",
    "  \"client0_attacker_10_normal_step\": 0.5096798162960074,\n",
    "  \"client0_attacker_12_normal_step\": 0.5175706596299099,\n",
    "  \"client0_attacker_26_normal_step\": 0.5203007468834715,\n",
    "  \"_runtime\": 1651.2562370300293,\n",
    "  \"_timestamp\": 1707696679.616939,\n",
    "  \"client0_attacker_1_normal_step\": 0.5177280500885659,\n",
    "  \"client0_attacker_28_normal_avg\": 0.5459204030441271,\n",
    "  \"client0_attacker_6_normal_avg\": 0.6324742085562801,\n",
    "  \"client0_attacker_17_normal_avg\": 0.6309008512450668,\n",
    "  \"client0_attacker_18_normal_avg\": 0.6301045366130664,\n",
    "  \"client0_attacker_4_normal_step\": 0.5473022862129748,\n",
    "  \"client0_attacker_17_normal_step\": 0.5469824243357921,\n",
    "  \"client0_attacker_15_normal_avg\": 0.6324732529184328,\n",
    "  \"client0_attacker_22_normal_avg\": 0.611303527540108,\n",
    "  \"client0_attacker_23_normal_avg\": 0.6043506538926331,\n",
    "  \"client0_attacker_7_normal_step\": 0.5562817669714759,\n",
    "  \"client0_self\": 0.0005098648707545071,\n",
    "  \"client0_local_step\": 4249,\n",
    "  \"client0_attacker_8_normal_step\": 0.5549242374281007,\n",
    "  \"client0_attacker_29_tr2t_step\": 0.454184699192842,\n",
    "  \"client0_attacker_2_normal_step\": 0.5012778336386043,\n",
    "  \"client0_attacker_11_normal_step\": 0.5135746556334841,\n",
    "  \"client0_attacker_0_normal_step\": 0.5027100221139359,\n",
    "  \"client0_attacker_14_normal_avg\": 0.6337987627417009,\n",
    "  \"client0_attacker_35_normal_step\": 0.2107142807178891,\n",
    "  \"client0_attacker_27_normal_step\": 0.5097402547483976,\n",
    "  \"client0_attacker_1_normal_avg\": 0.5966522677713505,\n",
    "  \"client0_attacker_19_normal_avg\": 0.627233252992626,\n",
    "  \"client0_attacker_30_normal_avg\": 0.5104403879249436,\n",
    "  \"client0_attacker_18_normal_step\": 0.5510835863330007\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from sfl.config import FLConfig\n",
    "from sfl.utils.exp import get_model_and_tokenizer\n",
    "config = FLConfig(collect_intermediates=True,\n",
    "                  global_round=4,\n",
    "                  client_evaluate_freq=500,\n",
    "                  client_epoch=1,  # 每轮联邦每个Client训2轮\n",
    "                  split_point_1=6,\n",
    "                  split_point_2=30,  # [0,1 | 2,3,.... 29| 30, 31]\n",
    "                  use_lora_at_trunk=True,  # 在trunk部分使用LoRA\n",
    "                  use_lora_at_top=True,\n",
    "                  use_lora_at_bottom=True,\n",
    "                  top_and_bottom_from_scratch='False',  # top和bottom都不采用预训练参数.\n",
    "                  noise_mode=\"none\",\n",
    "                  noise_scale_dxp=0,  # 噪声大小,\n",
    "                  batch_size=2,\n",
    "                  dataset_type='train'\n",
    "                  )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassificationSplitModel were not initialized from the model checkpoint at /root/autodl-tmp/sfl/models/FacebookAI/roberta-large/ and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model, _ = get_model_and_tokenizer('roberta-large', load_bits=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.embeddings.word_embeddings.weight torch.Size([50265, 1024])\n",
      "roberta.embeddings.position_embeddings.weight torch.Size([514, 1024])\n",
      "roberta.embeddings.token_type_embeddings.weight torch.Size([1, 1024])\n",
      "roberta.embeddings.LayerNorm.weight torch.Size([1024])\n",
      "roberta.embeddings.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.0.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.0.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.0.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.0.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.0.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.0.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.0.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.1.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.1.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.1.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.1.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.1.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.1.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.1.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.2.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.2.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.2.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.2.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.2.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.2.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.2.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.3.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.3.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.3.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.3.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.3.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.3.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.3.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.4.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.4.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.4.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.4.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.4.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.4.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.4.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.5.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.5.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.5.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.5.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.5.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.5.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.5.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.6.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.6.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.6.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.6.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.6.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.6.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.6.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.7.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.7.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.7.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.7.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.7.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.7.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.7.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.8.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.8.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.8.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.8.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.8.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.8.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.8.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.9.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.9.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.9.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.9.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.9.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.9.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.9.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.10.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.10.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.10.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.10.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.10.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.10.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.10.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.11.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.11.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.11.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.11.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.11.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.11.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.11.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.12.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.12.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.12.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.12.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.12.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.12.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.12.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.12.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.13.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.13.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.13.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.13.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.13.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.13.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.13.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.13.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.14.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.14.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.14.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.14.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.14.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.14.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.14.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.14.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.15.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.15.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.15.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.15.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.15.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.15.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.15.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.15.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.16.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.16.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.16.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.16.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.16.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.16.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.16.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.16.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.17.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.17.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.17.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.17.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.17.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.17.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.17.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.17.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.18.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.18.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.18.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.18.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.18.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.18.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.18.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.18.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.19.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.19.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.19.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.19.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.19.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.19.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.19.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.19.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.20.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.20.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.20.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.20.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.20.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.20.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.20.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.20.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.21.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.21.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.21.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.21.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.21.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.21.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.21.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.21.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.22.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.22.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.22.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.22.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.22.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.22.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.22.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.22.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.23.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.23.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.23.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.23.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.23.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.23.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.23.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.23.output.LayerNorm.bias torch.Size([1024])\n",
      "classifier.dense.weight torch.Size([1024, 1024])\n",
      "classifier.dense.bias torch.Size([1024])\n",
      "classifier.out_proj.weight torch.Size([2, 1024])\n",
      "classifier.out_proj.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for nm,p in model.named_parameters():\n",
    "    print(nm, p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sfl.utils.exp import get_dlg_attacker\n",
    "tmp_model, _ = get_model_and_tokenizer('llama2', load_bits=32)\n",
    "tmp_model.config_sfl(config)\n",
    "dlg = get_dlg_attacker(tmp_model)\n",
    "del tmp_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sfl.utils.exp import get_model_and_tokenizer\n",
    "\n",
    "model, tokenizer = get_model_and_tokenizer('llama2', load_bits=4)\n",
    "\n",
    "model.config_sfl(config)\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fl_config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#\n",
    "# ts = get_output(\"test\", tokenizer, model)\n",
    "# # print(ts)\n",
    "# dlg = get_dlg_attacker(model)\n",
    "# model = model.convert_to_lora_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sfl.config import DRAConfig\n",
    "from sfl.utils.exp import get_dra_attacker\n",
    "\n",
    "atk_cfg = DRAConfig(target_model_name='llama2', target_dataset='sanitized', target_sps='6-6', train_label='val', target_model_load_bits=4)\n",
    "atk, _ = get_dra_attacker(atk_cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AdamW\n",
    "from sfl.utils.model import evaluate_attacker_rouge\n",
    "from sfl.utils.exp import get_dataset_class\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "client_ids = ['0']\n",
    "\n",
    "dataset_cls = get_dataset_class('sanitized')\n",
    "dataset = dataset_cls(tokenizer=tokenizer, client_ids=client_ids)\n",
    "test_loader = dataset.get_dataloader_unsliced(2, 'train', shrink_frac=0.2)\n",
    "\n",
    "avg_rouge = 0\n",
    "avg_rouge_dlg = 0\n",
    "step = 0\n",
    "opt = AdamW(model.parameters(), lr=1e-5)\n",
    "config.noise_mode = 'dxp'\n",
    "config.noise_scale = 1000.0\n",
    "model.config_sfl(config)\n",
    "\n",
    "dlg.to(model.device)\n",
    "atk.to(model.device)\n",
    "with tqdm_notebook(total=len(test_loader)) as pbar:\n",
    "  for batch in test_loader:\n",
    "    opt.zero_grad()\n",
    "    input_ids = batch['input_ids'].to(model.device)\n",
    "    o1 = model(input_ids, batch['input_att_mask'].to(model.device), labels=input_ids)\n",
    "    # o2 = dlg(tr2t.fx.to(model.device))\n",
    "    # print(o1)\n",
    "    o1.loss.backward()\n",
    "    b2tr, tr2t, all = model.get_all_inter()\n",
    "    opt.step()\n",
    "    pred = atk(b2tr.fx.to(model.device))\n",
    "    # print(batch['input_text'][0])\n",
    "    gt = dlg.fit(tr2t.fx.to(model.device), tr2t.grad.to(model.device), epochs=20, gt_init=pred)\n",
    "    # gt_texts = [tokenizer.decode(g.argmax(-1), skip_special_tokens=True) for g in gt]\n",
    "    avg_rouge += evaluate_attacker_rouge(tokenizer, pred, batch)['rouge-l']['f']\n",
    "    avg_rouge_dlg += evaluate_attacker_rouge(tokenizer, gt, batch)['rouge-l']['f']\n",
    "    step += 1\n",
    "    pbar.set_postfix({'dra_rouge': avg_rouge / step, 'dlg_rouge':avg_rouge_dlg/step})\n",
    "    pbar.update()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sfl.utils.exp import add_sfl_params\n",
    "import argparse\n",
    "from typing import Any\n",
    "from sfl.utils.model import Intermediate\n",
    "from sfl.simulator.strategy import BaseSFLStrategy\n",
    "from sfl.simulator.simulator import SFLSimulator\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "add_sfl_params(parser)\n",
    "args = parser.parse_args({})\n",
    "\n",
    "args.log_to_wandb = False\n",
    "args.dlg_epochs = 30\n",
    "args.dlg_init_with_dra = True\n",
    "\n",
    "# 定义Client本地学习策略\n",
    "class QAFLStrategy(BaseSFLStrategy):\n",
    "\n",
    "\n",
    "    def sample_attacker_triggered(self, global_round, client_id, local_epoch, local_step,\n",
    "                                  b2tr_inter: Intermediate, tr2t_inter: Intermediate,\n",
    "                                  all_inter: dict[Any, Intermediate],\n",
    "                                  batch, logs):\n",
    "        encoder_inter = all_inter.get('encoder', None)\n",
    "        with torch.no_grad():\n",
    "            for type, atk in zip(['b2tr', 'tr2t'], [self.dra1, self.dra2]):\n",
    "                if atk is None:\n",
    "                    continue\n",
    "                atk.to(self.simulator.device)\n",
    "                inter = b2tr_inter if type == 'b2tr' else tr2t_inter\n",
    "                if self.llm.type == 'encoder-decoder':\n",
    "                    attacked = atk(torch.concat([encoder_inter.fx.to(\n",
    "                        self.simulator.device), inter.fx.to(atk.device)], dim=1))\n",
    "                else:\n",
    "                    attacked = atk(inter.fx.to(atk.device))\n",
    "                rouge_res = calculate_rouge(self.tokenizer, attacked, batch['input_text'])\n",
    "                self.log_to_sample_result(client_id, f'attacker_{type}', rouge_res['rouge-l']['f'])\n",
    "                self.log_to_all_result(client_id, f'attacker_{type}', rouge_res['rouge-l']['f'])\n",
    "                logs[f'attacker_{type}_step'] = rouge_res['rouge-l']['f']\n",
    "        gt_init = None\n",
    "        if self.args.dlg_init_with_dra:\n",
    "            gt_init = attacked\n",
    "        self.dlg.to(self.simulator.device)\n",
    "        gt = self.dlg.fit(tr2t_inter.fx.to(self.simulator.device), tr2t_inter.grad.to(self.simulator.device),\n",
    "                          epochs=self.args.dlg_epochs,\n",
    "                          adjust=False,\n",
    "                          beta=self.args.dlg_beta,\n",
    "                          gt_init=gt_init,\n",
    "                          gt_reg=self.args.dlg_dra_reg,\n",
    "                          temp_range=self.args.dlg_temp_range,\n",
    "                          further_ft=self.args.dlg_further_ft,\n",
    "                          encoder_inter=None if encoder_inter is None else encoder_inter.fx.to(\n",
    "                              self.simulator.device)\n",
    "                          )\n",
    "        if self.llm.type == 'encoder-decoder':\n",
    "            # replace the latter half of attacked to gt\n",
    "            attacked[:, -gt.shape[1]:, :] = gt\n",
    "            rouge = calculate_rouge(self.tokenizer, attacked, batch['input_text'])\n",
    "        else:\n",
    "            rouge = calculate_rouge(self.tokenizer, gt, batch['input_text'])\n",
    "        self.log_to_sample_result(client_id, 'tag_rouge_lf', rouge['rouge-l']['f'])\n",
    "        self.log_to_all_result(client_id, 'tag_rouge_lf', rouge['rouge-l']['f'])\n",
    "        print(self.attack_all_performs)\n",
    "\n",
    "\n",
    "\n",
    "simulator = SFLSimulator(client_ids=client_ids,\n",
    "                             strategy=QAFLStrategy(args, model, tokenizer, test_loader, atk, None,dlg),\n",
    "                             llm=model,\n",
    "                             tokenizer=tokenizer,\n",
    "                             dataset=dataset, config=config, args=args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulator.simulate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 生成SensMarked数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw = pd.read_csv('/home/project/SFL-LLM/sanitized_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              sani_label  \\\n0      <PERSON> attended the press conference to rais...   \n1      The <DATE>, who joined from <ORG> for £<MONEY>...   \n2      <ORG> slipped to 47-4 but <PERSON> led a recov...   \n3      <ORG> have  agreed a deal to loan <NORP> inter...   \n4      The <DATE> announced the ban after scoring in ...   \n...                                                  ...   \n19660  The <NORP> champions take on the <NORP> in <GP...   \n19661  (<ORG>) -- He's the king of cool but <GPE> sno...   \n19662  <PERSON>, <DATE>, is a doubt for <ORG>' Six Na...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . <PERSON> . An expensive delicacy, most pe...   \n\n                                        sani_label_trans  \\\n0      <PERSON>参加了新闻发布会，他对比赛官员<PERSON>提出了关切，而不是派遣教练<P...   \n1      这位于<DATE>从<ORG>以£<MONEY>的价格加盟的球员，曾在<DATE>为<ORG...   \n2      <ORG>滑到了47-4，但<PERSON>以96分不出的成绩带领球队恢复了局面。<PERS...   \n3      <ORG>已经同意将<NORP>国际后卫<PERSON>租借给陷入困境的<ORG>，俱乐部已...   \n4      <DATE>在<PERSON>在球队3-0的世界杯预选赛胜利后得分后宣布了禁令。一份广播报道...   \n...                                                  ...   \n19660  <NORP>冠军将在<GPE>的比赛中迎战<NORP>，他们希望能够锁定一个晋级八强的名额。...   \n19661  (<ORG>) - 他是酷的王者，但<GPE>滑雪板明星<PERSON>不会在索契<DATE...   \n19662  <PERSON>，<DATE>，在对阵<GPE>的六国赛比赛中因脚踝受伤而一瘸一拐地离场。在...   \n19663  (CNN)据<ORG>报道，一艘货船在<GPE>海岸翻覆后，8名船员失踪。<ORG>表示，搜...   \n19664  由<PERSON>。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但是一位厨师更进一步，...   \n\n                                                  entity  \\\n0      ['Chris Kendall', 'Widnes', 'today', 'Monday',...   \n1      ['Derby', 'a great season', '3', 'Curtis Davie...   \n2      ['Lewis Hill', 'Leicestershire', 'Ned Eckersle...   \n3      ['Spartak Moscow', 'Italian', 'Milan', 'Sparta...   \n4      ['Argentina', 'Colombia', 'Lavezzi', 'Ezequiel...   \n...                                                  ...   \n19660  ['South Korea', 'Africa', 'Costa Rica', '[Jurg...   \n19661  ['Norway', 'Team USA', 'Finnish', 'U.S.', 'Tue...   \n19662  ['Sunday', 'Wales', 'Priestland', 'Ireland', '...   \n19663  ['Sunday', 'England', 'RNLI', 'Southampton', '...   \n19664  ['Jennifer Smith', 'Huang', 'Huang Mingbo', 'F...   \n\n                                                 content  \\\n0      Beaumont attended the press conference to rais...   \n1      The 24-year-old, who joined from Liverpool for...   \n2      Derbyshire slipped to 47-4 but Alex Hughes led...   \n3      Spartak Moscow have  agreed a deal to loan Ita...   \n4      The 29-year-old announced the ban after scorin...   \n...                                                  ...   \n19660  The African champions take on the Europeans in...   \n19661  (CNN) -- He's the king of cool but U.S. snowbo...   \n19662  Biggar, 26, is a doubt for Wales' Six Nations ...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . Jennifer Smith . An expensive delicacy, m...   \n\n                                               sani_gpt4  \\\n0      John Smith attended the press conference to ra...   \n1      The 30-year-old, who joined from Manchester fo...   \n2      Yorkshire slipped to 47-4 but John Smith led a...   \n3      Barcelona FC have agreed a deal to loan Spanis...   \n4      The 35-year-old announced the ban after scorin...   \n...                                                  ...   \n19660  The Asian champions take on the Americans in T...   \n19661  (BBC) -- He's the emperor of cool but Canadian...   \n19662  Hudson, 32, is a doubt for France's Six Nation...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . Emily Johnson . An expensive delicacy, mo...   \n\n                                         sani_gpt4_trans  \\\n0      约翰·史密斯参加了新闻发布会，向比赛官员迈克·约翰逊表达了他对比赛失利的担忧，而不是派遣教练...   \n1      这位30岁的球员上周以700万英镑的价格从曼彻斯特加盟，他在2018-2019赛季为公牛队出...   \n2      约克郡队在比赛中一度陷入47-4的困境，但约翰·史密斯以96分不出的表现带领球队实现了反弹。...   \n3      巴塞罗那足球俱乐部已经同意将西班牙国家队后卫亚历杭德罗·费尔南德斯租借给陷入困境的皇家马德里...   \n4      这位35岁的球员在秘鲁队以3-0的比分赢得世界杯预选赛后宣布禁赛。一则广播报道声称前锋卡洛斯...   \n...                                                  ...   \n19660  亚洲冠军将在日本东京与美国队对决，他们希望能够锁定一个晋级四分之一决赛的名额。村上（Mura...   \n19661  （BBC）-- 他是酷劲十足的皇帝，但加拿大滑雪板明星约翰·多伊将不会在东京2020年的令人...   \n19662  Hudson，32岁，在对阵西班牙的比赛中因脚踝受伤而退出，成为法国对阵意大利的六国赛比赛的...   \n19663  （CNN）国际海上救援联合会周五早上表示，一艘货船在爱尔兰海岸翻覆后，有八名船员失踪。海军和...   \n19664  由艾米莉·约翰逊报道。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但一位厨师更进一步，...   \n\n                                              gpt4_trans  \n0      博蒙特参加了新闻发布会，向比赛官员克里斯·肯德尔表达了他对比赛失利的担忧，而不是派遣教练尼尔...  \n1      这位24岁的球员上个月以300万英镑的价格从利物浦加盟，他在2013-2014赛季为公羊队出...  \n2      德比郡队在比赛中一度陷入47-4的困境，但亚历克斯·休斯以96分不出的表现带领球队实现了反弹...  \n3      莫斯科斯巴达克同意将意大利国家队后卫萨尔瓦托雷·博凯蒂租借给陷入困境的AC米兰，俱乐部已经确...  \n4      这位29岁的球员在哥伦比亚队以3-0的比分赢得世界杯预选赛后宣布禁赛。一则广播报道声称前锋埃...  \n...                                                  ...  \n19660  非洲冠军将在韩国济州岛与欧洲队对决，他们希望能够锁定一个晋级四分之一决赛的名额。钱贝西（Ch...  \n19661  （CNN）-- 他是酷劲十足的国际滑雪板明星肖恩·怀特，但他将不会在索契2014年的令人生畏...  \n19662  Biggar，26岁，在对阵爱尔兰的比赛中因脚踝受伤而退出，成为威尔士对阵苏格兰的六国赛比赛...  \n19663  （CNN）周六晚间，英国皇家国家救生艇机构表示，一艘货船在苏格兰海岸翻覆后，有八名船员失踪。...  \n19664  由詹妮弗·史密斯报道。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但一位厨师更进一步，...  \n\n[19665 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sani_label</th>\n      <th>sani_label_trans</th>\n      <th>entity</th>\n      <th>content</th>\n      <th>sani_gpt4</th>\n      <th>sani_gpt4_trans</th>\n      <th>gpt4_trans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;PERSON&gt; attended the press conference to rais...</td>\n      <td>&lt;PERSON&gt;参加了新闻发布会，他对比赛官员&lt;PERSON&gt;提出了关切，而不是派遣教练&lt;P...</td>\n      <td>['Chris Kendall', 'Widnes', 'today', 'Monday',...</td>\n      <td>Beaumont attended the press conference to rais...</td>\n      <td>John Smith attended the press conference to ra...</td>\n      <td>约翰·史密斯参加了新闻发布会，向比赛官员迈克·约翰逊表达了他对比赛失利的担忧，而不是派遣教练...</td>\n      <td>博蒙特参加了新闻发布会，向比赛官员克里斯·肯德尔表达了他对比赛失利的担忧，而不是派遣教练尼尔...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The &lt;DATE&gt;, who joined from &lt;ORG&gt; for £&lt;MONEY&gt;...</td>\n      <td>这位于&lt;DATE&gt;从&lt;ORG&gt;以£&lt;MONEY&gt;的价格加盟的球员，曾在&lt;DATE&gt;为&lt;ORG...</td>\n      <td>['Derby', 'a great season', '3', 'Curtis Davie...</td>\n      <td>The 24-year-old, who joined from Liverpool for...</td>\n      <td>The 30-year-old, who joined from Manchester fo...</td>\n      <td>这位30岁的球员上周以700万英镑的价格从曼彻斯特加盟，他在2018-2019赛季为公牛队出...</td>\n      <td>这位24岁的球员上个月以300万英镑的价格从利物浦加盟，他在2013-2014赛季为公羊队出...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;ORG&gt; slipped to 47-4 but &lt;PERSON&gt; led a recov...</td>\n      <td>&lt;ORG&gt;滑到了47-4，但&lt;PERSON&gt;以96分不出的成绩带领球队恢复了局面。&lt;PERS...</td>\n      <td>['Lewis Hill', 'Leicestershire', 'Ned Eckersle...</td>\n      <td>Derbyshire slipped to 47-4 but Alex Hughes led...</td>\n      <td>Yorkshire slipped to 47-4 but John Smith led a...</td>\n      <td>约克郡队在比赛中一度陷入47-4的困境，但约翰·史密斯以96分不出的表现带领球队实现了反弹。...</td>\n      <td>德比郡队在比赛中一度陷入47-4的困境，但亚历克斯·休斯以96分不出的表现带领球队实现了反弹...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;ORG&gt; have  agreed a deal to loan &lt;NORP&gt; inter...</td>\n      <td>&lt;ORG&gt;已经同意将&lt;NORP&gt;国际后卫&lt;PERSON&gt;租借给陷入困境的&lt;ORG&gt;，俱乐部已...</td>\n      <td>['Spartak Moscow', 'Italian', 'Milan', 'Sparta...</td>\n      <td>Spartak Moscow have  agreed a deal to loan Ita...</td>\n      <td>Barcelona FC have agreed a deal to loan Spanis...</td>\n      <td>巴塞罗那足球俱乐部已经同意将西班牙国家队后卫亚历杭德罗·费尔南德斯租借给陷入困境的皇家马德里...</td>\n      <td>莫斯科斯巴达克同意将意大利国家队后卫萨尔瓦托雷·博凯蒂租借给陷入困境的AC米兰，俱乐部已经确...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The &lt;DATE&gt; announced the ban after scoring in ...</td>\n      <td>&lt;DATE&gt;在&lt;PERSON&gt;在球队3-0的世界杯预选赛胜利后得分后宣布了禁令。一份广播报道...</td>\n      <td>['Argentina', 'Colombia', 'Lavezzi', 'Ezequiel...</td>\n      <td>The 29-year-old announced the ban after scorin...</td>\n      <td>The 35-year-old announced the ban after scorin...</td>\n      <td>这位35岁的球员在秘鲁队以3-0的比分赢得世界杯预选赛后宣布禁赛。一则广播报道声称前锋卡洛斯...</td>\n      <td>这位29岁的球员在哥伦比亚队以3-0的比分赢得世界杯预选赛后宣布禁赛。一则广播报道声称前锋埃...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19660</th>\n      <td>The &lt;NORP&gt; champions take on the &lt;NORP&gt; in &lt;GP...</td>\n      <td>&lt;NORP&gt;冠军将在&lt;GPE&gt;的比赛中迎战&lt;NORP&gt;，他们希望能够锁定一个晋级八强的名额。...</td>\n      <td>['South Korea', 'Africa', 'Costa Rica', '[Jurg...</td>\n      <td>The African champions take on the Europeans in...</td>\n      <td>The Asian champions take on the Americans in T...</td>\n      <td>亚洲冠军将在日本东京与美国队对决，他们希望能够锁定一个晋级四分之一决赛的名额。村上（Mura...</td>\n      <td>非洲冠军将在韩国济州岛与欧洲队对决，他们希望能够锁定一个晋级四分之一决赛的名额。钱贝西（Ch...</td>\n    </tr>\n    <tr>\n      <th>19661</th>\n      <td>(&lt;ORG&gt;) -- He's the king of cool but &lt;GPE&gt; sno...</td>\n      <td>(&lt;ORG&gt;) - 他是酷的王者，但&lt;GPE&gt;滑雪板明星&lt;PERSON&gt;不会在索契&lt;DATE...</td>\n      <td>['Norway', 'Team USA', 'Finnish', 'U.S.', 'Tue...</td>\n      <td>(CNN) -- He's the king of cool but U.S. snowbo...</td>\n      <td>(BBC) -- He's the emperor of cool but Canadian...</td>\n      <td>（BBC）-- 他是酷劲十足的皇帝，但加拿大滑雪板明星约翰·多伊将不会在东京2020年的令人...</td>\n      <td>（CNN）-- 他是酷劲十足的国际滑雪板明星肖恩·怀特，但他将不会在索契2014年的令人生畏...</td>\n    </tr>\n    <tr>\n      <th>19662</th>\n      <td>&lt;PERSON&gt;, &lt;DATE&gt;, is a doubt for &lt;ORG&gt;' Six Na...</td>\n      <td>&lt;PERSON&gt;，&lt;DATE&gt;，在对阵&lt;GPE&gt;的六国赛比赛中因脚踝受伤而一瘸一拐地离场。在...</td>\n      <td>['Sunday', 'Wales', 'Priestland', 'Ireland', '...</td>\n      <td>Biggar, 26, is a doubt for Wales' Six Nations ...</td>\n      <td>Hudson, 32, is a doubt for France's Six Nation...</td>\n      <td>Hudson，32岁，在对阵西班牙的比赛中因脚踝受伤而退出，成为法国对阵意大利的六国赛比赛的...</td>\n      <td>Biggar，26岁，在对阵爱尔兰的比赛中因脚踝受伤而退出，成为威尔士对阵苏格兰的六国赛比赛...</td>\n    </tr>\n    <tr>\n      <th>19663</th>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>(CNN)据&lt;ORG&gt;报道，一艘货船在&lt;GPE&gt;海岸翻覆后，8名船员失踪。&lt;ORG&gt;表示，搜...</td>\n      <td>['Sunday', 'England', 'RNLI', 'Southampton', '...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>（CNN）国际海上救援联合会周五早上表示，一艘货船在爱尔兰海岸翻覆后，有八名船员失踪。海军和...</td>\n      <td>（CNN）周六晚间，英国皇家国家救生艇机构表示，一艘货船在苏格兰海岸翻覆后，有八名船员失踪。...</td>\n    </tr>\n    <tr>\n      <th>19664</th>\n      <td>By . &lt;PERSON&gt; . An expensive delicacy, most pe...</td>\n      <td>由&lt;PERSON&gt;。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但是一位厨师更进一步，...</td>\n      <td>['Jennifer Smith', 'Huang', 'Huang Mingbo', 'F...</td>\n      <td>By . Jennifer Smith . An expensive delicacy, m...</td>\n      <td>By . Emily Johnson . An expensive delicacy, mo...</td>\n      <td>由艾米莉·约翰逊报道。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但一位厨师更进一步，...</td>\n      <td>由詹妮弗·史密斯报道。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但一位厨师更进一步，...</td>\n    </tr>\n  </tbody>\n</table>\n<p>19665 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_548089/1355228985.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, row in tqdm_notebook(raw.iterrows(), total=len(raw)):\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19665 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3badd7f1c59e49ed9757fdaa0256b611"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "raw = pd.read_csv('/home/project/SFL-LLM/sanitized_data.csv')\n",
    "# take only 'content' and 'entity'\n",
    "raw = raw[['content', 'entity', 'sani_gpt4','sani_label']]\n",
    "\n",
    "\n",
    "marked_content = []\n",
    "\n",
    "for i, row in tqdm_notebook(raw.iterrows(), total=len(raw)):\n",
    "    # get the content and entity\n",
    "    data = {}\n",
    "    content = row['content']\n",
    "    entity = row['entity']\n",
    "    data['sentence'] = content\n",
    "    # print(entity)\n",
    "    entity = ast.literal_eval(entity)\n",
    "    replaced_places = []\n",
    "    for e in entity:\n",
    "        indexes = [(m.start(), m.end()) for m in re.finditer(re.escape(e), content)]\n",
    "        for idx in indexes:\n",
    "            if any([idx[0] > r[0] and idx[1] < r[1] for r in replaced_places]):\n",
    "                continue\n",
    "            content = content[:idx[0]] + '<P>' + content[idx[0]:idx[1]] + '<\\P>' + content[idx[1]:]\n",
    "            replaced_places.append(idx)\n",
    "    marked_content.append(content)\n",
    "\n",
    "df = pd.DataFrame(marked_content, columns=['marked_content'])\n",
    "new = pd.concat([raw, df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "type_labels = ['train'] * len(new)\n",
    "# randomly select 20% indexes\n",
    "all_indexes = list(range(len(new)))\n",
    "import random\n",
    "\n",
    "test_indexes = random.sample(all_indexes, int(len(new) * 0.25))\n",
    "for i in test_indexes:\n",
    "    type_labels[i] = 'test'\n",
    "\n",
    "all_indexes = list(set(all_indexes) - set(test_indexes))\n",
    "val_indexes = random.sample(all_indexes, int(len(new) * 0.15))\n",
    "for i in val_indexes:\n",
    "    type_labels[i] = 'validation'\n",
    "\n",
    "# make type_labels to dataframe and concat it with the original dataframe\n",
    "df = pd.DataFrame(type_labels, columns=['type'])\n",
    "# concat it with new\n",
    "new = pd.concat([new, df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "new.to_csv('/home/project/SFL-LLM/sensi.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 content  \\\n0      Beaumont attended the press conference to rais...   \n1      The 24-year-old, who joined from Liverpool for...   \n2      Derbyshire slipped to 47-4 but Alex Hughes led...   \n3      Spartak Moscow have  agreed a deal to loan Ita...   \n4      The 29-year-old announced the ban after scorin...   \n...                                                  ...   \n19660  The African champions take on the Europeans in...   \n19661  (CNN) -- He's the king of cool but U.S. snowbo...   \n19662  Biggar, 26, is a doubt for Wales' Six Nations ...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . Jennifer Smith . An expensive delicacy, m...   \n\n                                                  entity  \\\n0      ['Chris Kendall', 'Widnes', 'today', 'Monday',...   \n1      ['Derby', 'a great season', '3', 'Curtis Davie...   \n2      ['Lewis Hill', 'Leicestershire', 'Ned Eckersle...   \n3      ['Spartak Moscow', 'Italian', 'Milan', 'Sparta...   \n4      ['Argentina', 'Colombia', 'Lavezzi', 'Ezequiel...   \n...                                                  ...   \n19660  ['South Korea', 'Africa', 'Costa Rica', '[Jurg...   \n19661  ['Norway', 'Team USA', 'Finnish', 'U.S.', 'Tue...   \n19662  ['Sunday', 'Wales', 'Priestland', 'Ireland', '...   \n19663  ['Sunday', 'England', 'RNLI', 'Southampton', '...   \n19664  ['Jennifer Smith', 'Huang', 'Huang Mingbo', 'F...   \n\n                                               sani_gpt4  \\\n0      John Smith attended the press conference to ra...   \n1      The 30-year-old, who joined from Manchester fo...   \n2      Yorkshire slipped to 47-4 but John Smith led a...   \n3      Barcelona FC have agreed a deal to loan Spanis...   \n4      The 35-year-old announced the ban after scorin...   \n...                                                  ...   \n19660  The Asian champions take on the Americans in T...   \n19661  (BBC) -- He's the emperor of cool but Canadian...   \n19662  Hudson, 32, is a doubt for France's Six Nation...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . Emily Johnson . An expensive delicacy, mo...   \n\n                                              sani_label  \\\n0      <PERSON> attended the press conference to rais...   \n1      The <DATE>, who joined from <ORG> for £<MONEY>...   \n2      <ORG> slipped to 47-4 but <PERSON> led a recov...   \n3      <ORG> have  agreed a deal to loan <NORP> inter...   \n4      The <DATE> announced the ban after scoring in ...   \n...                                                  ...   \n19660  The <NORP> champions take on the <NORP> in <GP...   \n19661  (<ORG>) -- He's the king of cool but <GPE> sno...   \n19662  <PERSON>, <DATE>, is a doubt for <ORG>' Six Na...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . <PERSON> . An expensive delicacy, most pe...   \n\n                                          marked_content        type  \n0      <P>Beaumont<\\P> attended the press conference ...       train  \n1      The <P>24-year-old<\\P>, who joined from <P>Liv...        test  \n2      <P>Derbyshire<\\P> slipped to 47-4 but Alex <P>...       train  \n3      <P>Spartak Moscow<\\P> have  agreed a deal to l...       train  \n4      The <P>29-year-old<\\P> announced the ban after...  validation  \n...                                                  ...         ...  \n19660  The <P>Africa<\\P>n champions take on the <P>Eu...       train  \n19661  (<P>CNN<\\P>) -- He's the king of cool but <P>U...        test  \n19662  <P>Biggar<\\P>, <P>26<\\P>, is a doubt for <P>Wa...        test  \n19663  (CNN)Eight crew members are missing after a ca...       train  \n19664  By . <P>Jennifer Smith<\\P> . An expensive deli...       train  \n\n[19665 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>entity</th>\n      <th>sani_gpt4</th>\n      <th>sani_label</th>\n      <th>marked_content</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beaumont attended the press conference to rais...</td>\n      <td>['Chris Kendall', 'Widnes', 'today', 'Monday',...</td>\n      <td>John Smith attended the press conference to ra...</td>\n      <td>&lt;PERSON&gt; attended the press conference to rais...</td>\n      <td>&lt;P&gt;Beaumont&lt;\\P&gt; attended the press conference ...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The 24-year-old, who joined from Liverpool for...</td>\n      <td>['Derby', 'a great season', '3', 'Curtis Davie...</td>\n      <td>The 30-year-old, who joined from Manchester fo...</td>\n      <td>The &lt;DATE&gt;, who joined from &lt;ORG&gt; for £&lt;MONEY&gt;...</td>\n      <td>The &lt;P&gt;24-year-old&lt;\\P&gt;, who joined from &lt;P&gt;Liv...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Derbyshire slipped to 47-4 but Alex Hughes led...</td>\n      <td>['Lewis Hill', 'Leicestershire', 'Ned Eckersle...</td>\n      <td>Yorkshire slipped to 47-4 but John Smith led a...</td>\n      <td>&lt;ORG&gt; slipped to 47-4 but &lt;PERSON&gt; led a recov...</td>\n      <td>&lt;P&gt;Derbyshire&lt;\\P&gt; slipped to 47-4 but Alex &lt;P&gt;...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Spartak Moscow have  agreed a deal to loan Ita...</td>\n      <td>['Spartak Moscow', 'Italian', 'Milan', 'Sparta...</td>\n      <td>Barcelona FC have agreed a deal to loan Spanis...</td>\n      <td>&lt;ORG&gt; have  agreed a deal to loan &lt;NORP&gt; inter...</td>\n      <td>&lt;P&gt;Spartak Moscow&lt;\\P&gt; have  agreed a deal to l...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The 29-year-old announced the ban after scorin...</td>\n      <td>['Argentina', 'Colombia', 'Lavezzi', 'Ezequiel...</td>\n      <td>The 35-year-old announced the ban after scorin...</td>\n      <td>The &lt;DATE&gt; announced the ban after scoring in ...</td>\n      <td>The &lt;P&gt;29-year-old&lt;\\P&gt; announced the ban after...</td>\n      <td>validation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19660</th>\n      <td>The African champions take on the Europeans in...</td>\n      <td>['South Korea', 'Africa', 'Costa Rica', '[Jurg...</td>\n      <td>The Asian champions take on the Americans in T...</td>\n      <td>The &lt;NORP&gt; champions take on the &lt;NORP&gt; in &lt;GP...</td>\n      <td>The &lt;P&gt;Africa&lt;\\P&gt;n champions take on the &lt;P&gt;Eu...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>19661</th>\n      <td>(CNN) -- He's the king of cool but U.S. snowbo...</td>\n      <td>['Norway', 'Team USA', 'Finnish', 'U.S.', 'Tue...</td>\n      <td>(BBC) -- He's the emperor of cool but Canadian...</td>\n      <td>(&lt;ORG&gt;) -- He's the king of cool but &lt;GPE&gt; sno...</td>\n      <td>(&lt;P&gt;CNN&lt;\\P&gt;) -- He's the king of cool but &lt;P&gt;U...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>19662</th>\n      <td>Biggar, 26, is a doubt for Wales' Six Nations ...</td>\n      <td>['Sunday', 'Wales', 'Priestland', 'Ireland', '...</td>\n      <td>Hudson, 32, is a doubt for France's Six Nation...</td>\n      <td>&lt;PERSON&gt;, &lt;DATE&gt;, is a doubt for &lt;ORG&gt;' Six Na...</td>\n      <td>&lt;P&gt;Biggar&lt;\\P&gt;, &lt;P&gt;26&lt;\\P&gt;, is a doubt for &lt;P&gt;Wa...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>19663</th>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>['Sunday', 'England', 'RNLI', 'Southampton', '...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>19664</th>\n      <td>By . Jennifer Smith . An expensive delicacy, m...</td>\n      <td>['Jennifer Smith', 'Huang', 'Huang Mingbo', 'F...</td>\n      <td>By . Emily Johnson . An expensive delicacy, mo...</td>\n      <td>By . &lt;PERSON&gt; . An expensive delicacy, most pe...</td>\n      <td>By . &lt;P&gt;Jennifer Smith&lt;\\P&gt; . An expensive deli...</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>19665 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from sfl.utils.exp import get_model_and_tokenizer\n",
    "\n",
    "_, tokenizer = get_model_and_tokenizer('bert')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sfl.simulator.dataset import FedDataset\n",
    "\n",
    "\n",
    "class SanitizedFedDataset(FedDataset):\n",
    "\n",
    "    def _format(self, example):\n",
    "        return {'input': example['content'], 'entities': ast.literal_eval(example['entity'])}\n",
    "\n",
    "    def _col_fun(self, batch):\n",
    "        texts = [b['input'] for b in batch]\n",
    "        input = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "        mask = torch.zeros_like(input['input_ids'])\n",
    "        for sp, sample in enumerate(batch):\n",
    "            seq = input['input_ids'][sp].numpy().tolist()\n",
    "            r = tokenizer(sample['entities'], add_special_tokens=False)\n",
    "            for subseq in r.input_ids:\n",
    "                for i in range(len(seq) - len(subseq) + 1):\n",
    "                    if seq[i:i + len(subseq)] == subseq:\n",
    "                        mask[sp, i:i + len(subseq)] = 1\n",
    "\n",
    "        return {'input_ids': input['input_ids'],\n",
    "                'input_att_mask': input['attention_mask'],\n",
    "                'input_text': texts, 'entities': [b['entity'] for b in batch],\n",
    "                'input_santi_mask': mask}\n",
    "\n",
    "    def __init__(self, tokenizer, client_ids: list[str], ):\n",
    "        self.df = pd.read_csv('/home/project/SFL-LLM/sanitized_data_marked.csv')\n",
    "        dataset = {\n",
    "            'train': Dataset.from_pandas(self.df[self.df['type'] == 'train']),\n",
    "            'val': Dataset.from_pandas(self.df[self.df['type'] == 'val']),\n",
    "            'test': Dataset.from_pandas(self.df[self.df['type'] == 'test'])\n",
    "        }\n",
    "        super().__init__(tokenizer, client_ids, dataset, ['train', 'val', 'test'])\n",
    "\n",
    "\n",
    "ds = SanitizedFedDataset(tokenizer, ['0'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ld = ds.get_dataloader_unsliced(6, 'val')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for batch in ld:\n",
    "    # find input_ids masked by mask\n",
    "    input_ids = batch['input_ids']\n",
    "    mask = batch['input_santi_mask']\n",
    "    masked = input_ids * mask\n",
    "\n",
    "    print(tokenizer.decode(masked[0],skip_special_tokens=True))\n",
    "    print(batch['entities'][0])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from sfl.config import FLConfig\n",
    "from sfl.utils.exp import get_model_and_tokenizer\n",
    "import argparse\n",
    "\n",
    "config = FLConfig(\n",
    "    collect_intermediates=False,\n",
    "    global_round=10,\n",
    "    client_evaluate_freq=500,\n",
    "    client_epoch=1,  # 每轮联邦每个Client训2轮\n",
    "    split_point_1=6,\n",
    "    split_point_2=30,  # [0,1 | 2,3,.... 29| 30, 31]\n",
    "    use_lora_at_trunk=True,  # 在trunk部分使用LoRA\n",
    "    use_lora_at_top=True,\n",
    "    use_lora_at_bottom=False,\n",
    "    top_and_bottom_from_scratch='True',\n",
    "    attack_mode='b2tr',\n",
    "    client_steps=700\n",
    ")\n",
    "\n",
    "args = {\n",
    "    'dataset_train_frac': 1.0,\n",
    "    'dataset_test_frac': 0.1,\n",
    "    'dataset': 'piqa',\n",
    "    'model_name': 'gpt2-large',\n",
    "    'save_checkpoint': True,\n",
    "    'task_type': 'lm',\n",
    "    'attacker_freq': 10000,\n",
    "    'log_to_wandb': False\n",
    "}\n",
    "# convert to namespace\n",
    "args = argparse.Namespace(**args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model, tokenizer = get_model_and_tokenizer(args.model_name)\n",
    "model.config_sfl(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dab781f459894535af42839e1fac1b3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tok = get_model_and_tokenizer('llama2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "LlamaConfig {\n  \"_name_or_path\": \"/root/autodl-tmp/sfl/models/daryl149/llama-2-7b-chat-hf\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 2048,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"pad_token_id\": 0,\n  \"pretraining_tp\": 1,\n  \"quantization_config\": {\n    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n    \"bnb_4bit_quant_type\": \"nf4\",\n    \"bnb_4bit_use_double_quant\": true,\n    \"llm_int8_enable_fp32_cpu_offload\": false,\n    \"llm_int8_has_fp16_weight\": false,\n    \"llm_int8_skip_modules\": null,\n    \"llm_int8_threshold\": 6.0,\n    \"load_in_4bit\": false,\n    \"load_in_8bit\": true\n  },\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.31.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sfl.utils.exp import get_dataset\n",
    "from sfl.config import DRA_train_label, DRA_test_label\n",
    "\n",
    "dataset = get_dataset(args.dataset, tokenizer,client_ids=['0'],shrink_frac=0.08)\n",
    "pub_loader = dataset.get_dataloader_unsliced(16, DRA_train_label[args.dataset], args.dataset_train_frac)\n",
    "test_loader = dataset.get_dataloader_unsliced(16, DRA_test_label[args.dataset], args.dataset_test_frac)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "FSHAAttacker(\n  (f_inv): GRUDRAttacker(\n    (gru): GRU(1280, 256, batch_first=True)\n    (mlp): Linear(in_features=256, out_features=50257, bias=True)\n  )\n  (f): GRUDRAttacker(\n    (gru): GRU(50257, 256, batch_first=True)\n    (mlp): Linear(in_features=256, out_features=1280, bias=True)\n  )\n  (d): GRU(1280, 256, batch_first=True)\n  (d_mlp): Sequential(\n    (0): Linear(in_features=256, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sfl.utils.model import get_best_gpu\n",
    "from sfl.model.attacker.fsha_attacker import FSHAAttacker, AutoEncoderConfig\n",
    "\n",
    "device = get_best_gpu()\n",
    "model.to(device)\n",
    "attacker = FSHAAttacker(AutoEncoderConfig(), target_config=model.config)\n",
    "attacker.to(model.device)\n",
    "# attacker.fit_auto_encoder(model, tokenizer,pub_loader,test_loader, 50, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from sfl.utils.exp import get_fsha_attacker, DRAConfig\n",
    "#\n",
    "# attacker = get_fsha_attacker(DRAConfig(b2tr_sp=6,target_model_name='gpt2-large',target_sps='6-6', train_label='validation',dataset='piqa'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sfl/lib/python3.11/site-packages/peft/tuners/lora.py:299: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================Global Round 0=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_543624/3998992960.py:32: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm_notebook(total=config.client_steps) as pbar:\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23fe44388f9c49c582af0457669ae8b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 0 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "==================================Global Round 1=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33ccd8734cf94a6d8ef239cfbea6dece"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 1 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "==================================Global Round 2=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5aa53e3ef81456b86d02f4c9a4f36d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 2 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "==================================Global Round 3=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3afe56af7e2f4fc48844cf308300453e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 3 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "==================================Global Round 4=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7150356da7ad46489f183a0e731edbd8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 4 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "==================================Global Round 5=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "608eefaa2ee145c4bff9cf1ed1b5ea33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 5 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "==================================Global Round 6=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63024cc92c4e40f396aa941d67f37179"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 6 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "==================================Global Round 7=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccf6e22b2df540ec94da07775d7df11c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 7 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "==================================Global Round 8=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50f31a4c3f184363975d847fd71f0165"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 8 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "==================================Global Round 9=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92e8ddc0b7214c83b32657b2d23ba99b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:0.00 Bytes, downlink:0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "Global Round 9 communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n",
      "SERVER: AGGREGATION\n",
      "FL communication overhead: uplink=0.00 Bytes, downlink=0.00 Bytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sfl.simulator.simulator import SFLSimulator\n",
    "from sfl.utils.model import get_t5_input, calc_unshift_loss\n",
    "from sfl.model.attacker.fsha_attacker import FSHAAttacker\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Iterator\n",
    "from sfl.model.llm.split_model import SplitWrapperModel\n",
    "from sfl.simulator.strategy import BaseSFLStrategy\n",
    "from torch.optim import AdamW, Adam\n",
    "from tqdm import tqdm_notebook\n",
    "from sfl.utils.model import calculate_rouge\n",
    "import torch\n",
    "\n",
    "\n",
    "class FSHAStrategy(BaseSFLStrategy):\n",
    "\n",
    "    def __init__(self, args, llm, tokenizer, attacker: FSHAAttacker, pub_loader: DataLoader):\n",
    "        super().__init__(args, llm, tokenizer)\n",
    "        self.attacker = attacker\n",
    "        self.pub_loader = pub_loader\n",
    "        self.pub_loader_iter = iter(pub_loader)\n",
    "        self.optim_d = Adam(list(self.attacker.d_mlp.parameters())+list(self.attacker.d.parameters()),lr=1e-5, weight_decay=1e-6)\n",
    "        self.optim_f = Adam(list(self.attacker.f.parameters())+list(self.attacker.f_inv.parameters()),lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "    def client_step(self, client_id: str, global_round, client_epoch, llm: SplitWrapperModel, iterator: Iterator,\n",
    "                    config: FLConfig):\n",
    "        optimizer = Adam([p for _, p in llm.get_top_params()], lr=5e-7, weight_decay=1e-7)\n",
    "        # optimizer = AdamW([p for _, p in llm.get_top_params()], lr=3e-7, weight_decay=1e-4)\n",
    "        avg_d_loss = 0\n",
    "        avg_f_loss = 0\n",
    "        avg_rouge_lf = 0\n",
    "        batch_num = 0\n",
    "        with tqdm_notebook(total=config.client_steps) as pbar:\n",
    "            for step, batch in enumerate(iterator):\n",
    "                if llm.type == 'encoder-decoder':\n",
    "                    outputs = llm(**get_t5_input(batch, self.tokenizer, llm.device))\n",
    "                else:\n",
    "                    input_ids = batch['input_ids'].to(llm.device)\n",
    "                    attention_mask = batch['input_att_mask'].to(llm.device)\n",
    "                    labels = input_ids\n",
    "                    if 'labels' in batch and self.task_type == 'clsf':\n",
    "                        labels = batch['labels'].to(llm.device)\n",
    "                    outputs = llm(input_ids=input_ids, labels=labels, attention_mask=attention_mask)\n",
    "                z_priv = outputs\n",
    "                try:\n",
    "                    x_pub = next(self.pub_loader_iter)\n",
    "                except StopIteration:\n",
    "                    self.pub_loader_iter = iter(self.pub_loader)\n",
    "                    x_pub = next(self.pub_loader_iter)\n",
    "                x_pub = x_pub['input_ids'].to(llm.device)\n",
    "                z_pub = self.attacker.f_forward(x_pub)\n",
    "                adv_priv_logits = self.attacker.d_forward(z_priv)\n",
    "                adv_pub_logits = self.attacker.d_forward(z_pub)\n",
    "                # print('pub', adv_pub_logits, 'priv', adv_priv_logits)\n",
    "\n",
    "                # f_loss = torch.mean(adv_priv_logits)\n",
    "                f_loss = torch.mean(\n",
    "                    torch.binary_cross_entropy_with_logits(adv_priv_logits, torch.ones_like(adv_priv_logits)))\n",
    "\n",
    "                d_loss_true = torch.mean(\n",
    "                    torch.binary_cross_entropy_with_logits(adv_pub_logits, torch.ones_like(adv_pub_logits)\n",
    "                                                           ))\n",
    "                d_loss_fake = torch.mean(\n",
    "                    torch.binary_cross_entropy_with_logits(adv_priv_logits, torch.zeros_like(adv_priv_logits)))\n",
    "                d_loss = (d_loss_true + d_loss_fake) / 2\n",
    "                # d_loss_true = torch.mean(adv_pub_logits)\n",
    "                # d_loss_fake = -torch.mean(adv_priv_logits)\n",
    "                # # print(d_loss_true, d_loss_fake)\n",
    "                # d_loss = d_loss_true + d_loss_fake\n",
    "                rec_x_pub = self.attacker.f_inv_forward(z_pub)\n",
    "                inv_loss = calc_unshift_loss(rec_x_pub, x_pub)\n",
    "\n",
    "                rec_x_priv = self.attacker.f_inv_forward(z_priv)\n",
    "                recover_rouge = calculate_rouge(self.tokenizer, rec_x_priv, batch['input_text'])\n",
    "                avg_rouge_lf += recover_rouge['rouge-l']['f']\n",
    "\n",
    "                # (d_loss+f_loss).backward()\n",
    "                self.optim_d.zero_grad()\n",
    "                self.optim_f.zero_grad()\n",
    "                (inv_loss+d_loss).backward(retain_graph=True)\n",
    "                self.optim_d.step()\n",
    "                self.optim_f.step()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                f_grad = torch.autograd.grad(f_loss, z_priv)[0]\n",
    "                z_priv.backward(f_grad)\n",
    "                optimizer.step()\n",
    "                # optimizer.step()\n",
    "\n",
    "                batch_num += 1\n",
    "                avg_d_loss += d_loss.detach().cpu().item()\n",
    "                avg_f_loss += f_loss.detach().cpu().item()\n",
    "                pbar.set_description(\n",
    "                    f'Client {client_id} HIJACK Epoch {client_epoch} Step {self.simulator.get_current_step(client_id, step)} D_Loss {d_loss.item():.3f}, F_Loss {f_loss.item():.3f}, Rouge_L_F {recover_rouge[\"rouge-l\"][\"f\"]:.3f}, Avg_Rouge_L_F {avg_rouge_lf / (step + 1):.3f}')\n",
    "                self.step_done(client_id, step, batch,\n",
    "                               {\"d_loss\": float(avg_d_loss / batch_num),\n",
    "                                \"f_loss\": float(avg_f_loss / batch_num),\n",
    "                                \"rouge_l_f\": float(avg_rouge_lf / batch_num),\n",
    "                                })\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "attacker.to(model.device)\n",
    "attacker.train()\n",
    "simulator = SFLSimulator(client_ids=['0'],\n",
    "                         strategy=FSHAStrategy(args, model, tokenizer, attacker, pub_loader),\n",
    "                         llm=model,\n",
    "                         tokenizer=tokenizer,\n",
    "                         dataset=dataset, config=config, args=args)\n",
    "\n",
    "simulator.simulate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}