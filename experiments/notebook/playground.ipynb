{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sfl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m      4\u001B[0m sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../..\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msfl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FLConfig\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01margparse\u001B[39;00m\n\u001B[1;32m      8\u001B[0m config \u001B[38;5;241m=\u001B[39m FLConfig(\n\u001B[1;32m      9\u001B[0m     collect_intermediates\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     10\u001B[0m     global_round\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     20\u001B[0m     client_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m700\u001B[39m\n\u001B[1;32m     21\u001B[0m )\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'sfl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from sfl.config import FLConfig\n",
    "import argparse\n",
    "\n",
    "config = FLConfig(\n",
    "    collect_intermediates=False,\n",
    "    global_round=10,\n",
    "    client_evaluate_freq=500,\n",
    "    client_epoch=1,  # 每轮联邦每个Client训2轮\n",
    "    split_point_1=6,\n",
    "    split_point_2=30,  # [0,1 | 2,3,.... 29| 30, 31]\n",
    "    use_lora_at_trunk=True,  # 在trunk部分使用LoRA\n",
    "    use_lora_at_top=True,\n",
    "    use_lora_at_bottom=False,\n",
    "    top_and_bottom_from_scratch='True',\n",
    "    attack_mode='b2tr',\n",
    "    client_steps=700\n",
    ")\n",
    "\n",
    "args = {\n",
    "    'dataset_train_frac': 1.0,\n",
    "    'dataset_test_frac': 0.1,\n",
    "    'dataset': 'piqa',\n",
    "    'model_name': 'llama2',\n",
    "    'save_checkpoint': True,\n",
    "    'task_type': 'lm',\n",
    "    'attacker_freq': 10,\n",
    "    'attacker_samples':2,\n",
    "    'log_to_wandb': False\n",
    "}\n",
    "# convert to namespace\n",
    "args = argparse.Namespace(**args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sfl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msfl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DRAConfig\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msfl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_dra_attacker\n\u001B[1;32m      4\u001B[0m atk_cfg \u001B[38;5;241m=\u001B[39m DRAConfig(target_model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mllama2\u001B[39m\u001B[38;5;124m'\u001B[39m, target_dataset\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msanitized\u001B[39m\u001B[38;5;124m'\u001B[39m, target_sps\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m6-6\u001B[39m\u001B[38;5;124m'\u001B[39m, train_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m, target_model_load_bits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'sfl'"
     ]
    }
   ],
   "source": [
    "from sfl.config import DRAConfig\n",
    "from sfl.utils.exp import get_dra_attacker\n",
    "\n",
    "atk_cfg = DRAConfig(target_model_name='llama2', target_dataset='sanitized', target_sps='6-6', train_label='val', target_model_load_bits=4)\n",
    "atk, _ = get_dra_attacker(atk_cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AdamW\n",
    "from sfl.utils.model import evaluate_attacker_rouge\n",
    "from sfl.utils.exp import get_dataset_class\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "client_ids = ['0']\n",
    "\n",
    "dataset_cls = get_dataset_class('sanitized')\n",
    "dataset = dataset_cls(tokenizer=tokenizer, client_ids=client_ids)\n",
    "test_loader = dataset.get_dataloader_unsliced(2, 'train', shrink_frac=0.2)\n",
    "\n",
    "avg_rouge = 0\n",
    "avg_rouge_dlg = 0\n",
    "step = 0\n",
    "opt = AdamW(model.parameters(), lr=1e-5)\n",
    "config.noise_mode = 'dxp'\n",
    "config.noise_scale = 1000.0\n",
    "model.config_sfl(config)\n",
    "\n",
    "dlg.to(model.device)\n",
    "atk.to(model.device)\n",
    "with tqdm_notebook(total=len(test_loader)) as pbar:\n",
    "  for batch in test_loader:\n",
    "    opt.zero_grad()\n",
    "    input_ids = batch['input_ids'].to(model.device)\n",
    "    o1 = model(input_ids, batch['input_att_mask'].to(model.device), labels=input_ids)\n",
    "    # o2 = dlg(tr2t.fx.to(model.device))\n",
    "    # print(o1)\n",
    "    o1.loss.backward()\n",
    "    b2tr, tr2t, all = model.get_all_inter()\n",
    "    opt.step()\n",
    "    pred = atk(b2tr.fx.to(model.device))\n",
    "    # print(batch['input_text'][0])\n",
    "    gt = dlg.fit(tr2t.fx.to(model.device), tr2t.grad.to(model.device), epochs=20, gt_init=pred)\n",
    "    # gt_texts = [tokenizer.decode(g.argmax(-1), skip_special_tokens=True) for g in gt]\n",
    "    avg_rouge += evaluate_attacker_rouge(tokenizer, pred, batch)['rouge-l']['f']\n",
    "    avg_rouge_dlg += evaluate_attacker_rouge(tokenizer, gt, batch)['rouge-l']['f']\n",
    "    step += 1\n",
    "    pbar.set_postfix({'dra_rouge': avg_rouge / step, 'dlg_rouge':avg_rouge_dlg/step})\n",
    "    pbar.update()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sfl.utils.exp import add_sfl_params\n",
    "import argparse\n",
    "from typing import Any\n",
    "from sfl.utils.model import Intermediate\n",
    "from sfl.simulator.strategy import BaseSFLStrategy\n",
    "from sfl.simulator.simulator import SFLSimulator\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "add_sfl_params(parser)\n",
    "args = parser.parse_args({})\n",
    "\n",
    "args.log_to_wandb = False\n",
    "args.dlg_epochs = 30\n",
    "args.dlg_init_with_dra = True\n",
    "\n",
    "# 定义Client本地学习策略\n",
    "class QAFLStrategy(BaseSFLStrategy):\n",
    "\n",
    "\n",
    "    def sample_attacker_triggered(self, global_round, client_id, local_epoch, local_step,\n",
    "                                  b2tr_inter: Intermediate, tr2t_inter: Intermediate,\n",
    "                                  all_inter: dict[Any, Intermediate],\n",
    "                                  batch, logs):\n",
    "        encoder_inter = all_inter.get('encoder', None)\n",
    "        with torch.no_grad():\n",
    "            for type, atk in zip(['b2tr', 'tr2t'], [self.dra1, self.dra2]):\n",
    "                if atk is None:\n",
    "                    continue\n",
    "                atk.to(self.simulator.device)\n",
    "                inter = b2tr_inter if type == 'b2tr' else tr2t_inter\n",
    "                if self.llm.type == 'encoder-decoder':\n",
    "                    attacked = atk(torch.concat([encoder_inter.fx.to(\n",
    "                        self.simulator.device), inter.fx.to(atk.device)], dim=1))\n",
    "                else:\n",
    "                    attacked = atk(inter.fx.to(atk.device))\n",
    "                rouge_res = calculate_rouge(self.tokenizer, attacked, batch['input_text'])\n",
    "                self.log_to_sample_result(client_id, f'attacker_{type}', rouge_res['rouge-l']['f'])\n",
    "                self.log_to_all_result(client_id, f'attacker_{type}', rouge_res['rouge-l']['f'])\n",
    "                logs[f'attacker_{type}_step'] = rouge_res['rouge-l']['f']\n",
    "        gt_init = None\n",
    "        if self.args.dlg_init_with_dra:\n",
    "            gt_init = attacked\n",
    "        self.dlg.to(self.simulator.device)\n",
    "        gt = self.dlg.fit(tr2t_inter.fx.to(self.simulator.device), tr2t_inter.grad.to(self.simulator.device),\n",
    "                          epochs=self.args.dlg_epochs,\n",
    "                          adjust=False,\n",
    "                          beta=self.args.dlg_beta,\n",
    "                          gt_init=gt_init,\n",
    "                          gt_reg=self.args.dlg_dra_reg,\n",
    "                          temp_range=self.args.dlg_temp_range,\n",
    "                          further_ft=self.args.dlg_further_ft,\n",
    "                          encoder_inter=None if encoder_inter is None else encoder_inter.fx.to(\n",
    "                              self.simulator.device)\n",
    "                          )\n",
    "        if self.llm.type == 'encoder-decoder':\n",
    "            # replace the latter half of attacked to gt\n",
    "            attacked[:, -gt.shape[1]:, :] = gt\n",
    "            rouge = calculate_rouge(self.tokenizer, attacked, batch['input_text'])\n",
    "        else:\n",
    "            rouge = calculate_rouge(self.tokenizer, gt, batch['input_text'])\n",
    "        self.log_to_sample_result(client_id, 'tag_rouge_lf', rouge['rouge-l']['f'])\n",
    "        self.log_to_all_result(client_id, 'tag_rouge_lf', rouge['rouge-l']['f'])\n",
    "        print(self.attack_all_performs)\n",
    "\n",
    "\n",
    "\n",
    "simulator = SFLSimulator(client_ids=client_ids,\n",
    "                             strategy=QAFLStrategy(args, model, tokenizer, test_loader, atk, None,dlg),\n",
    "                             llm=model,\n",
    "                             tokenizer=tokenizer,\n",
    "                             dataset=dataset, config=config, args=args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulator.simulate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 生成SensMarked数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw = pd.read_csv('/home/project/SFL-LLM/sanitized_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              sani_label  \\\n0      <PERSON> attended the press conference to rais...   \n1      The <DATE>, who joined from <ORG> for £<MONEY>...   \n2      <ORG> slipped to 47-4 but <PERSON> led a recov...   \n3      <ORG> have  agreed a deal to loan <NORP> inter...   \n4      The <DATE> announced the ban after scoring in ...   \n...                                                  ...   \n19660  The <NORP> champions take on the <NORP> in <GP...   \n19661  (<ORG>) -- He's the king of cool but <GPE> sno...   \n19662  <PERSON>, <DATE>, is a doubt for <ORG>' Six Na...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . <PERSON> . An expensive delicacy, most pe...   \n\n                                        sani_label_trans  \\\n0      <PERSON>参加了新闻发布会，他对比赛官员<PERSON>提出了关切，而不是派遣教练<P...   \n1      这位于<DATE>从<ORG>以£<MONEY>的价格加盟的球员，曾在<DATE>为<ORG...   \n2      <ORG>滑到了47-4，但<PERSON>以96分不出的成绩带领球队恢复了局面。<PERS...   \n3      <ORG>已经同意将<NORP>国际后卫<PERSON>租借给陷入困境的<ORG>，俱乐部已...   \n4      <DATE>在<PERSON>在球队3-0的世界杯预选赛胜利后得分后宣布了禁令。一份广播报道...   \n...                                                  ...   \n19660  <NORP>冠军将在<GPE>的比赛中迎战<NORP>，他们希望能够锁定一个晋级八强的名额。...   \n19661  (<ORG>) - 他是酷的王者，但<GPE>滑雪板明星<PERSON>不会在索契<DATE...   \n19662  <PERSON>，<DATE>，在对阵<GPE>的六国赛比赛中因脚踝受伤而一瘸一拐地离场。在...   \n19663  (CNN)据<ORG>报道，一艘货船在<GPE>海岸翻覆后，8名船员失踪。<ORG>表示，搜...   \n19664  由<PERSON>。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但是一位厨师更进一步，...   \n\n                                                  entity  \\\n0      ['Chris Kendall', 'Widnes', 'today', 'Monday',...   \n1      ['Derby', 'a great season', '3', 'Curtis Davie...   \n2      ['Lewis Hill', 'Leicestershire', 'Ned Eckersle...   \n3      ['Spartak Moscow', 'Italian', 'Milan', 'Sparta...   \n4      ['Argentina', 'Colombia', 'Lavezzi', 'Ezequiel...   \n...                                                  ...   \n19660  ['South Korea', 'Africa', 'Costa Rica', '[Jurg...   \n19661  ['Norway', 'Team USA', 'Finnish', 'U.S.', 'Tue...   \n19662  ['Sunday', 'Wales', 'Priestland', 'Ireland', '...   \n19663  ['Sunday', 'England', 'RNLI', 'Southampton', '...   \n19664  ['Jennifer Smith', 'Huang', 'Huang Mingbo', 'F...   \n\n                                                 content  \\\n0      Beaumont attended the press conference to rais...   \n1      The 24-year-old, who joined from Liverpool for...   \n2      Derbyshire slipped to 47-4 but Alex Hughes led...   \n3      Spartak Moscow have  agreed a deal to loan Ita...   \n4      The 29-year-old announced the ban after scorin...   \n...                                                  ...   \n19660  The African champions take on the Europeans in...   \n19661  (CNN) -- He's the king of cool but U.S. snowbo...   \n19662  Biggar, 26, is a doubt for Wales' Six Nations ...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . Jennifer Smith . An expensive delicacy, m...   \n\n                                               sani_gpt4  \\\n0      John Smith attended the press conference to ra...   \n1      The 30-year-old, who joined from Manchester fo...   \n2      Yorkshire slipped to 47-4 but John Smith led a...   \n3      Barcelona FC have agreed a deal to loan Spanis...   \n4      The 35-year-old announced the ban after scorin...   \n...                                                  ...   \n19660  The Asian champions take on the Americans in T...   \n19661  (BBC) -- He's the emperor of cool but Canadian...   \n19662  Hudson, 32, is a doubt for France's Six Nation...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . Emily Johnson . An expensive delicacy, mo...   \n\n                                         sani_gpt4_trans  \\\n0      约翰·史密斯参加了新闻发布会，向比赛官员迈克·约翰逊表达了他对比赛失利的担忧，而不是派遣教练...   \n1      这位30岁的球员上周以700万英镑的价格从曼彻斯特加盟，他在2018-2019赛季为公牛队出...   \n2      约克郡队在比赛中一度陷入47-4的困境，但约翰·史密斯以96分不出的表现带领球队实现了反弹。...   \n3      巴塞罗那足球俱乐部已经同意将西班牙国家队后卫亚历杭德罗·费尔南德斯租借给陷入困境的皇家马德里...   \n4      这位35岁的球员在秘鲁队以3-0的比分赢得世界杯预选赛后宣布禁赛。一则广播报道声称前锋卡洛斯...   \n...                                                  ...   \n19660  亚洲冠军将在日本东京与美国队对决，他们希望能够锁定一个晋级四分之一决赛的名额。村上（Mura...   \n19661  （BBC）-- 他是酷劲十足的皇帝，但加拿大滑雪板明星约翰·多伊将不会在东京2020年的令人...   \n19662  Hudson，32岁，在对阵西班牙的比赛中因脚踝受伤而退出，成为法国对阵意大利的六国赛比赛的...   \n19663  （CNN）国际海上救援联合会周五早上表示，一艘货船在爱尔兰海岸翻覆后，有八名船员失踪。海军和...   \n19664  由艾米莉·约翰逊报道。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但一位厨师更进一步，...   \n\n                                              gpt4_trans  \n0      博蒙特参加了新闻发布会，向比赛官员克里斯·肯德尔表达了他对比赛失利的担忧，而不是派遣教练尼尔...  \n1      这位24岁的球员上个月以300万英镑的价格从利物浦加盟，他在2013-2014赛季为公羊队出...  \n2      德比郡队在比赛中一度陷入47-4的困境，但亚历克斯·休斯以96分不出的表现带领球队实现了反弹...  \n3      莫斯科斯巴达克同意将意大利国家队后卫萨尔瓦托雷·博凯蒂租借给陷入困境的AC米兰，俱乐部已经确...  \n4      这位29岁的球员在哥伦比亚队以3-0的比分赢得世界杯预选赛后宣布禁赛。一则广播报道声称前锋埃...  \n...                                                  ...  \n19660  非洲冠军将在韩国济州岛与欧洲队对决，他们希望能够锁定一个晋级四分之一决赛的名额。钱贝西（Ch...  \n19661  （CNN）-- 他是酷劲十足的国际滑雪板明星肖恩·怀特，但他将不会在索契2014年的令人生畏...  \n19662  Biggar，26岁，在对阵爱尔兰的比赛中因脚踝受伤而退出，成为威尔士对阵苏格兰的六国赛比赛...  \n19663  （CNN）周六晚间，英国皇家国家救生艇机构表示，一艘货船在苏格兰海岸翻覆后，有八名船员失踪。...  \n19664  由詹妮弗·史密斯报道。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但一位厨师更进一步，...  \n\n[19665 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sani_label</th>\n      <th>sani_label_trans</th>\n      <th>entity</th>\n      <th>content</th>\n      <th>sani_gpt4</th>\n      <th>sani_gpt4_trans</th>\n      <th>gpt4_trans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;PERSON&gt; attended the press conference to rais...</td>\n      <td>&lt;PERSON&gt;参加了新闻发布会，他对比赛官员&lt;PERSON&gt;提出了关切，而不是派遣教练&lt;P...</td>\n      <td>['Chris Kendall', 'Widnes', 'today', 'Monday',...</td>\n      <td>Beaumont attended the press conference to rais...</td>\n      <td>John Smith attended the press conference to ra...</td>\n      <td>约翰·史密斯参加了新闻发布会，向比赛官员迈克·约翰逊表达了他对比赛失利的担忧，而不是派遣教练...</td>\n      <td>博蒙特参加了新闻发布会，向比赛官员克里斯·肯德尔表达了他对比赛失利的担忧，而不是派遣教练尼尔...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The &lt;DATE&gt;, who joined from &lt;ORG&gt; for £&lt;MONEY&gt;...</td>\n      <td>这位于&lt;DATE&gt;从&lt;ORG&gt;以£&lt;MONEY&gt;的价格加盟的球员，曾在&lt;DATE&gt;为&lt;ORG...</td>\n      <td>['Derby', 'a great season', '3', 'Curtis Davie...</td>\n      <td>The 24-year-old, who joined from Liverpool for...</td>\n      <td>The 30-year-old, who joined from Manchester fo...</td>\n      <td>这位30岁的球员上周以700万英镑的价格从曼彻斯特加盟，他在2018-2019赛季为公牛队出...</td>\n      <td>这位24岁的球员上个月以300万英镑的价格从利物浦加盟，他在2013-2014赛季为公羊队出...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;ORG&gt; slipped to 47-4 but &lt;PERSON&gt; led a recov...</td>\n      <td>&lt;ORG&gt;滑到了47-4，但&lt;PERSON&gt;以96分不出的成绩带领球队恢复了局面。&lt;PERS...</td>\n      <td>['Lewis Hill', 'Leicestershire', 'Ned Eckersle...</td>\n      <td>Derbyshire slipped to 47-4 but Alex Hughes led...</td>\n      <td>Yorkshire slipped to 47-4 but John Smith led a...</td>\n      <td>约克郡队在比赛中一度陷入47-4的困境，但约翰·史密斯以96分不出的表现带领球队实现了反弹。...</td>\n      <td>德比郡队在比赛中一度陷入47-4的困境，但亚历克斯·休斯以96分不出的表现带领球队实现了反弹...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;ORG&gt; have  agreed a deal to loan &lt;NORP&gt; inter...</td>\n      <td>&lt;ORG&gt;已经同意将&lt;NORP&gt;国际后卫&lt;PERSON&gt;租借给陷入困境的&lt;ORG&gt;，俱乐部已...</td>\n      <td>['Spartak Moscow', 'Italian', 'Milan', 'Sparta...</td>\n      <td>Spartak Moscow have  agreed a deal to loan Ita...</td>\n      <td>Barcelona FC have agreed a deal to loan Spanis...</td>\n      <td>巴塞罗那足球俱乐部已经同意将西班牙国家队后卫亚历杭德罗·费尔南德斯租借给陷入困境的皇家马德里...</td>\n      <td>莫斯科斯巴达克同意将意大利国家队后卫萨尔瓦托雷·博凯蒂租借给陷入困境的AC米兰，俱乐部已经确...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The &lt;DATE&gt; announced the ban after scoring in ...</td>\n      <td>&lt;DATE&gt;在&lt;PERSON&gt;在球队3-0的世界杯预选赛胜利后得分后宣布了禁令。一份广播报道...</td>\n      <td>['Argentina', 'Colombia', 'Lavezzi', 'Ezequiel...</td>\n      <td>The 29-year-old announced the ban after scorin...</td>\n      <td>The 35-year-old announced the ban after scorin...</td>\n      <td>这位35岁的球员在秘鲁队以3-0的比分赢得世界杯预选赛后宣布禁赛。一则广播报道声称前锋卡洛斯...</td>\n      <td>这位29岁的球员在哥伦比亚队以3-0的比分赢得世界杯预选赛后宣布禁赛。一则广播报道声称前锋埃...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19660</th>\n      <td>The &lt;NORP&gt; champions take on the &lt;NORP&gt; in &lt;GP...</td>\n      <td>&lt;NORP&gt;冠军将在&lt;GPE&gt;的比赛中迎战&lt;NORP&gt;，他们希望能够锁定一个晋级八强的名额。...</td>\n      <td>['South Korea', 'Africa', 'Costa Rica', '[Jurg...</td>\n      <td>The African champions take on the Europeans in...</td>\n      <td>The Asian champions take on the Americans in T...</td>\n      <td>亚洲冠军将在日本东京与美国队对决，他们希望能够锁定一个晋级四分之一决赛的名额。村上（Mura...</td>\n      <td>非洲冠军将在韩国济州岛与欧洲队对决，他们希望能够锁定一个晋级四分之一决赛的名额。钱贝西（Ch...</td>\n    </tr>\n    <tr>\n      <th>19661</th>\n      <td>(&lt;ORG&gt;) -- He's the king of cool but &lt;GPE&gt; sno...</td>\n      <td>(&lt;ORG&gt;) - 他是酷的王者，但&lt;GPE&gt;滑雪板明星&lt;PERSON&gt;不会在索契&lt;DATE...</td>\n      <td>['Norway', 'Team USA', 'Finnish', 'U.S.', 'Tue...</td>\n      <td>(CNN) -- He's the king of cool but U.S. snowbo...</td>\n      <td>(BBC) -- He's the emperor of cool but Canadian...</td>\n      <td>（BBC）-- 他是酷劲十足的皇帝，但加拿大滑雪板明星约翰·多伊将不会在东京2020年的令人...</td>\n      <td>（CNN）-- 他是酷劲十足的国际滑雪板明星肖恩·怀特，但他将不会在索契2014年的令人生畏...</td>\n    </tr>\n    <tr>\n      <th>19662</th>\n      <td>&lt;PERSON&gt;, &lt;DATE&gt;, is a doubt for &lt;ORG&gt;' Six Na...</td>\n      <td>&lt;PERSON&gt;，&lt;DATE&gt;，在对阵&lt;GPE&gt;的六国赛比赛中因脚踝受伤而一瘸一拐地离场。在...</td>\n      <td>['Sunday', 'Wales', 'Priestland', 'Ireland', '...</td>\n      <td>Biggar, 26, is a doubt for Wales' Six Nations ...</td>\n      <td>Hudson, 32, is a doubt for France's Six Nation...</td>\n      <td>Hudson，32岁，在对阵西班牙的比赛中因脚踝受伤而退出，成为法国对阵意大利的六国赛比赛的...</td>\n      <td>Biggar，26岁，在对阵爱尔兰的比赛中因脚踝受伤而退出，成为威尔士对阵苏格兰的六国赛比赛...</td>\n    </tr>\n    <tr>\n      <th>19663</th>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>(CNN)据&lt;ORG&gt;报道，一艘货船在&lt;GPE&gt;海岸翻覆后，8名船员失踪。&lt;ORG&gt;表示，搜...</td>\n      <td>['Sunday', 'England', 'RNLI', 'Southampton', '...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>（CNN）国际海上救援联合会周五早上表示，一艘货船在爱尔兰海岸翻覆后，有八名船员失踪。海军和...</td>\n      <td>（CNN）周六晚间，英国皇家国家救生艇机构表示，一艘货船在苏格兰海岸翻覆后，有八名船员失踪。...</td>\n    </tr>\n    <tr>\n      <th>19664</th>\n      <td>By . &lt;PERSON&gt; . An expensive delicacy, most pe...</td>\n      <td>由&lt;PERSON&gt;。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但是一位厨师更进一步，...</td>\n      <td>['Jennifer Smith', 'Huang', 'Huang Mingbo', 'F...</td>\n      <td>By . Jennifer Smith . An expensive delicacy, m...</td>\n      <td>By . Emily Johnson . An expensive delicacy, mo...</td>\n      <td>由艾米莉·约翰逊报道。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但一位厨师更进一步，...</td>\n      <td>由詹妮弗·史密斯报道。一种昂贵的美味，大多数人不喜欢看到好的龙虾被浪费。但一位厨师更进一步，...</td>\n    </tr>\n  </tbody>\n</table>\n<p>19665 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_548089/1355228985.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, row in tqdm_notebook(raw.iterrows(), total=len(raw)):\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19665 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3badd7f1c59e49ed9757fdaa0256b611"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "raw = pd.read_csv('/home/project/SFL-LLM/sanitized_data.csv')\n",
    "# take only 'content' and 'entity'\n",
    "raw = raw[['content', 'entity', 'sani_gpt4','sani_label']]\n",
    "\n",
    "\n",
    "marked_content = []\n",
    "\n",
    "for i, row in tqdm_notebook(raw.iterrows(), total=len(raw)):\n",
    "    # get the content and entity\n",
    "    data = {}\n",
    "    content = row['content']\n",
    "    entity = row['entity']\n",
    "    data['sentence'] = content\n",
    "    # print(entity)\n",
    "    entity = ast.literal_eval(entity)\n",
    "    replaced_places = []\n",
    "    for e in entity:\n",
    "        indexes = [(m.start(), m.end()) for m in re.finditer(re.escape(e), content)]\n",
    "        for idx in indexes:\n",
    "            if any([idx[0] > r[0] and idx[1] < r[1] for r in replaced_places]):\n",
    "                continue\n",
    "            content = content[:idx[0]] + '<P>' + content[idx[0]:idx[1]] + '<\\P>' + content[idx[1]:]\n",
    "            replaced_places.append(idx)\n",
    "    marked_content.append(content)\n",
    "\n",
    "df = pd.DataFrame(marked_content, columns=['marked_content'])\n",
    "new = pd.concat([raw, df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "type_labels = ['train'] * len(new)\n",
    "# randomly select 20% indexes\n",
    "all_indexes = list(range(len(new)))\n",
    "import random\n",
    "\n",
    "test_indexes = random.sample(all_indexes, int(len(new) * 0.25))\n",
    "for i in test_indexes:\n",
    "    type_labels[i] = 'test'\n",
    "\n",
    "all_indexes = list(set(all_indexes) - set(test_indexes))\n",
    "val_indexes = random.sample(all_indexes, int(len(new) * 0.15))\n",
    "for i in val_indexes:\n",
    "    type_labels[i] = 'validation'\n",
    "\n",
    "# make type_labels to dataframe and concat it with the original dataframe\n",
    "df = pd.DataFrame(type_labels, columns=['type'])\n",
    "# concat it with new\n",
    "new = pd.concat([new, df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "new.to_csv('/home/project/SFL-LLM/sensi.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 content  \\\n0      Beaumont attended the press conference to rais...   \n1      The 24-year-old, who joined from Liverpool for...   \n2      Derbyshire slipped to 47-4 but Alex Hughes led...   \n3      Spartak Moscow have  agreed a deal to loan Ita...   \n4      The 29-year-old announced the ban after scorin...   \n...                                                  ...   \n19660  The African champions take on the Europeans in...   \n19661  (CNN) -- He's the king of cool but U.S. snowbo...   \n19662  Biggar, 26, is a doubt for Wales' Six Nations ...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . Jennifer Smith . An expensive delicacy, m...   \n\n                                                  entity  \\\n0      ['Chris Kendall', 'Widnes', 'today', 'Monday',...   \n1      ['Derby', 'a great season', '3', 'Curtis Davie...   \n2      ['Lewis Hill', 'Leicestershire', 'Ned Eckersle...   \n3      ['Spartak Moscow', 'Italian', 'Milan', 'Sparta...   \n4      ['Argentina', 'Colombia', 'Lavezzi', 'Ezequiel...   \n...                                                  ...   \n19660  ['South Korea', 'Africa', 'Costa Rica', '[Jurg...   \n19661  ['Norway', 'Team USA', 'Finnish', 'U.S.', 'Tue...   \n19662  ['Sunday', 'Wales', 'Priestland', 'Ireland', '...   \n19663  ['Sunday', 'England', 'RNLI', 'Southampton', '...   \n19664  ['Jennifer Smith', 'Huang', 'Huang Mingbo', 'F...   \n\n                                               sani_gpt4  \\\n0      John Smith attended the press conference to ra...   \n1      The 30-year-old, who joined from Manchester fo...   \n2      Yorkshire slipped to 47-4 but John Smith led a...   \n3      Barcelona FC have agreed a deal to loan Spanis...   \n4      The 35-year-old announced the ban after scorin...   \n...                                                  ...   \n19660  The Asian champions take on the Americans in T...   \n19661  (BBC) -- He's the emperor of cool but Canadian...   \n19662  Hudson, 32, is a doubt for France's Six Nation...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . Emily Johnson . An expensive delicacy, mo...   \n\n                                              sani_label  \\\n0      <PERSON> attended the press conference to rais...   \n1      The <DATE>, who joined from <ORG> for £<MONEY>...   \n2      <ORG> slipped to 47-4 but <PERSON> led a recov...   \n3      <ORG> have  agreed a deal to loan <NORP> inter...   \n4      The <DATE> announced the ban after scoring in ...   \n...                                                  ...   \n19660  The <NORP> champions take on the <NORP> in <GP...   \n19661  (<ORG>) -- He's the king of cool but <GPE> sno...   \n19662  <PERSON>, <DATE>, is a doubt for <ORG>' Six Na...   \n19663  (CNN)Eight crew members are missing after a ca...   \n19664  By . <PERSON> . An expensive delicacy, most pe...   \n\n                                          marked_content        type  \n0      <P>Beaumont<\\P> attended the press conference ...       train  \n1      The <P>24-year-old<\\P>, who joined from <P>Liv...        test  \n2      <P>Derbyshire<\\P> slipped to 47-4 but Alex <P>...       train  \n3      <P>Spartak Moscow<\\P> have  agreed a deal to l...       train  \n4      The <P>29-year-old<\\P> announced the ban after...  validation  \n...                                                  ...         ...  \n19660  The <P>Africa<\\P>n champions take on the <P>Eu...       train  \n19661  (<P>CNN<\\P>) -- He's the king of cool but <P>U...        test  \n19662  <P>Biggar<\\P>, <P>26<\\P>, is a doubt for <P>Wa...        test  \n19663  (CNN)Eight crew members are missing after a ca...       train  \n19664  By . <P>Jennifer Smith<\\P> . An expensive deli...       train  \n\n[19665 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>entity</th>\n      <th>sani_gpt4</th>\n      <th>sani_label</th>\n      <th>marked_content</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beaumont attended the press conference to rais...</td>\n      <td>['Chris Kendall', 'Widnes', 'today', 'Monday',...</td>\n      <td>John Smith attended the press conference to ra...</td>\n      <td>&lt;PERSON&gt; attended the press conference to rais...</td>\n      <td>&lt;P&gt;Beaumont&lt;\\P&gt; attended the press conference ...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The 24-year-old, who joined from Liverpool for...</td>\n      <td>['Derby', 'a great season', '3', 'Curtis Davie...</td>\n      <td>The 30-year-old, who joined from Manchester fo...</td>\n      <td>The &lt;DATE&gt;, who joined from &lt;ORG&gt; for £&lt;MONEY&gt;...</td>\n      <td>The &lt;P&gt;24-year-old&lt;\\P&gt;, who joined from &lt;P&gt;Liv...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Derbyshire slipped to 47-4 but Alex Hughes led...</td>\n      <td>['Lewis Hill', 'Leicestershire', 'Ned Eckersle...</td>\n      <td>Yorkshire slipped to 47-4 but John Smith led a...</td>\n      <td>&lt;ORG&gt; slipped to 47-4 but &lt;PERSON&gt; led a recov...</td>\n      <td>&lt;P&gt;Derbyshire&lt;\\P&gt; slipped to 47-4 but Alex &lt;P&gt;...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Spartak Moscow have  agreed a deal to loan Ita...</td>\n      <td>['Spartak Moscow', 'Italian', 'Milan', 'Sparta...</td>\n      <td>Barcelona FC have agreed a deal to loan Spanis...</td>\n      <td>&lt;ORG&gt; have  agreed a deal to loan &lt;NORP&gt; inter...</td>\n      <td>&lt;P&gt;Spartak Moscow&lt;\\P&gt; have  agreed a deal to l...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The 29-year-old announced the ban after scorin...</td>\n      <td>['Argentina', 'Colombia', 'Lavezzi', 'Ezequiel...</td>\n      <td>The 35-year-old announced the ban after scorin...</td>\n      <td>The &lt;DATE&gt; announced the ban after scoring in ...</td>\n      <td>The &lt;P&gt;29-year-old&lt;\\P&gt; announced the ban after...</td>\n      <td>validation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19660</th>\n      <td>The African champions take on the Europeans in...</td>\n      <td>['South Korea', 'Africa', 'Costa Rica', '[Jurg...</td>\n      <td>The Asian champions take on the Americans in T...</td>\n      <td>The &lt;NORP&gt; champions take on the &lt;NORP&gt; in &lt;GP...</td>\n      <td>The &lt;P&gt;Africa&lt;\\P&gt;n champions take on the &lt;P&gt;Eu...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>19661</th>\n      <td>(CNN) -- He's the king of cool but U.S. snowbo...</td>\n      <td>['Norway', 'Team USA', 'Finnish', 'U.S.', 'Tue...</td>\n      <td>(BBC) -- He's the emperor of cool but Canadian...</td>\n      <td>(&lt;ORG&gt;) -- He's the king of cool but &lt;GPE&gt; sno...</td>\n      <td>(&lt;P&gt;CNN&lt;\\P&gt;) -- He's the king of cool but &lt;P&gt;U...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>19662</th>\n      <td>Biggar, 26, is a doubt for Wales' Six Nations ...</td>\n      <td>['Sunday', 'Wales', 'Priestland', 'Ireland', '...</td>\n      <td>Hudson, 32, is a doubt for France's Six Nation...</td>\n      <td>&lt;PERSON&gt;, &lt;DATE&gt;, is a doubt for &lt;ORG&gt;' Six Na...</td>\n      <td>&lt;P&gt;Biggar&lt;\\P&gt;, &lt;P&gt;26&lt;\\P&gt;, is a doubt for &lt;P&gt;Wa...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>19663</th>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>['Sunday', 'England', 'RNLI', 'Southampton', '...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>(CNN)Eight crew members are missing after a ca...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>19664</th>\n      <td>By . Jennifer Smith . An expensive delicacy, m...</td>\n      <td>['Jennifer Smith', 'Huang', 'Huang Mingbo', 'F...</td>\n      <td>By . Emily Johnson . An expensive delicacy, mo...</td>\n      <td>By . &lt;PERSON&gt; . An expensive delicacy, most pe...</td>\n      <td>By . &lt;P&gt;Jennifer Smith&lt;\\P&gt; . An expensive deli...</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>19665 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "# _, tokenizer = get_model_and_tokenizer('bert')\n",
    "# model, t = get_model_and_tokenizer('flan-t5-large')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sfl.simulator.dataset import FedDataset\n",
    "\n",
    "\n",
    "class SanitizedFedDataset(FedDataset):\n",
    "\n",
    "    def _format(self, example):\n",
    "        return {'input': example['content'], 'entities': ast.literal_eval(example['entity'])}\n",
    "\n",
    "    def _col_fun(self, batch):\n",
    "        texts = [b['input'] for b in batch]\n",
    "        input = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "        mask = torch.zeros_like(input['input_ids'])\n",
    "        for sp, sample in enumerate(batch):\n",
    "            seq = input['input_ids'][sp].numpy().tolist()\n",
    "            r = tokenizer(sample['entities'], add_special_tokens=False)\n",
    "            for subseq in r.input_ids:\n",
    "                for i in range(len(seq) - len(subseq) + 1):\n",
    "                    if seq[i:i + len(subseq)] == subseq:\n",
    "                        mask[sp, i:i + len(subseq)] = 1\n",
    "\n",
    "        return {'input_ids': input['input_ids'],\n",
    "                'input_att_mask': input['attention_mask'],\n",
    "                'input_text': texts, 'entities': [b['entity'] for b in batch],\n",
    "                'input_santi_mask': mask}\n",
    "\n",
    "    def __init__(self, tokenizer, client_ids: list[str], ):\n",
    "        self.df = pd.read_csv('/home/project/SFL-LLM/sanitized_data_marked.csv')\n",
    "        dataset = {\n",
    "            'train': Dataset.from_pandas(self.df[self.df['type'] == 'train']),\n",
    "            'val': Dataset.from_pandas(self.df[self.df['type'] == 'val']),\n",
    "            'test': Dataset.from_pandas(self.df[self.df['type'] == 'test'])\n",
    "        }\n",
    "        super().__init__(tokenizer, client_ids, dataset, ['train', 'val', 'test'])\n",
    "\n",
    "\n",
    "ds = SanitizedFedDataset(tokenizer, ['0'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ld = ds.get_dataloader_unsliced(6, 'val')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for batch in ld:\n",
    "    # find input_ids masked by mask\n",
    "    input_ids = batch['input_ids']\n",
    "    mask = batch['input_santi_mask']\n",
    "    masked = input_ids * mask\n",
    "\n",
    "    print(tokenizer.decode(masked[0],skip_special_tokens=True))\n",
    "    print(batch['entities'][0])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sfl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m      4\u001B[0m sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../..\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msfl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FLConfig\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msfl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_model_and_tokenizer\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01margparse\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'sfl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from sfl.config import FLConfig\n",
    "from sfl.utils.exp import get_model_and_tokenizer\n",
    "import argparse\n",
    "\n",
    "config = FLConfig(\n",
    "    collect_intermediates=False,\n",
    "    global_round=10,\n",
    "    client_evaluate_freq=500,\n",
    "    client_epoch=1,  # 每轮联邦每个Client训2轮\n",
    "    split_point_1=6,\n",
    "    split_point_2=30,  # [0,1 | 2,3,.... 29| 30, 31]\n",
    "    use_lora_at_trunk=True,  # 在trunk部分使用LoRA\n",
    "    use_lora_at_top=True,\n",
    "    use_lora_at_bottom=False,\n",
    "    top_and_bottom_from_scratch='True',\n",
    "    attack_mode='b2tr',\n",
    "    client_steps=700\n",
    ")\n",
    "\n",
    "args = {\n",
    "    'dataset_train_frac': 1.0,\n",
    "    'dataset_test_frac': 0.1,\n",
    "    'dataset': 'piqa',\n",
    "    'model_name': 'gpt2-large',\n",
    "    'save_checkpoint': True,\n",
    "    'task_type': 'lm',\n",
    "    'attacker_freq': 10000,\n",
    "    'log_to_wandb': False\n",
    "}\n",
    "# convert to namespace\n",
    "args = argparse.Namespace(**args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model, tokenizer = get_model_and_tokenizer(args.model_name)\n",
    "model.config_sfl(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dab781f459894535af42839e1fac1b3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tok = get_model_and_tokenizer('llama2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "LlamaConfig {\n  \"_name_or_path\": \"/root/autodl-tmp/sfl/models/daryl149/llama-2-7b-chat-hf\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 2048,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"pad_token_id\": 0,\n  \"pretraining_tp\": 1,\n  \"quantization_config\": {\n    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n    \"bnb_4bit_quant_type\": \"nf4\",\n    \"bnb_4bit_use_double_quant\": true,\n    \"llm_int8_enable_fp32_cpu_offload\": false,\n    \"llm_int8_has_fp16_weight\": false,\n    \"llm_int8_skip_modules\": null,\n    \"llm_int8_threshold\": 6.0,\n    \"load_in_4bit\": false,\n    \"load_in_8bit\": true\n  },\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.31.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sfl.utils.exp import get_dataset\n",
    "from sfl.config import DRA_train_label, DRA_test_label\n",
    "\n",
    "dataset = get_dataset(args.dataset, tokenizer,client_ids=['0'],shrink_frac=0.08)\n",
    "pub_loader = dataset.get_dataloader_unsliced(16, DRA_train_label[args.dataset], args.dataset_train_frac)\n",
    "test_loader = dataset.get_dataloader_unsliced(16, DRA_test_label[args.dataset], args.dataset_test_frac)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "FSHAAttacker(\n  (f_inv): GRUDRAttacker(\n    (gru): GRU(1280, 256, batch_first=True)\n    (mlp): Linear(in_features=256, out_features=50257, bias=True)\n  )\n  (f): GRUDRAttacker(\n    (gru): GRU(50257, 256, batch_first=True)\n    (mlp): Linear(in_features=256, out_features=1280, bias=True)\n  )\n  (d): GRU(1280, 256, batch_first=True)\n  (d_mlp): Sequential(\n    (0): Linear(in_features=256, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sfl.utils.model import get_best_gpu\n",
    "from sfl.model.attacker.fsha_attacker import FSHAAttacker, AutoEncoderConfig\n",
    "\n",
    "device = get_best_gpu()\n",
    "model.to(device)\n",
    "attacker = FSHAAttacker(AutoEncoderConfig(), target_config=model.config)\n",
    "attacker.to(model.device)\n",
    "# attacker.fit_auto_encoder(model, tokenizer,pub_loader,test_loader, 50, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from sfl.utils.exp import get_fsha_attacker, DRAConfig\n",
    "#\n",
    "# attacker = get_fsha_attacker(DRAConfig(b2tr_sp=6,target_model_name='gpt2-large',target_sps='6-6', train_label='validation',dataset='piqa'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FLConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 14\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msfl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m calculate_rouge\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mFSHAStrategy\u001B[39;00m(BaseSFLStrategy):\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, args, llm, tokenizer, attacker: FSHAAttacker, pub_loader: DataLoader):\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(args, llm, tokenizer)\n",
      "Cell \u001B[0;32mIn[9], line 25\u001B[0m, in \u001B[0;36mFSHAStrategy\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_d \u001B[38;5;241m=\u001B[39m Adam(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattacker\u001B[38;5;241m.\u001B[39md_mlp\u001B[38;5;241m.\u001B[39mparameters())\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattacker\u001B[38;5;241m.\u001B[39md\u001B[38;5;241m.\u001B[39mparameters()),lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-6\u001B[39m)\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_f \u001B[38;5;241m=\u001B[39m Adam(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattacker\u001B[38;5;241m.\u001B[39mf\u001B[38;5;241m.\u001B[39mparameters())\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattacker\u001B[38;5;241m.\u001B[39mf_inv\u001B[38;5;241m.\u001B[39mparameters()),lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclient_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, client_id: \u001B[38;5;28mstr\u001B[39m, global_round, client_epoch, llm: SplitWrapperModel, iterator: Iterator,\n\u001B[0;32m---> 25\u001B[0m                 config: FLConfig):\n\u001B[1;32m     26\u001B[0m     optimizer \u001B[38;5;241m=\u001B[39m Adam([p \u001B[38;5;28;01mfor\u001B[39;00m _, p \u001B[38;5;129;01min\u001B[39;00m llm\u001B[38;5;241m.\u001B[39mget_top_params()], lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5e-7\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-7\u001B[39m)\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# optimizer = AdamW([p for _, p in llm.get_top_params()], lr=3e-7, weight_decay=1e-4)\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'FLConfig' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sfl.simulator.simulator import SFLSimulator\n",
    "from sfl.utils.model import get_t5_input, calc_unshift_loss\n",
    "from sfl.model.attacker.fsha_attacker import FSHAAttacker\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Iterator\n",
    "from sfl.model.llm.split_model import SplitWrapperModel\n",
    "from sfl.simulator.strategy import BaseSFLStrategy\n",
    "from torch.optim import Adam\n",
    "from sfl.utils.model import calculate_rouge\n",
    "\n",
    "\n",
    "class FSHAStrategy(BaseSFLStrategy):\n",
    "\n",
    "    def __init__(self, args, llm, tokenizer, attacker: FSHAAttacker, pub_loader: DataLoader):\n",
    "        super().__init__(args, llm, tokenizer)\n",
    "        self.attacker = attacker\n",
    "        self.pub_loader = pub_loader\n",
    "        self.pub_loader_iter = iter(pub_loader)\n",
    "        self.optim_d = Adam(list(self.attacker.d_mlp.parameters())+list(self.attacker.d.parameters()),lr=1e-5, weight_decay=1e-6)\n",
    "        self.optim_f = Adam(list(self.attacker.f.parameters())+list(self.attacker.f_inv.parameters()),lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "    def client_step(self, client_id: str, global_round, client_epoch, llm: SplitWrapperModel, iterator: Iterator,\n",
    "                    config: FLConfig):\n",
    "        optimizer = Adam([p for _, p in llm.get_top_params()], lr=5e-7, weight_decay=1e-7)\n",
    "        # optimizer = AdamW([p for _, p in llm.get_top_params()], lr=3e-7, weight_decay=1e-4)\n",
    "        avg_d_loss = 0\n",
    "        avg_f_loss = 0\n",
    "        avg_rouge_lf = 0\n",
    "        batch_num = 0\n",
    "        with tqdm_notebook(total=config.client_steps) as pbar:\n",
    "            for step, batch in enumerate(iterator):\n",
    "                if llm.type == 'encoder-decoder':\n",
    "                    outputs = llm(**get_t5_input(batch, self.tokenizer, llm.device))\n",
    "                else:\n",
    "                    input_ids = batch['input_ids'].to(llm.device)\n",
    "                    attention_mask = batch['input_att_mask'].to(llm.device)\n",
    "                    labels = input_ids\n",
    "                    if 'labels' in batch and self.task_type == 'clsf':\n",
    "                        labels = batch['labels'].to(llm.device)\n",
    "                    outputs = llm(input_ids=input_ids, labels=labels, attention_mask=attention_mask)\n",
    "                z_priv = outputs\n",
    "                try:\n",
    "                    x_pub = next(self.pub_loader_iter)\n",
    "                except StopIteration:\n",
    "                    self.pub_loader_iter = iter(self.pub_loader)\n",
    "                    x_pub = next(self.pub_loader_iter)\n",
    "                x_pub = x_pub['input_ids'].to(llm.device)\n",
    "                z_pub = self.attacker.f_forward(x_pub)\n",
    "                adv_priv_logits = self.attacker.d_forward(z_priv)\n",
    "                adv_pub_logits = self.attacker.d_forward(z_pub)\n",
    "                # print('pub', adv_pub_logits, 'priv', adv_priv_logits)\n",
    "\n",
    "                # f_loss = torch.mean(adv_priv_logits)\n",
    "                f_loss = torch.mean(\n",
    "                    torch.binary_cross_entropy_with_logits(adv_priv_logits, torch.ones_like(adv_priv_logits)))\n",
    "\n",
    "                d_loss_true = torch.mean(\n",
    "                    torch.binary_cross_entropy_with_logits(adv_pub_logits, torch.ones_like(adv_pub_logits)\n",
    "                                                           ))\n",
    "                d_loss_fake = torch.mean(\n",
    "                    torch.binary_cross_entropy_with_logits(adv_priv_logits, torch.zeros_like(adv_priv_logits)))\n",
    "                d_loss = (d_loss_true + d_loss_fake) / 2\n",
    "                # d_loss_true = torch.mean(adv_pub_logits)\n",
    "                # d_loss_fake = -torch.mean(adv_priv_logits)\n",
    "                # # print(d_loss_true, d_loss_fake)\n",
    "                # d_loss = d_loss_true + d_loss_fake\n",
    "                rec_x_pub = self.attacker.f_inv_forward(z_pub)\n",
    "                inv_loss = calc_unshift_loss(rec_x_pub, x_pub)\n",
    "\n",
    "                rec_x_priv = self.attacker.f_inv_forward(z_priv)\n",
    "                recover_rouge = calculate_rouge(self.tokenizer, rec_x_priv, batch['input_text'])\n",
    "                avg_rouge_lf += recover_rouge['rouge-l']['f']\n",
    "\n",
    "                # (d_loss+f_loss).backward()\n",
    "                self.optim_d.zero_grad()\n",
    "                self.optim_f.zero_grad()\n",
    "                (inv_loss+d_loss).backward(retain_graph=True)\n",
    "                self.optim_d.step()\n",
    "                self.optim_f.step()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                f_grad = torch.autograd.grad(f_loss, z_priv)[0]\n",
    "                z_priv.backward(f_grad)\n",
    "                optimizer.step()\n",
    "                # optimizer.step()\n",
    "\n",
    "                batch_num += 1\n",
    "                avg_d_loss += d_loss.detach().cpu().item()\n",
    "                avg_f_loss += f_loss.detach().cpu().item()\n",
    "                pbar.set_description(\n",
    "                    f'Client {client_id} HIJACK Epoch {client_epoch} Step {self.simulator.get_current_step(client_id, step)} D_Loss {d_loss.item():.3f}, F_Loss {f_loss.item():.3f}, Rouge_L_F {recover_rouge[\"rouge-l\"][\"f\"]:.3f}, Avg_Rouge_L_F {avg_rouge_lf / (step + 1):.3f}')\n",
    "                self.step_done(client_id, step, batch,\n",
    "                               {\"d_loss\": float(avg_d_loss / batch_num),\n",
    "                                \"f_loss\": float(avg_f_loss / batch_num),\n",
    "                                \"rouge_l_f\": float(avg_rouge_lf / batch_num),\n",
    "                                })\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "attacker.to(model.device)\n",
    "attacker.train()\n",
    "simulator = SFLSimulator(client_ids=['0'],\n",
    "                         strategy=FSHAStrategy(args, model, tokenizer, attacker, pub_loader),\n",
    "                         llm=model,\n",
    "                         tokenizer=tokenizer,\n",
    "                         dataset=dataset, config=config, args=args)\n",
    "\n",
    "simulator.simulate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from sfl.utils.exp import get_model_and_tokenizer\n",
    "from sfl.config import FLConfig\n",
    "from sfl.utils.model import get_best_gpu\n",
    "\n",
    "model, processor = get_model_and_tokenizer('vit-large')\n",
    "\n",
    "device = get_best_gpu()\n",
    "model.to(device)\n",
    "config = FLConfig(\n",
    "    collect_intermediates=False,\n",
    "    global_round=10,\n",
    "    client_evaluate_freq=500,\n",
    "    client_epoch=1,  # 每轮联邦每个Client训2轮\n",
    "    split_point_1=6,\n",
    "    split_point_2=20,  # [0,1 | 2,3,.... 29| 30, 31]\n",
    "    use_lora_at_trunk=False,  # 在trunk部分使用LoRA\n",
    "    use_lora_at_top=False,\n",
    "    use_lora_at_bottom=False,\n",
    "    top_and_bottom_from_scratch='True',\n",
    "    attack_mode='b2tr',\n",
    "    client_steps=700\n",
    ")\n",
    "\n",
    "model.config_sfl(config, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sfl/lib/python3.11/site-packages/datasets/load.py:926: FutureWarning: The repository for imagewoof contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at /root/autodl-tmp/sfl/datasets/imagewoof/imagewoof.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sfl.utils.exp import get_dataset\n",
    "\n",
    "ds = get_dataset('imagewoof',processor, client_ids=['0'], shrink_frac=0.1)\n",
    "dl = ds.get_dataloader_unsliced(64,'train', 1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sfl.model.attacker.dra_attacker import ViTDRAttacker\n",
    "from sfl.model.attacker.dra_attacker import ViTDRAttackerConfig\n",
    "\n",
    "attacker = ViTDRAttacker(ViTDRAttackerConfig(), model.config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sfl.utils.model import convert_to_image\n",
    "# train the attacker\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# attacker.to(device)\n",
    "\n",
    "def test(md, atk, image):\n",
    "    atk.to(md.device)\n",
    "    inter = md(image['input'].to(model.device))\n",
    "    image = convert_to_image(atk(inter))\n",
    "    image[0].show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_195557/4195046156.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm_notebook(total=epochs*len(dl)) as pbar:\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1420 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b341fef6dc743a49e932c258c70fc16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m----> 8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dl:\n\u001B[1;32m      9\u001B[0m         input_tensor \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     10\u001B[0m         inter \u001B[38;5;241m=\u001B[39m model(input_tensor)\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    676\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 677\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    679\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollate_fn(data)\n",
      "File \u001B[0;32m/home/project/SFL-LLM/sfl/simulator/dataset.py:52\u001B[0m, in \u001B[0;36mFedDataset.get_dataloader_unsliced.<locals>.<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m     43\u001B[0m     ds_split \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39mtrain_test_split(shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, test_size\u001B[38;5;241m=\u001B[39mfurther_test_split)\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataLoader(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pre_process(ds_split[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m], batch_size),\n\u001B[1;32m     45\u001B[0m                       collate_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_col_fun(x),\n\u001B[1;32m     46\u001B[0m                       batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     49\u001B[0m                       collate_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_col_fun(x),\n\u001B[1;32m     50\u001B[0m                       batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataLoader(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pre_process(ds, batch_size), batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m---> 52\u001B[0m                   collate_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_col_fun(x))\n",
      "File \u001B[0;32m/home/project/SFL-LLM/sfl/simulator/dataset.py:385\u001B[0m, in \u001B[0;36mImageWoofFedDataset._col_fun\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    383\u001B[0m images \u001B[38;5;241m=\u001B[39m [s[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m batch]\n\u001B[1;32m    384\u001B[0m labels \u001B[38;5;241m=\u001B[39m [s[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m batch]\n\u001B[0;32m--> 385\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer(images, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpixel_values\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m: labels,\n\u001B[1;32m    387\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m: images}\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/transformers/image_processing_utils.py:494\u001B[0m, in \u001B[0;36mBaseImageProcessor.__call__\u001B[0;34m(self, images, **kwargs)\u001B[0m\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, images, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BatchFeature:\n\u001B[1;32m    493\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 494\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(images, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/transformers/models/vit/image_processing_vit.py:262\u001B[0m, in \u001B[0;36mViTImageProcessor.preprocess\u001B[0;34m(self, images, do_resize, size, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, return_tensors, data_format, **kwargs)\u001B[0m\n\u001B[1;32m    259\u001B[0m images \u001B[38;5;241m=\u001B[39m [to_numpy_array(image) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images]\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_resize:\n\u001B[0;32m--> 262\u001B[0m     images \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresize(image\u001B[38;5;241m=\u001B[39mimage, size\u001B[38;5;241m=\u001B[39msize_dict, resample\u001B[38;5;241m=\u001B[39mresample) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images]\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_rescale:\n\u001B[1;32m    265\u001B[0m     images \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrescale(image\u001B[38;5;241m=\u001B[39mimage, scale\u001B[38;5;241m=\u001B[39mrescale_factor) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images]\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/transformers/models/vit/image_processing_vit.py:262\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    259\u001B[0m images \u001B[38;5;241m=\u001B[39m [to_numpy_array(image) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images]\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_resize:\n\u001B[0;32m--> 262\u001B[0m     images \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresize(image\u001B[38;5;241m=\u001B[39mimage, size\u001B[38;5;241m=\u001B[39msize_dict, resample\u001B[38;5;241m=\u001B[39mresample) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images]\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_rescale:\n\u001B[1;32m    265\u001B[0m     images \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrescale(image\u001B[38;5;241m=\u001B[39mimage, scale\u001B[38;5;241m=\u001B[39mrescale_factor) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images]\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/transformers/models/vit/image_processing_vit.py:126\u001B[0m, in \u001B[0;36mViTImageProcessor.resize\u001B[0;34m(self, image, size, resample, data_format, **kwargs)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheight\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m size \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwidth\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m size:\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `size` dictionary must contain the keys `height` and `width`. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msize\u001B[38;5;241m.\u001B[39mkeys()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resize(\n\u001B[1;32m    127\u001B[0m     image, size\u001B[38;5;241m=\u001B[39m(size[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheight\u001B[39m\u001B[38;5;124m\"\u001B[39m], size[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwidth\u001B[39m\u001B[38;5;124m\"\u001B[39m]), resample\u001B[38;5;241m=\u001B[39mresample, data_format\u001B[38;5;241m=\u001B[39mdata_format, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    128\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/transformers/image_transforms.py:309\u001B[0m, in \u001B[0;36mresize\u001B[0;34m(image, size, resample, reducing_gap, data_format, return_numpy)\u001B[0m\n\u001B[1;32m    307\u001B[0m height, width \u001B[38;5;241m=\u001B[39m size\n\u001B[1;32m    308\u001B[0m \u001B[38;5;66;03m# PIL images are in the format (width, height)\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m resized_image \u001B[38;5;241m=\u001B[39m image\u001B[38;5;241m.\u001B[39mresize((width, height), resample\u001B[38;5;241m=\u001B[39mresample, reducing_gap\u001B[38;5;241m=\u001B[39mreducing_gap)\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_numpy:\n\u001B[1;32m    312\u001B[0m     resized_image \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(resized_image)\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/PIL/Image.py:2174\u001B[0m, in \u001B[0;36mImage.resize\u001B[0;34m(self, size, resample, box, reducing_gap)\u001B[0m\n\u001B[1;32m   2166\u001B[0m             \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mreduce(\u001B[38;5;28mself\u001B[39m, factor, box\u001B[38;5;241m=\u001B[39mreduce_box)\n\u001B[1;32m   2167\u001B[0m         box \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2168\u001B[0m             (box[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_x,\n\u001B[1;32m   2169\u001B[0m             (box[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_y,\n\u001B[1;32m   2170\u001B[0m             (box[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_x,\n\u001B[1;32m   2171\u001B[0m             (box[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_y,\n\u001B[1;32m   2172\u001B[0m         )\n\u001B[0;32m-> 2174\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mim\u001B[38;5;241m.\u001B[39mresize(size, resample, box))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(attacker.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "with tqdm_notebook(total=epochs*len(dl)) as pbar:\n",
    "    step = 0\n",
    "    for epc in range(epochs):\n",
    "        for batch in dl:\n",
    "            input_tensor = batch['input'].to(device)\n",
    "            inter = model(input_tensor)\n",
    "            recovered = attacker(inter)\n",
    "            loss = torch.nn.functional.mse_loss(recovered, input_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            pbar.set_description(f'Epoch {epc} Step {step} Loss {loss.item()}')\n",
    "            pbar.update(1)\n",
    "            step += 1\n",
    "            # if step % 100 == 0:\n",
    "            #     test(model, attacker, sample)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "\n",
    "from sfl.utils.exp import get_dra_attacker, DRAConfig\n",
    "\n",
    "atk, _ = get_dra_attacker(\n",
    "    DRAConfig(target_model_name='vit-large', larger_better=False, target_sps='6-999', train_label='validation',\n",
    "              dataset='imagewoof', model='vit', tr2t_enable=False,prefix='gaussian:0.0001'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=224x224>",
      "image/png": "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",
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCADgAOADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCrRRRXKahRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFACHpSZpT0ptMTH0UUUhhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFACHpTO9PbpUdNEslooopFBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFACN92ou9St901F3polk1FFFIoKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooARvumou9St901F3polk1FFFIoKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooARvumou9St92ou9NEsmooopFBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFACN0qOpD0pmKaJZJRRRSKCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAEPSm049KbTEx9FFFIYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAh6UzvTz0ptNCY+iiikMKKKKACiiigAooooAKKKKACiiigAooooAKSlpKAFpKWkoAWiiigAooooAKKKKACiiigBD0plPPSmd6aEySiiikMKKKKACiiigAooooAKKKKACiiigApKWigApKWigAooooAKKKKACiiigAooooAKKKKAEPSo6kb7tR00SyWiiikUFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAI33TUOeamb7pqKmiWTUUUUigooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigBG+6ah71M33TUPemiWT0UUUigooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigBG+6aixzUp6VHimiWS0UYNLikUJRRijFABRRg0YNABRRg0YNABRRg0YNABRRg0YNABRRg0YNABRRg0YNABRRg0YNABRRg0YNABRRg0YoAKKMGjBoAKKMGjBoAQ9KbinkHFN2mmJn//2Q=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=224x224>",
      "image/png": "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",
      "image/jpeg": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=224x224>",
      "image/png": "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",
      "image/jpeg": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "test_dl = ds.get_dataloader_unsliced(3, 'train')\n",
    "num = 3\n",
    "for sample in test_dl:\n",
    "    test(model, atk, sample)\n",
    "    num -= 1\n",
    "    if num == 0:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sfl/lib/python3.11/site-packages/datasets/load.py:926: FutureWarning: The repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at /root/autodl-tmp/sfl/datasets/piqa/piqa.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from sfl.utils.exp import get_dataset, get_tokenizer\n",
    "\n",
    "tok = get_tokenizer('gpt2-large')\n",
    "tok.pad_token = tok.eos_token\n",
    "data = get_dataset('piqa',tok,[])\n",
    "dl = data.get_dataloader_unsliced(10,'test',1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[21017, 18233,    25,  1374,   284,  8335, 15317, 12656,   329,  2702,\n",
      "          1586,    30,   198, 21017, 28186,    25,   797,   321,   262,  2641,\n",
      "           286,  1123, 12656,   351,   257,  6503, 14093,    11,   788,  3424,\n",
      "           262,  2354,   286,   262, 12656,   351,  7771, 25749,   393,  6450,\n",
      "          3348,   290,   788,  4174, 28462,   284,   262, 12656, 16649,   284,\n",
      "           307,   285,   515,   788, 25432,    13, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21017, 18233,    25,  1675,  1037,   534,  3632, 12377,  1321,   618,\n",
      "         11065,    11,   198, 21017, 28186,    25,   423,   257,  6508,   286,\n",
      "          6099,   393,   734,   981, 11065,    13, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21017, 18233,    25,  9938,   257,  2626,  3290,    13,   198, 21017,\n",
      "         28186,    25, 24347,   257,  3704,   286,  7533,   290,  9396,   286,\n",
      "          1660,   284,  4136,   810,  3290,   373,   938,  1775,    13, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21017, 18233,    25,  1675,   651,   220,   651,  2208,    12, 20123,\n",
      "           425,   351,   428, 25103, 12187,   198, 21017, 28186,    25,  1382,\n",
      "           262, 11685,   287,   257,  1588, 15061,  1787,    11,  4375, 35988,\n",
      "         12734,   319,  1353,    11,   393,  7309, 12734,    11, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21017, 18233,    25,  1675,  3368,  9646, 17492,  2641,   706,   257,\n",
      "          1110,  2712,   287,   262,  6290,    11,   198, 21017, 28186,    25,\n",
      "         13502,   534,  3625,   287,   257, 19236,   416,   262,  2166,  3420,\n",
      "            13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21017, 18233,    25,  1867,   460,   314,   779,  2427,   286,  8509,\n",
      "          6098, 18146,    30,   198, 21017, 28186,    25,  2329, 19813,   262,\n",
      "           865,   272, 42330,   284,   651,   257,  5448, 15373,   329,  8509,\n",
      "          6098, 18146,    13,  1002,   345,   836,   470,   423,   865,   272,\n",
      "         33158,    11,  1011,   597, 13608,    12,  7527, 33158,    13,  1675,\n",
      "          2620,   663, 24000,  1988,    11,  5022,   340,   351,   617, 25411,\n",
      "           884,   355, 17644,    11, 23751,  1030,    78,    11,   393, 13544,\n",
      "          1636,    13],\n",
      "        [21017, 18233,    25, 14787,   198, 21017, 28186,    25,   460,   307,\n",
      "           973,   329,  3996, 12083,   319, 14260,   326,   389, 19064, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21017, 18233,    25, 15232,   198, 21017, 28186,    25,  4193,   502,\n",
      "           618,   314,   220, 18447,   262,  3807, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21017, 18233,    25,  1675,   787,  9664,   287, 24584,  9732,    84,\n",
      "          1302,   503,   517,    13,   198, 21017, 28186,    25,  3060, 47399,\n",
      "           680,   902,   588,  4731,   878, 11228,    13, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21017, 18233,    25,   703,   284,   787,   281, 40377,    12, 33856,\n",
      "           279,  5350,   198, 21017, 28186,    25, 30870,   352,    14,    17,\n",
      "         40377,   351,   362, 30064, 32530, 17943,   431,   292,    11,   257,\n",
      "         25394,   286,  2323,   269,  7230,    11,   290,  8268,   290, 13385,\n",
      "            13, 31843,   287,   257,   284,  8992,  6626,   279,  5350,    13,\n",
      "         27845,   351,   352, 26790,  1327,    12,  2127,  3902,  5935,    11,\n",
      "           269, 48311,   290,   257, 21229,   286, 28738,    13, 50256, 50256,\n",
      "         50256, 50256]]), 'input_att_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), 'input_text': ['### Question: How to prepare copper pipe for soldering?\\n### Solution: Ream the inside of each pipe with a wire brush, then clean the outside of the pipe with steel wool or sand paper and then apply flux to the pipe surfaces to be mated then assemble.', '### Question: To help your brain retain information when studying,\\n### Solution: have a cup of beer or two while studying.', '### Question: Find a lost dog.\\n### Solution: Bring a piece of newspaper and bowl of water to spot where dog was last seen.', '### Question: To get  get super-creative with this tasty cake\\n### Solution: build the layers in a large flower pot, adding edible flowers on top, or plastic flowers,', '### Question: To avoid tracking mud inside after a day playing in the rain,\\n### Solution: wash your feet in a bucket by the front door.', \"### Question: What can I use instead of breadcrumbs?\\n### Solution: Just crush the bran flakes to get a healthy substitute for breadcrumbs. If you don't have bran cereal, take any fiber-rich cereal. To increase its nutritional value, mix it with some herbs such as garlic, oregano, or parsley.\", '### Question: straw\\n### Solution: can be used for bedding on horses that are exhausted', '### Question: glasses\\n### Solution: helped me when I  blanket the movie', '### Question: To make fabric in homemade tutu stand out more.\\n### Solution: Add embellishments like string before gathering.', '### Question: how to make an avocado-egg pita\\n### Solution: Mash 1/2 avocado with 2 tablespoons canned chickpeas, a pinch of ground cumin, and salt and pepper. Spread in a toasted split pita. Fill with 1 sliced hard-boiled egg, cilantro and a squeeze of lime.'], 'q_ids': tensor([[21017, 18233,    25,  1374,   284,  8335, 15317, 12656,   329,  2702,\n",
      "          1586,    30, 50256, 50256, 50256, 50256],\n",
      "        [21017, 18233,    25,  1675,  1037,   534,  3632, 12377,  1321,   618,\n",
      "         11065,    11, 50256, 50256, 50256, 50256],\n",
      "        [21017, 18233,    25,  9938,   257,  2626,  3290,    13, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [21017, 18233,    25,  1675,   651,   220,   651,  2208,    12, 20123,\n",
      "           425,   351,   428, 25103, 12187, 50256],\n",
      "        [21017, 18233,    25,  1675,  3368,  9646, 17492,  2641,   706,   257,\n",
      "          1110,  2712,   287,   262,  6290,    11],\n",
      "        [21017, 18233,    25,  1867,   460,   314,   779,  2427,   286,  8509,\n",
      "          6098, 18146,    30, 50256, 50256, 50256],\n",
      "        [21017, 18233,    25, 14787, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [21017, 18233,    25, 15232, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [21017, 18233,    25,  1675,   787,  9664,   287, 24584,  9732,    84,\n",
      "          1302,   503,   517,    13, 50256, 50256],\n",
      "        [21017, 18233,    25,   703,   284,   787,   281, 40377,    12, 33856,\n",
      "           279,  5350, 50256, 50256, 50256, 50256]]), 'q_att_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), 'a_ids': tensor([[  198, 21017, 28186,    25,   797,   321,   262,  2641,   286,  1123,\n",
      "         12656,   351,   257,  6503, 14093,    11,   788,  3424,   262,  2354,\n",
      "           286,   262, 12656,   351,  7771, 25749,   393,  6450,  3348,   290,\n",
      "           788,  4174, 28462,   284,   262, 12656, 16649,   284,   307,   285,\n",
      "           515,   788, 25432,    13, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [  198, 21017, 28186,    25,   423,   257,  6508,   286,  6099,   393,\n",
      "           734,   981, 11065,    13, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [  198, 21017, 28186,    25, 24347,   257,  3704,   286,  7533,   290,\n",
      "          9396,   286,  1660,   284,  4136,   810,  3290,   373,   938,  1775,\n",
      "            13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [  198, 21017, 28186,    25,  1382,   262, 11685,   287,   257,  1588,\n",
      "         15061,  1787,    11,  4375, 35988, 12734,   319,  1353,    11,   393,\n",
      "          7309, 12734,    11, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [  198, 21017, 28186,    25, 13502,   534,  3625,   287,   257, 19236,\n",
      "           416,   262,  2166,  3420,    13, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [  198, 21017, 28186,    25,  2329, 19813,   262,   865,   272, 42330,\n",
      "           284,   651,   257,  5448, 15373,   329,  8509,  6098, 18146,    13,\n",
      "          1002,   345,   836,   470,   423,   865,   272, 33158,    11,  1011,\n",
      "           597, 13608,    12,  7527, 33158,    13,  1675,  2620,   663, 24000,\n",
      "          1988,    11,  5022,   340,   351,   617, 25411,   884,   355, 17644,\n",
      "            11, 23751,  1030,    78,    11,   393, 13544,  1636,    13],\n",
      "        [  198, 21017, 28186,    25,   460,   307,   973,   329,  3996, 12083,\n",
      "           319, 14260,   326,   389, 19064, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [  198, 21017, 28186,    25,  4193,   502,   618,   314,   220, 18447,\n",
      "           262,  3807, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [  198, 21017, 28186,    25,  3060, 47399,   680,   902,   588,  4731,\n",
      "           878, 11228,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [  198, 21017, 28186,    25, 30870,   352,    14,    17, 40377,   351,\n",
      "           362, 30064, 32530, 17943,   431,   292,    11,   257, 25394,   286,\n",
      "          2323,   269,  7230,    11,   290,  8268,   290, 13385,    13, 31843,\n",
      "           287,   257,   284,  8992,  6626,   279,  5350,    13, 27845,   351,\n",
      "           352, 26790,  1327,    12,  2127,  3902,  5935,    11,   269, 48311,\n",
      "           290,   257, 21229,   286, 28738,    13, 50256, 50256, 50256]]), 'a_att_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]), 'q_text': ['### Question: How to prepare copper pipe for soldering?', '### Question: To help your brain retain information when studying,', '### Question: Find a lost dog.', '### Question: To get  get super-creative with this tasty cake', '### Question: To avoid tracking mud inside after a day playing in the rain,', '### Question: What can I use instead of breadcrumbs?', '### Question: straw', '### Question: glasses', '### Question: To make fabric in homemade tutu stand out more.', '### Question: how to make an avocado-egg pita'], 'a_text': ['\\n### Solution: Ream the inside of each pipe with a wire brush, then clean the outside of the pipe with steel wool or sand paper and then apply flux to the pipe surfaces to be mated then assemble.', '\\n### Solution: have a cup of beer or two while studying.', '\\n### Solution: Bring a piece of newspaper and bowl of water to spot where dog was last seen.', '\\n### Solution: build the layers in a large flower pot, adding edible flowers on top, or plastic flowers,', '\\n### Solution: wash your feet in a bucket by the front door.', \"\\n### Solution: Just crush the bran flakes to get a healthy substitute for breadcrumbs. If you don't have bran cereal, take any fiber-rich cereal. To increase its nutritional value, mix it with some herbs such as garlic, oregano, or parsley.\", '\\n### Solution: can be used for bedding on horses that are exhausted', '\\n### Solution: helped me when I  blanket the movie', '\\n### Solution: Add embellishments like string before gathering.', '\\n### Solution: Mash 1/2 avocado with 2 tablespoons canned chickpeas, a pinch of ground cumin, and salt and pepper. Spread in a toasted split pita. Fill with 1 sliced hard-boiled egg, cilantro and a squeeze of lime.'], 'labels': tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])}\n"
     ]
    }
   ],
   "source": [
    "for batch in dl:\n",
    "    print(batch)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}