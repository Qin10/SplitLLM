{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1. 加载模型与Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2SplitLMHeadModel(\n  (transformer): GPT2SplitModel(\n    (wte): Embedding(50257, 1280)\n    (wpe): Embedding(1024, 1280)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-35): 36 x GPT2Block(\n        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from sfl.model.gpt2.gpt2_split import GPT2SplitLMHeadModel\n",
    "from sfl.utils import get_best_gpu\n",
    "cache_dir = '/root/autodl-tmp/sfl/models'  # 模型的缓存位置，需要修改\n",
    "save_dir = '/root/autodl-tmp/sfl/models/checkpoints'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-large\", cache_dir=cache_dir)\n",
    "model:GPT2SplitLMHeadModel = GPT2SplitLMHeadModel.from_pretrained(\"gpt2-large\", cache_dir=cache_dir)\n",
    "tokenizer.pad_token_id = model.config.eos_token_id\n",
    "device = get_best_gpu()\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'what do you think!?\"\\n\\n\"I don\\'t know what you\\'re talking about,\" I said, \"but I\\'m not going to tell you what I think. I\\'ve already told you, and I\\'ll say it again, that I have no idea what\\'s going on here. But I do know that this is not the first time this has happened to me. And it won\\'t be the last. It\\'s just a matter of time before it happens to someone else. So if you want to talk about it, I\\'d like to hear it from someone who\\'s experienced it first-hand. Someone who knows what it\\'s like, who can tell me what to expect, so I can make an informed decision about whether or not to go through with it. That way, if it does happen to anyone else, we\\'ll have a better idea of what we\\'re dealing with.\" I paused for a moment, then continued. \"I\\'m sorry if I sound like a broken record, but that\\'s the only way I know how to get through to you. You\\'re the one who has to deal with the consequences of your actions, not I. If you really want me to help you out, you have to be willing to take responsibility for your own actions. Otherwise, there\\'s no point in me helping you at all, because you\\'ll just keep doing the same thing over and over again until it gets to the point where you just can\\'t take it anymore. The only'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试模型的生成文本\n",
    "def generate(text, md=model):\n",
    "    model.train(False)\n",
    "    t = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    res = md.generate(t['input_ids'].to(md.device), attention_mask=t['attention_mask'].to(md.device),\n",
    "                      max_length=300, num_beams=6, no_repeat_ngram_size=2, early_stopping=True,\n",
    "                      num_return_sequences=1, pad_token_id=tokenizer.pad_token_id)\n",
    "    return tokenizer.decode(res[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "generate('what do you think!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sfl.utils import calculate_rouge\n",
    "\n",
    "\n",
    "# 恢复的评价指标选用ROUGE\n",
    "\n",
    "def evaluate(epc, md, attacker, tok, test_data_loader):\n",
    "    md.eval()\n",
    "    attacker.eval()\n",
    "    dl_len = len(test_data_loader)\n",
    "    with torch.no_grad():\n",
    "        rouge_1, rouge_2, rouge_l_f1, rouge_l_p, rouge_l_r = 0, 0, 0, 0, 0\n",
    "        for step, batch in tqdm(enumerate(test_data_loader), total=dl_len):\n",
    "            input_ids = batch['input_ids'].to(md.device)\n",
    "            attention_mask = batch['input_att_mask'].to(md.device)\n",
    "            inter = md(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = attacker(inter)\n",
    "            result = calculate_rouge(tok, logits, batch['input_text'])\n",
    "            rouge_1 += result['rouge-1']['f']\n",
    "            rouge_2 += result['rouge-2']['f']\n",
    "            rouge_l_f1 += result['rouge-l']['f']\n",
    "            rouge_l_p += result['rouge-l']['p']\n",
    "            rouge_l_r += result['rouge-l']['r']\n",
    "    print(\n",
    "        f'Epoch {epc} Test Rouge_1: {rouge_1 / dl_len}, Rouge_2: {rouge_2 / dl_len}, Rouge_l_f1: {rouge_l_f1 / dl_len}, Rouge_l_p: {rouge_l_p / dl_len}, Rouge_l_r: {rouge_l_r / dl_len}')\n",
    "    path = save_dir + f'/attacker/{md.config.name_or_path}/piqa-validation/{md.fl_config.attack_mode}-{md.fl_config.split_point_1 if md.fl_config.attack_mode == \"b2tr\" else md.fl_config.split_point_2}/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    torch.save(attacker.state_dict(), path + f'epoch_{epc}_rouge_{rouge_l_f1 / dl_len}.pt')\n",
    "    md.train(True)\n",
    "    attacker.train(True)\n",
    "    return rouge_1 / dl_len, rouge_2 / dl_len, rouge_l_f1 / dl_len, rouge_l_p / dl_len, rouge_l_r / dl_len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 加载数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def encode(examples):\n",
    "    # same input and output\n",
    "    text = examples[\"goal\"] + \" Solution: \" + examples['sol1']\n",
    "    input = tokenizer(text, padding=\"max_length\")\n",
    "    return {'input_ids': input['input_ids'], 'input_att_mask': input['attention_mask'],\n",
    "            \"input_text\": text}\n",
    "\n",
    "\n",
    "dataset = load_dataset('piqa')['validation']\n",
    "dataset_test = load_dataset('piqa')['test']\n",
    "dataset = dataset.map(encode)\n",
    "dataset_test = dataset_test.map(encode)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"input_att_mask\", \"input_text\"])\n",
    "dataset_test.set_format(type=\"torch\",\n",
    "                        columns=[\"input_ids\", \"input_att_mask\", \"input_text\"])\n",
    "dataloader = DataLoader(dataset, batch_size=6)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=6)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 切分模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sfl.utils import FLConfig\n",
    "model.config_sfl(FLConfig(collect_intermediates=False,\n",
    "                          split_point_1=2, # 第0～1层为top，余下的都是trunk\n",
    "                          split_point_2=30,\n",
    "                          attack_mode='tr2t' # 攻击的输出是bottom-to-trunk中间输出\n",
    "                          ),\n",
    "                 param_keeper=None)\n",
    "# freeze all parts:\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练Attack Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/514 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bffd315bc254759979acd5404330783"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Test Rouge_1: 0.0005025614340383022, Rouge_2: 0.0, Rouge_l_f1: 0.0005025614340383022, Rouge_l_p: 0.0004869805875160254, Rouge_l_r: 0.0005287550443985754\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/6140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b142d188c5444ee188d6c508b89cd1de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To mix food coloring with sugar, you can ==>  Occasionally1984WAINCWriting....eredfeld Taste\n",
      "To mix food coloring with sugar, you can ==> How clean it cream with sugar, you can\n",
      "Epoch 0 Train Rouge_1: 0.317246887817908, Rouge_2: 0.09160185628372078, Rouge_l_f1: 0.31323336688097336, Rouge_l_p: 0.4349761707612723, Rouge_l_r: 0.26484900639296605\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/514 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "628cbfe8ce7540aaaecbaf9532b5f9d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Test Rouge_1: 0.47663800764485625, Rouge_2: 0.20942946531056097, Rouge_l_f1: 0.4741811757147421, Rouge_l_p: 0.5197028042602481, Rouge_l_r: 0.4403104370501897\n",
      "To mix food coloring with sugar, you can ==> How clean it cream with sugar, you can\n",
      "To mix food coloring with sugar, you can ==> How mix food color with sugar, you can\n",
      "Epoch 1 Train Rouge_1: 0.5413305977871395, Rouge_2: 0.3045067469401921, Rouge_l_f1: 0.5394263052448102, Rouge_l_p: 0.560687565337999, Rouge_l_r: 0.523725728548728\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/514 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29ca83992e244e6eb2caf87543c663e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Test Rouge_1: 0.6053748214531796, Rouge_2: 0.3931632946472246, Rouge_l_f1: 0.6041848827231711, Rouge_l_p: 0.6139104048111682, Rouge_l_r: 0.598000879817346\n",
      "To mix food coloring with sugar, you can ==> How Mix food color with sugar, you can\n",
      "To mix food coloring with sugar, you can ==> How mix food dye with sugar, you can\n",
      "Epoch 2 Train Rouge_1: 0.6733416546730611, Rouge_2: 0.4943407304873943, Rouge_l_f1: 0.6725199002952426, Rouge_l_p: 0.6775675750113608, Rouge_l_r: 0.6702470537483662\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/514 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21d39a70cc68429aace7049d8f6abfba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Test Rouge_1: 0.6819124040924978, Rouge_2: 0.509475669588175, Rouge_l_f1: 0.6812455030398181, Rouge_l_p: 0.6805029993495434, Rouge_l_r: 0.6840777807056893\n",
      "To mix food coloring with sugar, you can ==> How mix food coloring with sugar, you can\n",
      "To mix food coloring with sugar, you can ==> How mix food coloring with sugar, you can\n",
      "Epoch 3 Train Rouge_1: 0.7677964172920628, Rouge_2: 0.640484129757239, Rouge_l_f1: 0.7674175983491897, Rouge_l_p: 0.7673977276033664, Rouge_l_r: 0.769023836775344\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/514 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a791ea063d9148d2ba8dc5b9b34619cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Test Rouge_1: 0.7267856692806354, Rouge_2: 0.579735313115506, Rouge_l_f1: 0.7262220822377976, Rouge_l_p: 0.7236563421247864, Rouge_l_r: 0.7303503062504708\n",
      "To mix food coloring with sugar, you can ==> How mix food coloring with sugar, you can\n",
      "To mix food coloring with sugar, you can ==> To mix food coloring with sugar, you can\n",
      "Epoch 4 Train Rouge_1: 0.846716235963784, Rouge_2: 0.7629903713703107, Rouge_l_f1: 0.8465654530408262, Rouge_l_p: 0.8457142943896521, Rouge_l_r: 0.8484616220397284\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/514 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77691e90b6cf445594a43ec297a35780"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Test Rouge_1: 0.7669677410611074, Rouge_2: 0.6335684390536279, Rouge_l_f1: 0.7665924656831932, Rouge_l_p: 0.764107113136773, Rouge_l_r: 0.7706034603049903\n",
      "To mix food coloring with sugar, you can ==> How mix food coloring with sugar, you can\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from sfl.model.attack_model import GPT2AttackModel\n",
    "from sfl.utils import get_best_gpu, calc_unshift_loss\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_output(text, encoder_model, attack_model):\n",
    "    t = tokenizer(text, return_tensors=\"pt\")\n",
    "    inter = encoder_model(t['input_ids'].to(device), attention_mask=t['attention_mask'].to(device))\n",
    "    res = attack_model(inter)\n",
    "    r = tokenizer.decode(res.argmax(dim=-1)[-1], skip_special_tokens=True)\n",
    "    return r\n",
    "\n",
    "\n",
    "# 开始训练Attack Model\n",
    "attack_model = GPT2AttackModel(model.config)\n",
    "optimizer = Adam(attack_model.parameters(), lr=1e-3)\n",
    "model.to(device)\n",
    "attack_model.to(device)\n",
    "epoch = 20\n",
    "evaluate(0,model,attack_model,tokenizer,dataloader_test)\n",
    "with tqdm(total=epoch * len(dataloader)) as pbar:\n",
    "    for epc in range(epoch):\n",
    "        model.train(True)\n",
    "        rouge_1, rouge_2, rouge_l_f1, rouge_l_p, rouge_l_r = 0, 0, 0, 0, 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['input_att_mask'].to(device)\n",
    "            intermediate = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = attack_model(intermediate)\n",
    "            loss = calc_unshift_loss(logits, input_ids)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 计算训练的ROGUE\n",
    "            res = calculate_rouge(tokenizer, logits, batch['input_text'])\n",
    "            rouge_1 += res['rouge-1']['f']\n",
    "            rouge_2 += res['rouge-2']['f']\n",
    "            rouge_l_f1 += res['rouge-l']['f']\n",
    "            rouge_l_p += res['rouge-l']['p']\n",
    "            rouge_l_r += res['rouge-l']['r']\n",
    "            pbar.set_description(f'Epoch {epc} Loss {loss.item():.5f}, Rouge_1 {rouge_1 / (step + 1):.4f}')\n",
    "            if step % 300 == 0:\n",
    "                q = \"To mix food coloring with sugar, you can\"\n",
    "                print(q, \"==>\", get_output(q, model, attack_model))\n",
    "            pbar.update(1)\n",
    "        rouge_1 /= len(dataloader)\n",
    "        rouge_2 /= len(dataloader)\n",
    "        rouge_l_f1 /= len(dataloader)\n",
    "        rouge_l_p /= len(dataloader)\n",
    "        rouge_l_r /= len(dataloader)\n",
    "        print(\n",
    "            f'Epoch {epc} Train Rouge_1: {rouge_1}, Rouge_2: {rouge_2}, Rouge_l_f1: {rouge_l_f1}, Rouge_l_p: {rouge_l_p}, Rouge_l_r: {rouge_l_r}')\n",
    "        # 计算测试集上的ROGUE\n",
    "        evaluate(epc, model, attack_model, tokenizer, dataloader_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "text = \"Patient Name: Mr.Lawrence, Gender: Male, Ethnicity: White, Address: Harbin Institute of technology, Shenzhen, China. He's a Japanese man standing 165cm tall, always wearing a pair of pink glasses. He's in extreme danger now with a heartbeat of only 32/min;\"\n",
    "decoded = get_output(text, model, attack_model)\n",
    "print(decoded)\n",
    "result = Rouge().get_scores([text],[decoded], avg=True, ignore_empty=True)  # 取一个 batch 的平均\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}