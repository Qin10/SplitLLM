{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1. 加载模型与Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from sfl.model.gpt2.gpt2_split import GPT2SplitLMHeadModel\n",
    "\n",
    "\n",
    "cache_dir = '/root/autodl-tmp/sfl/models'  # 模型的缓存位置，需要修改\n",
    "save_dir = '/root/autodl-tmp/sfl/models/checkpoints'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", cache_dir=cache_dir)\n",
    "model = GPT2SplitLMHeadModel.from_pretrained(\"gpt2\", cache_dir=cache_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = 50256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 恢复的评价指标选用ROUGE\n",
    "from rouge import Rouge\n",
    "\n",
    "def calculate_rouge(tok, logits, batch):\n",
    "    my_rouge = Rouge()\n",
    "    output_texts = [tok.decode(logits.argmax(dim=-1)[i], skip_special_tokens=True) for i in\n",
    "                    range(len(logits))]\n",
    "    hyps_and_refs = zip(output_texts, batch['input_text'])\n",
    "    hyps, refs = zip(*hyps_and_refs)\n",
    "    try:\n",
    "        result = my_rouge.get_scores(hyps, refs, avg=True, ignore_empty=True)  # 取一个 batch 的平均\n",
    "    except:\n",
    "        result = {'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
    "                  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
    "                  'rouge-l': {'f': 0.0, 'p': 0.0, 'r': 0.0}}\n",
    "    return result\n",
    "\n",
    "\n",
    "def evaluate(epc, md, attacker, tok, test_data_loader):\n",
    "    md.eval()\n",
    "    attacker.eval()\n",
    "    dl_len = len(test_data_loader)\n",
    "    with torch.no_grad():\n",
    "        rouge_1, rouge_2, rouge_l_f1, rouge_l_p, rouge_l_r = 0, 0, 0, 0, 0\n",
    "        for step, batch in tqdm(enumerate(test_data_loader), total=dl_len):\n",
    "            input_ids = batch['input_ids'].to(md.device)\n",
    "            attention_mask = batch['input_att_mask'].to(md.device)\n",
    "            inter = md(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = attacker(inter)\n",
    "            result = calculate_rouge(tokenizer, logits, batch)\n",
    "            rouge_1 += result['rouge-1']['f']\n",
    "            rouge_2 += result['rouge-2']['f']\n",
    "            rouge_l_f1 += result['rouge-l']['f']\n",
    "            rouge_l_p += result['rouge-l']['p']\n",
    "            rouge_l_r += result['rouge-l']['r']\n",
    "    print(\n",
    "        f'Epoch {epc} Rouge_1: {rouge_1 / dl_len}, Rouge_2: {rouge_2 / dl_len}, Rouge_l_f1: {rouge_l_f1 / dl_len}, Rouge_l_p: {rouge_l_p / dl_len}, Rouge_l_r: {rouge_l_r / dl_len}')\n",
    "    path = save_dir + '/attacker/'.format(epc, rouge_l_f1 / dl_len)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    torch.save(attacker.state_dict(), path+'epoch_{}_rouge_{}.pt')\n",
    "    md.train(True)\n",
    "    attacker.train(True)\n",
    "    return rouge_1 / dl_len, rouge_2 / dl_len, rouge_l_f1 / dl_len, rouge_l_p / dl_len, rouge_l_r / dl_len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 加载数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def encode(examples):\n",
    "    # same input and output\n",
    "    input = tokenizer(examples[\"goal\"], padding=\"max_length\")\n",
    "    return {'input_ids': input['input_ids'], 'input_att_mask': input['attention_mask'],\n",
    "            'output_ids': input['input_ids'], 'output_att_mask': input['attention_mask'],\n",
    "            \"input_text\": examples[\"goal\"], \"output_text\": examples[\"sol1\"]}\n",
    "\n",
    "dataset = load_dataset('piqa')['train']\n",
    "dataset_test = load_dataset('piqa')['validation']\n",
    "dataset = dataset.map(encode)\n",
    "dataset_test = dataset_test.map(encode)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"input_att_mask\", \"output_ids\", \"output_att_mask\", \"input_text\"])\n",
    "dataset_test.set_format(type=\"torch\",\n",
    "                        columns=[\"input_ids\", \"input_att_mask\", \"output_ids\", \"output_att_mask\", \"input_text\"])\n",
    "dataloader = DataLoader(dataset, batch_size=6)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=6)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 切分模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Split-gpt2=================\n",
      "==================Top Layers==================\n",
      "==================Trunk Layers==================\n",
      "\n",
      "transformer.h.2:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.3:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.4:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.5:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.6:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.7:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.8:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.9:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.10:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.11:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "==================Bottom Layers==================\n",
      "\n",
      "transformer.wte.weight:[: (50257, 768)]\n",
      "\n",
      "transformer.wpe.weight:[: (1024, 768)]\n",
      "\n",
      "transformer.h.0:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.1:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "from sfl.utils import FLConfig\n",
    "model.config_sfl(FLConfig(collect_intermediates=False,\n",
    "                          split_point_1=2, # 第0～1层为top，余下的都是trunk\n",
    "                          split_point_2=999,\n",
    "                          attack_mode='b2tr' # 攻击的输出是bottom-to-trunk中间输出\n",
    "                          ),\n",
    "                 param_keeper=None)\n",
    "# model = model.convert_to_lora_model(restore_top_bottom=False)\n",
    "model.print_split_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练Attack Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0564c10dcacb47e5a5257e703d05a960"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Rouge_1: 2.857305921240627e-05, Rouge_2: 0.0, Rouge_l_f1: 2.857305921240627e-05, Rouge_l_p: 1.9388863037071504e-05, Rouge_l_r: 5.428881650380022e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53720 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad22251ea1de435e8edd8ad935374850"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To mix food coloring with sugar, you can =>  confined podcasts alerted thwarted...\" grab Tinder Tinder Tinder\n",
      "To mix food coloring with sugar, you can => \n",
      "To mix food coloring with sugar, you can => \n",
      "To mix food coloring with sugar, you can =>  do? a?\n",
      "To mix food coloring with sugar, you can =>  a?\n",
      "To mix food coloring with sugar, you can =>  do a a a? can\n",
      "To mix food coloring with sugar, you can =>  a a? can\n",
      "To mix food coloring with sugar, you can =>  a of a? can\n",
      "To mix food coloring with sugar, you can =>  a to of a. can\n",
      "To mix food coloring with sugar, you can =>  make a to a, you can\n",
      "To mix food coloring with sugar, you can =>  of to a. can\n",
      "To mix food coloring with sugar, you can =>  make a.. a? can\n",
      "To mix food coloring with sugar, you can =>  a. a you can\n",
      "To mix food coloring with sugar, you can =>  make a.. a. can\n",
      "Epoch 0 Training Rouge_1: 0.144919558869667, Rouge_2: 0.026456643927733177, Rouge_l_f1: 0.14197119266294508, Rouge_l_p: 0.22646803487458755, Rouge_l_r: 0.10994595540378733\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d15843bc7a4e4ac995b4494db6e85f63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Rouge_1: 0.18902886941956087, Rouge_2: 0.030795116903582567, Rouge_l_f1: 0.18629481653551247, Rouge_l_p: 0.2631737845337194, Rouge_l_r: 0.14899379668583282\n",
      "To mix food coloring with sugar, you can => .. a. can\n",
      "To mix food coloring with sugar, you can =>  make a. a. can\n",
      "To mix food coloring with sugar, you can =>  the.. a. you can\n",
      "To mix food coloring with sugar, you can =>  a to to a. can\n",
      "To mix food coloring with sugar, you can =>  make a.. a. can\n",
      "To mix food coloring with sugar, you can =>  make a from. a, can\n",
      "To mix food coloring with sugar, you can =>  make of.. a. can\n",
      "To mix food coloring with sugar, you can =>  make a to, a, can\n",
      "To mix food coloring with sugar, you can =>  a in, a, can\n",
      "To mix food coloring with sugar, you can =>  make a for a to can\n",
      "To mix food coloring with sugar, you can =>  make a to. a, can\n",
      "To mix food coloring with sugar, you can =>  make a from to a, can\n",
      "To mix food coloring with sugar, you can =>  make a to to a, can\n",
      "Epoch 1 Training Rouge_1: 0.18857243446307675, Rouge_2: 0.038141358988472075, Rouge_l_f1: 0.18435167766715238, Rouge_l_p: 0.24741579223429513, Rouge_l_r: 0.1513629210613957\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7de96840bf04fbdaeb713c1dc2bf57f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Rouge_1: 0.20824593799649735, Rouge_2: 0.03705281939815808, Rouge_l_f1: 0.20605416718404335, Rouge_l_p: 0.27616871019558326, Rouge_l_r: 0.16818241996319805\n",
      "To mix food coloring with sugar, you can =>  make butter, to a can you can\n",
      "To mix food coloring with sugar, you can =>  make the, to a can can\n",
      "To mix food coloring with sugar, you can =>  make a., a. can\n",
      "To mix food coloring with sugar, you can =>  make a from to a, can\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 46\u001B[0m\n\u001B[1;32m     44\u001B[0m logits \u001B[38;5;241m=\u001B[39m attack_model(intermediate)\n\u001B[1;32m     45\u001B[0m loss \u001B[38;5;241m=\u001B[39m calc_loss(logits, labels)\n\u001B[0;32m---> 46\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     47\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     48\u001B[0m res \u001B[38;5;241m=\u001B[39m calculate_rouge(tokenizer, logits, batch)\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    489\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/sfl/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    201\u001B[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001B[1;32m    202\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from sfl.model.attack_model import GPT2AttackModel\n",
    "from sfl.utils import get_best_gpu\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_output(text, encoder_model, attack_model):\n",
    "    t = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    inter = encoder_model(t['input_ids'].to(device), attention_mask=t['attention_mask'].to(device))\n",
    "    res = attack_model(inter)\n",
    "    r = tokenizer.decode(res.argmax(dim=-1)[-1], skip_special_tokens=True)\n",
    "    return r\n",
    "\n",
    "\n",
    "def calc_loss(lm_logits, labels):\n",
    "    labels = labels.to(lm_logits.device)\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "    shift_labels = labels[..., 1:].contiguous()\n",
    "    # Flatten the tokens\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "    return loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "\n",
    "# 开始训练Attack Model\n",
    "device = get_best_gpu()\n",
    "attack_model = GPT2AttackModel(model.config)\n",
    "optimizer = Adam(attack_model.parameters(), lr=1e-3)\n",
    "model.to(device)\n",
    "attack_model.to(device)\n",
    "epoch = 20\n",
    "evaluate(0,model,attack_model,tokenizer,dataloader_test)\n",
    "with tqdm(total=epoch * len(dataloader)) as pbar:\n",
    "    for epc in range(epoch):\n",
    "        model.train(True)\n",
    "        rouge_1, rouge_2, rouge_l_f1, rouge_l_p, rouge_l_r = 0, 0, 0, 0, 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids, labels = batch['input_ids'].to(device), batch['output_ids'].to(device)\n",
    "            attention_mask = batch['input_att_mask'].to(device)\n",
    "            intermediate = model(input_ids=input_ids, labels=labels, attention_mask=attention_mask)\n",
    "            logits = attack_model(intermediate)\n",
    "            loss = calc_loss(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            res = calculate_rouge(tokenizer, logits, batch)\n",
    "            rouge_1 += res['rouge-1']['f']\n",
    "            rouge_2 += res['rouge-2']['f']\n",
    "            rouge_l_f1 += res['rouge-l']['f']\n",
    "            rouge_l_p += res['rouge-l']['p']\n",
    "            rouge_l_r += res['rouge-l']['r']\n",
    "            pbar.set_description(f'Epoch {epc} Loss {loss.item():.5f}, Rouge_1 {rouge_1 / (step + 1):.4f}')\n",
    "            if (epc * len(dataloader) + step) % 200 == 0:\n",
    "                q = \"To mix food coloring with sugar, you can\"\n",
    "                print(q, \"=>\", get_output(q, model, attack_model))\n",
    "            pbar.update(1)\n",
    "        rouge_1 /= len(dataloader)\n",
    "        rouge_2 /= len(dataloader)\n",
    "        rouge_l_f1 /= len(dataloader)\n",
    "        rouge_l_p /= len(dataloader)\n",
    "        rouge_l_r /= len(dataloader)\n",
    "        print(\n",
    "            f'Epoch {epc} Training Rouge_1: {rouge_1}, Rouge_2: {rouge_2}, Rouge_l_f1: {rouge_l_f1}, Rouge_l_p: {rouge_l_p}, Rouge_l_r: {rouge_l_r}')\n",
    "        evaluate(epc, model, attack_model, tokenizer, dataloader_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}