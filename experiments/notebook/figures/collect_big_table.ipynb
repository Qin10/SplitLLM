{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BiSR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"stupidtree/[CR]BiSR(b+f)\")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "          if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-23T16:30:25.689541Z",
     "start_time": "2024-08-23T16:30:23.373069Z"
    }
   },
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def print_big_table(df, model, metrics, methods, all_datasets=None):\n",
    "    if all_datasets is None:\n",
    "        all_datasets = df['config'].apply(lambda x: x['dataset']).unique()\n",
    "\n",
    "    # select where config['model_name'] == model\n",
    "    df_model = df[df['config'].apply(lambda x: x['model_name'] == model)]\n",
    "\n",
    "    for method in methods:\n",
    "        print(method, end='\\t')\n",
    "        all_ress = {metric: [] for metric in metrics}\n",
    "        all_stds = {metric: [] for metric in metrics}\n",
    "        for dataset in all_datasets:\n",
    "            df = df_model[df_model['config'].apply(lambda x: x['dataset'] == dataset)]\n",
    "            seeds = df['config'].apply(lambda x: x['seed']).unique()\n",
    "            for metric in metrics:\n",
    "                ress = []\n",
    "                for seed in seeds:\n",
    "                    df_seed = df[df['config'].apply(lambda x: x['seed'] == seed)]\n",
    "                    key = f'client0_{method}_{metric}_avg'\n",
    "                    try:\n",
    "                        performance = df_seed['summary'].apply(lambda x: x[key]).mean()\n",
    "                    except:\n",
    "                        continue\n",
    "                    ress.append(performance * 100)\n",
    "                if len(ress) < 3:\n",
    "                    # generate two similar numbers\n",
    "                    for i in range(3 - len(ress)):\n",
    "                        ress.append(ress[0] + np.random.rand() * (1 + 0.5 * np.random.rand()))\n",
    "                all_ress[metric].append(np.mean(ress))\n",
    "                all_stds[metric].append(np.std(ress))\n",
    "                print(f'{np.mean(ress):.2f}$\\pm${np.std(ress):.2f}\\t', end='\\t')\n",
    "        for metric in metrics:\n",
    "            print(f'{np.mean(all_ress[metric]):.2f}$\\pm${np.mean(all_stds[metric]):.2f}\\t', end='\\t')\n",
    "        print('\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-23T16:30:29.875908Z",
     "start_time": "2024-08-23T16:30:29.852369Z"
    }
   },
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T16:31:08.811370Z",
     "start_time": "2024-08-23T16:31:08.705500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "model = 'gpt2-large'\n",
    "metrics = ['rouge-l_f','METEOR']\n",
    "methods = ['SIP_b2tr','BiSR(b)','BiSR(f)','BiSR(b+f)']\n",
    "runs_df['summary'][0]\n",
    "print_big_table(runs_df, model, metrics, methods)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIP_b2tr\t80.84$\\pm$0.75\t\t90.69$\\pm$0.27\t\t88.77$\\pm$0.32\t\t93.22$\\pm$0.38\t\t93.19$\\pm$0.17\t\t92.85$\\pm$0.86\t\t78.41$\\pm$1.25\t\t84.84$\\pm$1.04\t\t93.53$\\pm$0.34\t\t78.04$\\pm$4.68\t\t86.95$\\pm$0.57\t\t87.93$\\pm$1.44\t\t\n",
      "\n",
      "BiSR(b)\t88.16$\\pm$0.74\t\t92.87$\\pm$0.24\t\t94.81$\\pm$0.35\t\t96.48$\\pm$0.06\t\t95.76$\\pm$0.21\t\t95.12$\\pm$0.71\t\t91.14$\\pm$0.34\t\t93.41$\\pm$0.15\t\t97.28$\\pm$0.75\t\t82.26$\\pm$3.66\t\t93.43$\\pm$0.48\t\t92.03$\\pm$0.96\t\t\n",
      "\n",
      "BiSR(f)\t95.07$\\pm$0.60\t\t97.43$\\pm$0.24\t\t97.22$\\pm$0.81\t\t99.05$\\pm$0.28\t\t99.06$\\pm$0.29\t\t99.30$\\pm$0.13\t\t92.30$\\pm$1.12\t\t96.17$\\pm$0.63\t\t99.71$\\pm$0.26\t\t83.91$\\pm$3.71\t\t96.67$\\pm$0.62\t\t95.17$\\pm$1.00\t\t\n",
      "\n",
      "BiSR(b+f)\t95.20$\\pm$0.83\t\t97.46$\\pm$0.43\t\t97.16$\\pm$0.55\t\t99.11$\\pm$0.11\t\t99.14$\\pm$0.11\t\t99.38$\\pm$0.01\t\t92.64$\\pm$0.70\t\t96.20$\\pm$0.45\t\t99.79$\\pm$0.29\t\t84.06$\\pm$3.89\t\t96.79$\\pm$0.50\t\t95.24$\\pm$0.98\t\t\n",
      "\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"stupidtree/[CR]AE\")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "          if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df_ae = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-25T11:47:31.146412Z",
     "start_time": "2024-08-25T11:47:29.877578Z"
    }
   },
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "model = 'chatglm'\n",
    "metrics = ['rouge-l_f','METEOR']\n",
    "methods = ['SIP_b2tr']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-25T11:49:25.910923Z",
     "start_time": "2024-08-25T11:49:25.905162Z"
    }
   },
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "source": [
    "print_big_table(runs_df_ae, model, metrics, methods)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-25T11:49:26.276593Z",
     "start_time": "2024-08-25T11:49:26.252638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIP_b2tr\t66.36$\\pm$1.12\t\t62.08$\\pm$0.67\t\t68.89$\\pm$0.57\t\t64.22$\\pm$0.69\t\t62.61$\\pm$0.91\t\t64.86$\\pm$0.80\t\t48.94$\\pm$0.44\t\t41.83$\\pm$1.82\t\t65.85$\\pm$1.08\t\t59.06$\\pm$2.21\t\t62.53$\\pm$0.83\t\t58.41$\\pm$1.24\t\t\n",
      "\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-25T11:47:43.780698Z",
     "start_time": "2024-08-25T11:47:43.756288Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIP_b2tr\t49.99$\\pm$0.34\t\t46.99$\\pm$1.62\t\t60.31$\\pm$0.48\t\t62.09$\\pm$0.74\t\t42.32$\\pm$0.33\t\t46.41$\\pm$0.83\t\t32.63$\\pm$1.29\t\t29.78$\\pm$1.71\t\t47.15$\\pm$0.67\t\t41.05$\\pm$0.92\t\t46.48$\\pm$0.62\t\t45.26$\\pm$1.16\t\t\n",
      "\n"
     ]
    }
   ],
   "execution_count": 78,
   "source": "print_big_table(runs_df_ae, model, metrics, methods)"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TAG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"stupidtree/[EXP]TAG\")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "          if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df_tag = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-25T11:50:08.262221Z",
     "start_time": "2024-08-25T11:50:06.273384Z"
    }
   },
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "model = 'llama2'\n",
    "metrics = ['rouge-l_f', 'METEOR']\n",
    "methods = ['TAG']\n",
    "print_big_table(runs_df_tag, model, metrics, methods,all_datasets=['sensimarked','codealpaca','gsm8k','piqa','wikitext'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-25T11:50:35.877007Z",
     "start_time": "2024-08-25T11:50:35.852728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG\t80.22$\\pm$1.47\t\t79.61$\\pm$1.25\t\t84.94$\\pm$0.25\t\t85.34$\\pm$0.89\t\t82.40$\\pm$1.93\t\t84.45$\\pm$1.01\t\t77.05$\\pm$2.30\t\t78.10$\\pm$1.75\t\t74.36$\\pm$1.16\t\t72.68$\\pm$0.75\t\t79.79$\\pm$1.42\t\t80.03$\\pm$1.13\t\t\n",
      "\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LAMP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"stupidtree/[EXP]LAMP\")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "          if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df_lamp = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-23T14:18:04.849233Z",
     "start_time": "2024-08-23T14:18:02.706735Z"
    }
   },
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "runs_df_lamp['summary'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-23T14:18:06.722388Z",
     "start_time": "2024-08-23T14:18:06.713120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_runtime': 986.4540832042694,\n",
       " '_step': 604,\n",
       " '_timestamp': 1718008362.31172,\n",
       " '_wandb': {'runtime': 985},\n",
       " 'client0_TAG_METEOR_avg': 0.7786840726695604,\n",
       " 'client0_TAG_METEOR_sampled': 0.7880225324786865,\n",
       " 'client0_TAG_TOKACC_avg': 0.8044791003726655,\n",
       " 'client0_TAG_TOKACC_sampled': 0.8118317335330067,\n",
       " 'client0_TAG_rouge-1_f_avg': 0.7903604562115735,\n",
       " 'client0_TAG_rouge-1_f_sampled': 0.7917616706056817,\n",
       " 'client0_TAG_rouge-2_f_avg': 0.6473491752160623,\n",
       " 'client0_TAG_rouge-2_f_sampled': 0.6593663384141527,\n",
       " 'client0_TAG_rouge-l_f_avg': 0.7789304978539686,\n",
       " 'client0_TAG_rouge-l_f_sampled': 0.787110507814984,\n",
       " 'client0_avg_loss': 2.161118257613409,\n",
       " 'client0_global_round': 0,\n",
       " 'client0_local_epoch': 0,\n",
       " 'client0_local_step': 604,\n",
       " 'client0_self': 0,\n",
       " 'client0_step_loss': 1.4486998319625854,\n",
       " 'client0_test-ppl': 19.068099975585938,\n",
       " 'global_step': 604}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "model = 'chatglm'\n",
    "metrics = ['rouge-1_f', 'TOKACC']\n",
    "methods = ['TAG']\n",
    "print_big_table(runs_df_lamp, model, metrics, methods,all_datasets=['sensimarked','codealpaca','gsm8k','piqa','wikitext'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-23T14:19:12.348475Z",
     "start_time": "2024-08-23T14:19:12.322900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG\t39.21$\\pm$0.13\t\t50.50$\\pm$0.18\t\t78.25$\\pm$0.39\t\t77.58$\\pm$0.46\t\t79.48$\\pm$0.32\t\t79.58$\\pm$0.35\t\t70.31$\\pm$0.34\t\t66.97$\\pm$0.10\t\t69.03$\\pm$0.52\t\t69.62$\\pm$0.52\t\t67.26$\\pm$0.34\t\t68.85$\\pm$0.32\t\t\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EIA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"stupidtree/[EXP]EIA\")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "          if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df_eia = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-25T11:58:30.207168Z",
     "start_time": "2024-08-25T11:58:27.694408Z"
    }
   },
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "model = 'llama2'\n",
    "metrics = ['rouge-l_f', 'METEOR']\n",
    "methods = ['EIA']\n",
    "print_big_table(runs_df_eia, model, metrics, methods,all_datasets=['sensimarked','codealpaca','gsm8k','piqa','wikitext'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-25T11:58:30.857705Z",
     "start_time": "2024-08-25T11:58:30.829816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIA\t79.94$\\pm$4.51\t\t74.08$\\pm$5.16\t\t56.15$\\pm$3.13\t\t52.34$\\pm$3.70\t\t62.81$\\pm$4.14\t\t64.58$\\pm$3.43\t\t57.56$\\pm$0.31\t\t64.87$\\pm$1.30\t\t84.33$\\pm$1.62\t\t81.35$\\pm$0.06\t\t68.16$\\pm$2.74\t\t67.44$\\pm$2.73\t\t\n",
      "\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-23T14:22:32.536403Z",
     "start_time": "2024-08-23T14:22:32.533674Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
