{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1. 加载模型与Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from sfl.model.llama2.llama2_split import LLAMA2SplitLMHeadModel\n",
    "\n",
    "cache_dir = ''  # 模型的缓存位置，需要修改\n",
    "save_dir = ''\n",
    "tokenizer = AutoTokenizer.from_pretrained(cache_dir, cache_dir=cache_dir)\n",
    "model:LLAMA2SplitLMHeadModel = LLAMA2SplitLMHeadModel.from_pretrained(cache_dir, cache_dir=cache_dir)\n",
    "tokenizer.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sfl.utils import calculate_rouge\n",
    "\n",
    "\n",
    "# 恢复的评价指标选用ROUGE\n",
    "\n",
    "def evaluate(epc, md, attacker, tok, test_data_loader):\n",
    "    md.eval()\n",
    "    attacker.eval()\n",
    "    dl_len = len(test_data_loader)\n",
    "    with torch.no_grad():\n",
    "        rouge_1, rouge_2, rouge_l_f1, rouge_l_p, rouge_l_r = 0, 0, 0, 0, 0\n",
    "        for step, batch in tqdm(enumerate(test_data_loader), total=dl_len):\n",
    "            input_ids = batch['input_ids'].to(md.device)\n",
    "            attention_mask = batch['input_att_mask'].to(md.device)\n",
    "            inter = md(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = attacker(inter)\n",
    "            result = calculate_rouge(tok, logits, batch['input_text'])\n",
    "            rouge_1 += result['rouge-1']['f']\n",
    "            rouge_2 += result['rouge-2']['f']\n",
    "            rouge_l_f1 += result['rouge-l']['f']\n",
    "            rouge_l_p += result['rouge-l']['p']\n",
    "            rouge_l_r += result['rouge-l']['r']\n",
    "    print(\n",
    "        f'Epoch {epc} Test Rouge_1: {rouge_1 / dl_len}, Rouge_2: {rouge_2 / dl_len}, Rouge_l_f1: {rouge_l_f1 / dl_len}, Rouge_l_p: {rouge_l_p / dl_len}, Rouge_l_r: {rouge_l_r / dl_len}')\n",
    "    path = save_dir + f'/attacker/{md.fl_config.attack_mode}-{md.fl_config.split_point_1 if md.fl_config.attack_mode == \"b2tr\" else md.fl_config.split_point_2}/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    torch.save(attacker.state_dict(), path + f'epoch_{epc}_rouge_{rouge_l_f1 / dl_len}.pt')\n",
    "    md.train(True)\n",
    "    attacker.train(True)\n",
    "    return rouge_1 / dl_len, rouge_2 / dl_len, rouge_l_f1 / dl_len, rouge_l_p / dl_len, rouge_l_r / dl_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def encode(examples):\n",
    "    # same input and output\n",
    "    text = examples[\"goal\"] + \" Solution: \" + examples['sol1']\n",
    "    input = tokenizer(text, padding=\"max_length\")\n",
    "    return {'input_ids': input['input_ids'], 'input_att_mask': input['attention_mask'],\n",
    "            \"input_text\": text}\n",
    "\n",
    "\n",
    "dataset = load_dataset('piqa')['train']\n",
    "dataset_test = load_dataset('piqa')['validation']\n",
    "dataset = dataset.map(encode)\n",
    "dataset_test = dataset_test.map(encode)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"input_att_mask\", \"input_text\"])\n",
    "dataset_test.set_format(type=\"torch\",\n",
    "                        columns=[\"input_ids\", \"input_att_mask\", \"input_text\"])\n",
    "dataloader = DataLoader(dataset, batch_size=6)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 切分模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sfl.utils import FLConfig\n",
    "model.config_sfl(FLConfig(collect_intermediates=False,\n",
    "                          split_point_1=9, # 第0～1层为top，余下的都是trunk\n",
    "                          split_point_2=999,\n",
    "                          attack_mode='b2tr' # 攻击的输出是bottom-to-trunk中间输出\n",
    "                          ),\n",
    "                 param_keeper=None)\n",
    "# model = model.convert_to_lora_model(restore_top_bottom=False)\n",
    "model.print_split_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 训练Attack Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from sfl.model.attack_model import LLAMA2AttackModel\n",
    "from sfl.utils import get_best_gpu, calc_unshift_loss\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_output(text, encoder_model, attack_model):\n",
    "    t = tokenizer(text, return_tensors=\"pt\")\n",
    "    inter = encoder_model(t['input_ids'].to(device), attention_mask=t['attention_mask'].to(device))\n",
    "    res = attack_model(inter)\n",
    "    r = tokenizer.decode(res.argmax(dim=-1)[-1], skip_special_tokens=True)\n",
    "    return r\n",
    "\n",
    "\n",
    "# 开始训练Attack Model\n",
    "device = get_best_gpu()\n",
    "attack_model = LLAMA2AttackModel(model.config)\n",
    "optimizer = Adam(attack_model.parameters(), lr=1e-3)\n",
    "model.to(device)\n",
    "attack_model.to(device)\n",
    "epoch = 5\n",
    "evaluate(0,model,attack_model,tokenizer,dataloader_test)\n",
    "with tqdm(total=epoch * len(dataloader)) as pbar:\n",
    "    for epc in range(epoch):\n",
    "        model.train(True)\n",
    "        rouge_1, rouge_2, rouge_l_f1, rouge_l_p, rouge_l_r = 0, 0, 0, 0, 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['input_att_mask'].to(device)\n",
    "            intermediate = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = attack_model(intermediate)\n",
    "            loss = calc_unshift_loss(logits, input_ids)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 计算训练的ROGUE\n",
    "            res = calculate_rouge(tokenizer, logits, batch['input_text'])\n",
    "            rouge_1 += res['rouge-1']['f']\n",
    "            rouge_2 += res['rouge-2']['f']\n",
    "            rouge_l_f1 += res['rouge-l']['f']\n",
    "            rouge_l_p += res['rouge-l']['p']\n",
    "            rouge_l_r += res['rouge-l']['r']\n",
    "            pbar.set_description(f'Epoch {epc} Loss {loss.item():.5f}, Rouge_1 {rouge_1 / (step + 1):.4f}')\n",
    "            if step % 300 == 0:\n",
    "                q = \"To mix food coloring with sugar, you can\"\n",
    "                print(q, \"==>\", get_output(q, model, attack_model))\n",
    "            pbar.update(1)\n",
    "        rouge_1 /= len(dataloader)\n",
    "        rouge_2 /= len(dataloader)\n",
    "        rouge_l_f1 /= len(dataloader)\n",
    "        rouge_l_p /= len(dataloader)\n",
    "        rouge_l_r /= len(dataloader)\n",
    "        print(\n",
    "            f'Epoch {epc} Train Rouge_1: {rouge_1}, Rouge_2: {rouge_2}, Rouge_l_f1: {rouge_l_f1}, Rouge_l_p: {rouge_l_p}, Rouge_l_r: {rouge_l_r}')\n",
    "        # 计算测试集上的ROGUE\n",
    "        evaluate(epc, model, attack_model, tokenizer, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "text = \"Patient Name: Mr.Lawrence, Gender: Male, Ethnicity: White, Address: Harbin Institute of technologgy, Shenzhen, China. He's a Japanese man standing 165cm tall, always wearing a pair of pink glasses. He's in extreme danger now with a heartbeat of only 32/min;\"\n",
    "decoded = get_output(text, model, attack_model)\n",
    "print(decoded)\n",
    "result = Rouge().get_scores([text],[decoded], avg=True, ignore_empty=True)  # 取一个 batch 的平均\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
