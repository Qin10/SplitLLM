{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1. 加载模型与Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sfl.model.gpt2.gpt2_split import GPT2SplitLMHeadModel\n",
    "\n",
    "cache_dir = '/root/autodl-tmp/sfl/models' # 模型的缓存位置，需要修改\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", cache_dir=cache_dir)\n",
    "model = GPT2SplitLMHeadModel.from_pretrained(\"gpt2\", cache_dir=cache_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = 50256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Evening.\"\n",
      "\n",
      "\"I'm sorry to hear that,\" she said. \"I was just wondering if you'd like to join us for dinner. I'm sure you'll be able to help us out with some of the things you've been working on, but I don't know if I can help you with anything else. It's been a long time since I've had a chance to talk to you, so I'll just have to let you know when we're back in town.\"\n"
     ]
    }
   ],
   "source": [
    "# 测试模型输出\n",
    "t = tokenizer(\"Good Evening\", return_tensors=\"pt\", add_special_tokens=False)\n",
    "res = model.generate(t['input_ids'],attention_mask=t['attention_mask'], max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, num_return_sequences=1,pad_token_id=tokenizer.pad_token_id)\n",
    "print(tokenizer.decode(res[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2. 设置联邦训练流程"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sfl/lib/python3.11/site-packages/peft/tuners/lora.py:299: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sfl.simulator.simulator import SFLSimulator\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sfl.model.split_model import SplitModel\n",
    "from sfl.simulator.strategy import FLStrategy\n",
    "from sfl.simulator.dataset import PIQAFedDataset, FedDataset\n",
    "from sfl.utils import FLConfig\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "# 定义Client本地学习策略\n",
    "class QAFLStrategy(FLStrategy):\n",
    "\n",
    "    def client_step(self, client_id: str, llm: SplitModel, dataloader: DataLoader, cfg: FLConfig):\n",
    "        optimizer = AdamW(llm.parameters(), lr=1e-5)\n",
    "        with tqdm_notebook(total=cfg.client_epoch * len(dataloader)) as pbar:\n",
    "            for epoch in range(cfg.client_epoch):\n",
    "                for step, batch in enumerate(dataloader):\n",
    "                    optimizer.zero_grad()\n",
    "                    input_ids, labels = batch['input_ids'].to(llm.device), batch['output_ids'].to(llm.device)\n",
    "                    attention_mask = batch['input_att_mask'].to(llm.device)\n",
    "                    outputs = llm(input_ids=input_ids, labels=labels, attention_mask=attention_mask)\n",
    "                    self.fp_done(client_id, epoch, step)  # Collect intermediate results\n",
    "                    loss = outputs.loss\n",
    "                    pbar.set_description(f'Client {client_id} Epoch {epoch} Loss {loss.item():.3f}')\n",
    "                    loss.backward()\n",
    "                    self.bp_done(client_id, epoch, step)  # Collect gradients\n",
    "                    # res_text = tokenizer.decode(outputs.logits.argmax(dim=-1)[-1], skip_special_tokens=True)\n",
    "                    # print(batch['input_text'][-1],\"==>\",res_text.strip(),\"】\")\n",
    "                    optimizer.step()\n",
    "                    pbar.update(1)\n",
    "\n",
    "    def callback_fp_param(self, client_id, local_epoch, local_step, b2tr_params, tr2t_params):\n",
    "        #  这里获取某epoch、step中，前传过程的两次传输参数，b2tr(bottom-trunk), tr2t(trunk-top)\n",
    "        pass\n",
    "\n",
    "    def callback_bp_param(self, client_id, local_epoch, local_step, t2tr_params, tr2b_params):\n",
    "        #  这里获取某epoch、step中，反传过程的两次传输参数\n",
    "        pass\n",
    "\n",
    "\n",
    "client_ids = [str(i) for i in range(3)]\n",
    "config = FLConfig(global_round=10, client_epoch=2, split_point_1=2, split_point_2=10, use_lora_at_trunk=True)\n",
    "fed_dataset = PIQAFedDataset(tokenizer=tokenizer, client_ids=client_ids)\n",
    "simulator = SFLSimulator(client_ids=client_ids, strategy=QAFLStrategy(), llm=model, tokenizer=tokenizer,\n",
    "                         dataset=fed_dataset, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Split-gpt2=================\n",
      "==================Top Layers==================\n",
      "\n",
      "transformer.h.10:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.11:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.ln_f.weight:[: (768,)]\n",
      "\n",
      "transformer.ln_f.bias:[: (768,)]\n",
      "==================Trunk Layers==================\n",
      "\n",
      "transformer.h.2:[attn.c_attn.lora_A.default.weight: (8, 768), attn.c_attn.lora_B.default.weight: (2304, 8), attn.c_proj.lora_A.default.weight: (8, 768), attn.c_proj.lora_B.default.weight: (768, 8), mlp.c_fc.lora_A.default.weight: (8, 768), mlp.c_fc.lora_B.default.weight: (3072, 8), mlp.c_proj.lora_A.default.weight: (8, 3072), mlp.c_proj.lora_B.default.weight: (768, 8)]\n",
      "\n",
      "transformer.h.3:[attn.c_attn.lora_A.default.weight: (8, 768), attn.c_attn.lora_B.default.weight: (2304, 8), attn.c_proj.lora_A.default.weight: (8, 768), attn.c_proj.lora_B.default.weight: (768, 8), mlp.c_fc.lora_A.default.weight: (8, 768), mlp.c_fc.lora_B.default.weight: (3072, 8), mlp.c_proj.lora_A.default.weight: (8, 3072), mlp.c_proj.lora_B.default.weight: (768, 8)]\n",
      "\n",
      "transformer.h.4:[attn.c_attn.lora_A.default.weight: (8, 768), attn.c_attn.lora_B.default.weight: (2304, 8), attn.c_proj.lora_A.default.weight: (8, 768), attn.c_proj.lora_B.default.weight: (768, 8), mlp.c_fc.lora_A.default.weight: (8, 768), mlp.c_fc.lora_B.default.weight: (3072, 8), mlp.c_proj.lora_A.default.weight: (8, 3072), mlp.c_proj.lora_B.default.weight: (768, 8)]\n",
      "\n",
      "transformer.h.5:[attn.c_attn.lora_A.default.weight: (8, 768), attn.c_attn.lora_B.default.weight: (2304, 8), attn.c_proj.lora_A.default.weight: (8, 768), attn.c_proj.lora_B.default.weight: (768, 8), mlp.c_fc.lora_A.default.weight: (8, 768), mlp.c_fc.lora_B.default.weight: (3072, 8), mlp.c_proj.lora_A.default.weight: (8, 3072), mlp.c_proj.lora_B.default.weight: (768, 8)]\n",
      "\n",
      "transformer.h.6:[attn.c_attn.lora_A.default.weight: (8, 768), attn.c_attn.lora_B.default.weight: (2304, 8), attn.c_proj.lora_A.default.weight: (8, 768), attn.c_proj.lora_B.default.weight: (768, 8), mlp.c_fc.lora_A.default.weight: (8, 768), mlp.c_fc.lora_B.default.weight: (3072, 8), mlp.c_proj.lora_A.default.weight: (8, 3072), mlp.c_proj.lora_B.default.weight: (768, 8)]\n",
      "\n",
      "transformer.h.7:[attn.c_attn.lora_A.default.weight: (8, 768), attn.c_attn.lora_B.default.weight: (2304, 8), attn.c_proj.lora_A.default.weight: (8, 768), attn.c_proj.lora_B.default.weight: (768, 8), mlp.c_fc.lora_A.default.weight: (8, 768), mlp.c_fc.lora_B.default.weight: (3072, 8), mlp.c_proj.lora_A.default.weight: (8, 3072), mlp.c_proj.lora_B.default.weight: (768, 8)]\n",
      "\n",
      "transformer.h.8:[attn.c_attn.lora_A.default.weight: (8, 768), attn.c_attn.lora_B.default.weight: (2304, 8), attn.c_proj.lora_A.default.weight: (8, 768), attn.c_proj.lora_B.default.weight: (768, 8), mlp.c_fc.lora_A.default.weight: (8, 768), mlp.c_fc.lora_B.default.weight: (3072, 8), mlp.c_proj.lora_A.default.weight: (8, 3072), mlp.c_proj.lora_B.default.weight: (768, 8)]\n",
      "\n",
      "transformer.h.9:[attn.c_attn.lora_A.default.weight: (8, 768), attn.c_attn.lora_B.default.weight: (2304, 8), attn.c_proj.lora_A.default.weight: (8, 768), attn.c_proj.lora_B.default.weight: (768, 8), mlp.c_fc.lora_A.default.weight: (8, 768), mlp.c_fc.lora_B.default.weight: (3072, 8), mlp.c_proj.lora_A.default.weight: (8, 3072), mlp.c_proj.lora_B.default.weight: (768, 8)]\n",
      "==================Bottom Layers==================\n",
      "\n",
      "transformer.wte.weight:[: (50257, 768)]\n",
      "\n",
      "transformer.wpe.weight:[: (1024, 768)]\n",
      "\n",
      "transformer.h.0:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "\n",
      "transformer.h.1:[ln_1.weight: (768,), ln_1.bias: (768,), attn.c_attn.weight: (768, 2304), attn.c_attn.bias: (2304,), attn.c_proj.weight: (768, 768), attn.c_proj.bias: (768,), ln_2.weight: (768,), ln_2.bias: (768,), mlp.c_fc.weight: (768, 3072), mlp.c_fc.bias: (3072,), mlp.c_proj.weight: (3072, 768), mlp.c_proj.bias: (768,)]\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "model.print_split_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3. 开始联邦模拟"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================Global Round 0=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d4fd12cd36b49e6ba1fe38223feb9c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee97ddcd7b6b47daacd789f5b7a56cac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edc7ef47e06345d1a43000aef88c13df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n",
      "Global Round 0 communication overhead: uplink=943718400, downlink=943718400\n",
      "==================================Global Round 1=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd5892abba754d28a37bab61d22b26fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb73cb88d7df4f1b942609f3d85dc2d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7248295b2ccc4a06981bf945669dcf12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n",
      "Global Round 1 communication overhead: uplink=943718400, downlink=943718400\n",
      "==================================Global Round 2=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "665ddc08967d41d7989d0417c24902a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa82dfa3483a4735b5271399cca3f902"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "adfa3236d6484fbcaeb4468fe0f3d54b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n",
      "Global Round 2 communication overhead: uplink=943718400, downlink=943718400\n",
      "==================================Global Round 3=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fffb39c1eb20459092cbad6182acd40c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6516829651a484aab00127a462c8ce4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "609e85e98e63430e96cfae39263afc5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n",
      "Global Round 3 communication overhead: uplink=943718400, downlink=943718400\n",
      "==================================Global Round 4=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b32b2750901243e8bf8b4764e276ea2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca340313b1c8454ab72fab53b89a9413"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4916a305aea45ca87fd286d0752ebdf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n",
      "Global Round 4 communication overhead: uplink=943718400, downlink=943718400\n",
      "==================================Global Round 5=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c51f393402ac433f96be9a49233a8a8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e9165cfdd3949aaa6c411de7e466ae4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a44a3203a1f49618ee2bcfcdf274ebe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n",
      "Global Round 5 communication overhead: uplink=943718400, downlink=943718400\n",
      "==================================Global Round 6=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83e1a80b8c15420c8e39ddf5962254e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4256f9750b084f459545546cfdac8aaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67e932aa44804e4e8e45e8e33952ce9d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n",
      "Global Round 6 communication overhead: uplink=943718400, downlink=943718400\n",
      "==================================Global Round 7=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59a248b7548d4b2bb0f187bf4457a619"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c42f8b4d69a84c45a94de292950566f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ed30acfaca54b15b19bf4ba9c7da153"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n",
      "Global Round 7 communication overhead: uplink=943718400, downlink=943718400\n",
      "==================================Global Round 8=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd3f4b2757f248d28913e76f72bb1e5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc8d1dbdfcf449bc95235dde4015d2ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "492472a7fe8c439dbaf6ff23fb3aa571"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n",
      "Global Round 8 communication overhead: uplink=943718400, downlink=943718400\n",
      "==================================Global Round 9=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6cfe63dccdb4712aec26437f752f3ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 communication overhead: uplink:352321536, downlink:352321536\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7684e3a8ff804a158e9ecc59b6065ce5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 communication overhead: uplink:257949696, downlink:257949696\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/106 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68d085a1aa564e098059bd6beebcfd5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 communication overhead: uplink:333447168, downlink:333447168\n",
      "Global Round 9 communication overhead: uplink=943718400, downlink=943718400\n",
      "FL communication overhead: uplink=9437184000, downlink=9437184000\n"
     ]
    }
   ],
   "source": [
    "simulator.simulate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train(False)\n",
    "t = tokenizer(\"Hang kitchen knives against \", return_tensors=\"pt\", add_special_tokens=False)\n",
    "res = model(t['input_ids'].to(simulator.device), attention_mask=t['attention_mask'].to(simulator.device))\n",
    "r = tokenizer.decode(res.logits.argmax(dim=-1)[-1], skip_special_tokens=True)\n",
    "print(r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}